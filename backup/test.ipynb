{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, SegformerForSemanticSegmentation, AutoConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\",)\n",
    "config=AutoConfig.from_pretrained(\"nvidia/mit-b0\")\n",
    "config.strides=[16,4,2,2]\n",
    "model = SegformerForSemanticSegmentation(config).from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    "                                                    config=config,\n",
    "                                                    ignore_mismatched_sizes=True,\n",
    "                                                    )\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "inputs[\"pixel_values\"]=inputs[\"pixel_values\"][:,:,:224,:224]\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "list(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerConfig, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegformerConfig.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\").id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegformerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "name_gvkey=pd.read_csv(\"name_gvkey.csv\")\n",
    "unique_names=pd.read_csv(\"unique_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text features for all companies in name_gvkey\n",
    "\n",
    "text_features_ref=[]\n",
    "with torch.no_grad():\n",
    "    for template in [\"company {}\", \"company name {}\", \"{} Inc\"]:\n",
    "        text_features_ref_template=[]\n",
    "        for i in tqdm.tqdm(range(0, len(name_gvkey[\"conml\"]), 64)):\n",
    "            name_gvkey_list=name_gvkey[\"conml\"][i:min(i+64,len(name_gvkey[\"conml\"]))]\n",
    "            prompt=[f\"company {company_name}\" for company_name in name_gvkey_list]\n",
    "            inputs_ref_=tokenizer(prompt, padding=True,  return_tensors=\"pt\")\n",
    "            text_features_ref_ = model.get_text_features(inputs_ref_[\"input_ids\"].cuda()) \n",
    "            text_features_ref_template.append(text_features_ref_)\n",
    "        text_features_ref_template=torch.vstack(text_features_ref_template)\n",
    "        text_features_ref.append(text_features_ref_template)\n",
    "    text_features_ref=torch.vstack([i.unsqueeze(0) for i in text_features_ref])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_data=[]\n",
    "with torch.no_grad():\n",
    "    for template in [\"company {}\", \"company name {}\", \"{} Inc\"]:\n",
    "        text_features_data_template=[]\n",
    "        for i in tqdm.tqdm(range(0, len(unique_names[\"company\"]), 64)):\n",
    "            company_list=unique_names[\"company\"][i:min(i+64,len(unique_names[\"company\"]))]\n",
    "            prompt=[f\"company {company_name}\" for company_name in company_list]\n",
    "            inputs_data_=tokenizer(prompt, padding=True,  return_tensors=\"pt\")\n",
    "            text_features_data_ = model.get_text_features(inputs_data_[\"input_ids\"].cuda()) \n",
    "            text_features_data_template.append(text_features_data_)\n",
    "        text_features_data_template=torch.vstack(text_features_data_template)\n",
    "        text_features_data.append(text_features_data_template)\n",
    "    text_features_data=torch.vstack([i.unsqueeze(0) for i in text_features_data])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_ref=torch.vstack([i.unsqueeze(0) for i in text_features_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for idx,company_name in enumerate(unique_names[\"company\"]):\n",
    "        inputs1 = tokenizer([f\"Company {company_name}\"], padding=True, return_tensors=\"pt\")\n",
    "        text_features1 = model.get_text_features(inputs1[\"input_ids\"].to(\"cuda:0\"))   \n",
    "\n",
    "        sim=(text_features1 / text_features1.norm(dim=1, keepdim=True))@\\\n",
    "        (text_features_ref / text_features_ref.norm(dim=1, keepdim=True)).T\n",
    "        print((company_name,pd.Series(sim[0].detach().cpu().numpy(),index=name_gvkey[\"conml\"]).sort_values(ascending=False).iloc[:5].index))\n",
    "        if idx==100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ref = tokenizer([f\"company {i}\" for i in name_gvkey[\"conml\"]], padding=True, return_tensors=\"pt\")\n",
    "text_features_ref = model.get_text_features(inputs_ref[\"input_ids\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gvkey[\"conml\"][name_gvkey[\"conml\"].str.lower().str.contains(\"yahoo\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_text_features(processor(text=[\"a photo of a cat\", \"a photo of a dog\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Uber\"\n",
    "encoded_input1 = tokenizer(text1, return_tensors='pt')\n",
    "output1 = model(**encoded_input1,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = [\"Uber Technology\", \"AA tech\", 'facebook']\n",
    "encoded_input2 = tokenizer(text2, return_tensors='pt', padding=True)\n",
    "output2 = model(**encoded_input2,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output1[\"hidden_states\"][-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output2[\"hidden_states\"][-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output1[\"pooler_output\"]/output1[\"pooler_output\"].norm(dim=1, keepdim=True))\\\n",
    "@(output2[\"pooler_output\"]/output2[\"pooler_output\"].norm(dim=1, keepdim=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "list(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_config = AutoConfig.from_pretrained(\n",
    "    \"logs/vitbase_imagenette_surrogate\",\n",
    "    num_labels=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models import SurrogateForImageClassificationConfig\n",
    "\n",
    "surrogate_for_image_classification_config = SurrogateForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=\"logs/vitbase_imagenette_surrogate\",\n",
    "    surrogate_config=surrogate_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SurrogateForImageClassification\n",
    "\n",
    "surrogate = SurrogateForImageClassification(\n",
    "    config=surrogate_for_image_classification_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurrogateForImageClassification.from_pretrained(\"logs/vitbase_imagenette_surrogate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_config = AutoConfig.from_pretrained(\n",
    "    \"logs/vitbase_imagenette_surrogate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from models import ExplainerForImageClassificationConfig\n",
    "\n",
    "explainer_for_image_classification_config = ExplainerForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=\"logs/vitbase_imagenette_surrogate\",\n",
    "    surrogate_config=surrogate_for_image_classification_config,\n",
    "    explainer_pretrained_model_name_or_path=\"logs/vitbase_imagenette_surrogate\",\n",
    "    explainer_config=explainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from models import ExplainerForImageClassification\n",
    "\n",
    "explainer = ExplainerForImageClassification(\n",
    "    config=explainer_for_image_classification_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ResnetConfig(PretrainedConfig):\n",
    "    model_type = \"resnet\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stem_type,\n",
    "        block_type=\"bottleneck\",\n",
    "        layers: List[int] = [3, 4, 6, 3],\n",
    "        num_classes: int = 1000,\n",
    "        input_channels: int = 3,\n",
    "        cardinality: int = 1,\n",
    "        base_width: int = 64,\n",
    "        stem_width: int = 64,\n",
    "        \n",
    "        avg_down: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if block_type not in [\"basic\", \"bottleneck\"]:\n",
    "            raise ValueError(f\"`block_type` must be 'basic' or bottleneck', got {block_type}.\")\n",
    "        if stem_type not in [\"\", \"deep\", \"deep-tiered\"]:\n",
    "            raise ValueError(f\"`stem_type` must be '', 'deep' or 'deep-tiered', got {stem_type}.\")\n",
    "\n",
    "        self.block_type = block_type\n",
    "        self.layers = layers\n",
    "        self.num_classes = num_classes\n",
    "        self.input_channels = input_channels\n",
    "        self.cardinality = cardinality\n",
    "        self.base_width = base_width\n",
    "        self.stem_width = stem_width\n",
    "        self.stem_type = stem_type\n",
    "        self.avg_down = avg_down\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50d_config = ResnetConfig(block_type=\"bottleneck\", stem_width=32, stem_type=\"deep\", avg_down=True)\n",
    "resnet50d_config.save_pretrained(\"custom-resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50d_config.__dict__.get(\"problem_type\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"       \".join([i for i in dir(resnet50d_config)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50d_config = ResnetConfig.from_pretrained(\"custom-resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from transformers import AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForDepthEstimation\n",
    "AutoModelForDepthEstimation.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\n",
    "AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoModel.from_pretrained(\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=AutoModel.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def method(self):\n",
    "        print(\"Original method\")\n",
    "\n",
    "def new_method(self):\n",
    "    print(\"New method for this instance\")\n",
    "\n",
    "obj = MyClass()\n",
    "obj.method()  # This will print: Original method\n",
    "\n",
    "# Change method only for this instance\n",
    "obj.method = new_method.__get__(obj, MyClass)\n",
    "obj.method()  # This will print: New method for this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_method.__get__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config = AutoConfig.from_pretrained(\"logs/resnet50_imagenette/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AutoModelForImageClassification.from_pretrained(\n",
    "    \"logs/resnet50_imagenette/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config = AutoConfig.from_pretrained(\n",
    "    classifier_args.classifier_config_name\n",
    "    or classifier_args.classifier_model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=classifier_args.classifier_cache_dir,\n",
    "    revision=classifier_args.classifier_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "classifier = AutoModelForImageClassification.from_pretrained(\n",
    "    classifier_args.classifier_model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in classifier_args.classifier_model_name_or_path),\n",
    "    config=classifier_config,\n",
    "    cache_dir=classifier_args.classifier_cache_dir,\n",
    "    revision=classifier_args.classifier_model_revision,\n",
    "    token=other_args.token,\n",
    "    ignore_mismatched_sizes=classifier_args.classifier_ignore_mismatched_sizes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
