{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv=[\"train_objexplainer.py\", \"configs/vitbase_imagenette_shapley_objexplainer_newsample_32.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9562d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import evaluate\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from arguments import DataTrainingArguments, ExplainerArguments, SurrogateArguments\n",
    "from models import (\n",
    "    ObjExplainerForImageClassification,\n",
    "    ObjExplainerForImageClassificationConfig,\n",
    "    SurrogateForImageClassificationConfig,\n",
    ")\n",
    "from utils import (\n",
    "    MaskDataset,\n",
    "    configure_dataset,\n",
    "    generate_mask,\n",
    "    get_checkpoint,\n",
    "    get_image_transform,\n",
    "    load_attribution,\n",
    "    log_dataset,\n",
    "    read_eval_results,\n",
    "    setup_dataset,\n",
    ")\n",
    "\n",
    "\"\"\" Fine-tuning a ðŸ¤— Transformers model for image classification\"\"\"\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.32.0.dev0\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/image-classification/requirements.txt\",\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OtherArguments:\n",
    "    token: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n",
    "                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    validation_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    test_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    train_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for train\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    validation_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for validation\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    test_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for test\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Parse arguments\n",
    "#######################################################\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "parser = HfArgumentParser(\n",
    "    (\n",
    "        SurrogateArguments,\n",
    "        ExplainerArguments,\n",
    "        DataTrainingArguments,\n",
    "        TrainingArguments,\n",
    "        OtherArguments,\n",
    "    )\n",
    ")\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "else:\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_args_into_dataclasses()\n",
    "\n",
    "########################################################\n",
    "# Setup logging\n",
    "#######################################################\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "if training_args.should_log:\n",
    "    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "########################################################\n",
    "# Correct cache dir if necessary\n",
    "########################################################\n",
    "if not os.path.exists(\n",
    "    os.sep.join((data_args.dataset_cache_dir).split(os.sep, 2)[:2])\n",
    "):\n",
    "    if os.path.exists(\"/data2\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/data2\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    elif os.path.exists(\"/sdata\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/sdata\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Set seed before initializing model.\n",
    "########################################################\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "########################################################\n",
    "# Initialize our dataset and prepare it for the 'image-classification' task.\n",
    "########################################################\n",
    "dataset_original, labels, label2id, id2label = setup_dataset(\n",
    "    data_args=data_args, other_args=other_args\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Initialize explainer model\n",
    "########################################################\n",
    "\n",
    "explainer_config = AutoConfig.from_pretrained(\n",
    "    explainer_args.explainer_config_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "if os.path.isfile(\n",
    "    f\"{explainer_args.explainer_model_name_or_path}/config.json\"\n",
    ") and (\n",
    "    json.loads(\n",
    "        open(f\"{explainer_args.explainer_model_name_or_path}/config.json\").read()\n",
    "    )[\"architectures\"][0]\n",
    "    == \"ObjExplainerForImageClassification\"\n",
    "):\n",
    "    explainer = ObjExplainerForImageClassification.from_pretrained(\n",
    "        explainer_args.explainer_model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "        config=explainer_config,\n",
    "        cache_dir=explainer_args.explainer_cache_dir,\n",
    "        revision=explainer_args.explainer_model_revision,\n",
    "        token=other_args.token,\n",
    "        ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "else:\n",
    "    surrogate_config = AutoConfig.from_pretrained(\n",
    "        surrogate_args.surrogate_config_name\n",
    "        or surrogate_args.surrogate_model_name_or_path,\n",
    "        num_labels=len(labels),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        finetuning_task=\"image-classification\",\n",
    "        cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        revision=surrogate_args.surrogate_model_revision,\n",
    "        token=other_args.token,\n",
    "    )\n",
    "    surrogate_for_image_classification_config = SurrogateForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer_for_image_classification_config = ObjExplainerForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_for_image_classification_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "        explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "        explainer_config=explainer_config,\n",
    "        explainer_from_tf=bool(\n",
    "            \".ckpt\" in explainer_args.explainer_model_name_or_path\n",
    "        ),\n",
    "        explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "        explainer_revision=explainer_args.explainer_model_revision,\n",
    "        explainer_token=other_args.token,\n",
    "        explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer = ObjExplainerForImageClassification(\n",
    "        config=explainer_for_image_classification_config,\n",
    "    )\n",
    "explainer_image_processor = AutoImageProcessor.from_pretrained(\n",
    "    explainer_args.explainer_image_processor_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Configure dataset (set max samples, transforms, etc.)\n",
    "########################################################\n",
    "dataset_explainer = copy.deepcopy(dataset_original)\n",
    "dataset_explainer = configure_dataset(\n",
    "    dataset=dataset_explainer,\n",
    "    image_processor=explainer_image_processor,\n",
    "    training_args=training_args,\n",
    "    data_args=data_args,\n",
    "    train_augmentation=False,\n",
    "    validation_augmentation=False,\n",
    "    test_augmentation=False,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9592e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import (\n",
    "    RegExplainerForImageClassification,\n",
    "    RegExplainerForImageClassificationConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer_for_image_classification_config = RegExplainerForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "    surrogate_config=surrogate_for_image_classification_config,\n",
    "    surrogate_from_tf=bool(\".ckpt\" in surrogate_args.surrogate_model_name_or_path),\n",
    "    surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "    surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "    surrogate_token=other_args.token,\n",
    "    surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "    explainer_config=explainer_config,\n",
    "    explainer_from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "    explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "    explainer_revision=explainer_args.explainer_model_revision,\n",
    "    explainer_token=other_args.token,\n",
    "    explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    ")\n",
    "\n",
    "regexplainer = RegExplainerForImageClassification(\n",
    "    config=regexplainer_for_image_classification_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0339c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import (\n",
    "    RegExplainerNormalizeForImageClassification,\n",
    "    RegExplainerNormalizeForImageClassificationConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer_normalize_for_image_classification_config = RegExplainerNormalizeForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "    surrogate_config=surrogate_for_image_classification_config,\n",
    "    surrogate_from_tf=bool(\".ckpt\" in surrogate_args.surrogate_model_name_or_path),\n",
    "    surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "    surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "    surrogate_token=other_args.token,\n",
    "    surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "    explainer_config=explainer_config,\n",
    "    explainer_from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "    explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "    explainer_revision=explainer_args.explainer_model_revision,\n",
    "    explainer_token=other_args.token,\n",
    "    explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    ")\n",
    "\n",
    "regexplainer_normalize = RegExplainerNormalizeForImageClassification(\n",
    "    config=regexplainer_normalize_for_image_classification_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8aa117",
   "metadata": {},
   "source": [
    "# FLOPS calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772919a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed.profiling.flops_profiler.profiler import FlopsProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24748782",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_step=3\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, flop_count_table, flop_count_str\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = ViTB32()\n",
    "    model.eval()\n",
    "\n",
    "    input = cv2.imread(\"../input.jpg\")\n",
    "    input = cv2.resize(input, (224, 224))\n",
    "    input = torch.from_numpy(input).permute(2, 0, 1)\n",
    "    input = input[None,:,:,:].float()\n",
    "\n",
    "    flop = FlopCountAnalysis(model, input)\n",
    "    print(flop_count_table(flop, max_depth=4))\n",
    "    print(flop_count_str(flop))\n",
    "    print(flop.total())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops/8/1e+9, macs/8/1e+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021548f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class surrogate_warpper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(type(x))\n",
    "        print(type(masks))\n",
    "        return self.model(x, masks, return_loss=False)\n",
    "    \n",
    "surrogate_warpped=surrogate_warpper(explainer.surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf58cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flop = FlopCountAnalysis(surrogate_warpped, pixel_values.to(device))\n",
    "print(flop_count_table(flop, max_depth=4))\n",
    "print(flop_count_str(flop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "        print(step)\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "        masks=torch.Tensor(\n",
    "                    np.random.choice([0,1], \n",
    "                         size=(batch_size, 256, 196), \n",
    "                         replace=True)\n",
    "        )        \n",
    "        \n",
    "        \n",
    "        if step == profile_step:\n",
    "            flop = FlopCountAnalysis(surrogate_warpped, pixel_values.to(device))\n",
    "            print(flop_count_table(flop, max_depth=4))\n",
    "            print(flop_count_str(flop))\n",
    "            print(flop.total())            \n",
    "            break\n",
    "        else:\n",
    "            loss = surrogate_warpped(pixel_values.to(device)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bd956",
   "metadata": {},
   "source": [
    "# surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73bd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_step=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class surrogate_warpper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return self.model(x, masks, return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "        print(step)\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "        masks=torch.Tensor(\n",
    "                    np.random.choice([0,1], \n",
    "                         size=(batch_size, 256, 196), \n",
    "                         replace=True)\n",
    "        )\n",
    "        \n",
    "        if step==profile_step:\n",
    "            macs, params = get_model_complexity_info(surrogate_warpper(explainer.surrogate), \n",
    "                                                     (2,3,224,224), \n",
    "                                                     as_strings=True,\n",
    "                                                     print_per_layer_stat=True, verbose=True)            \n",
    "            break\n",
    "        else:\n",
    "            loss = explainer.surrogate(pixel_values=pixel_values,\n",
    "                                       masks=masks,\n",
    "                                       return_loss=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229abd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "        print(step)\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "        masks=torch.Tensor(\n",
    "                    np.random.choice([0,1], \n",
    "                         size=(batch_size, 128, 196), \n",
    "                         replace=True)\n",
    "        )\n",
    "        if step==profile_step:\n",
    "            macs, params = profile(explainer.surrogate, (pixel_values, masks, None, False))            \n",
    "            break\n",
    "        else:\n",
    "            loss = explainer.surrogate(pixel_values=pixel_values,\n",
    "                                       masks=masks,\n",
    "                                       return_loss=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fe482",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    surrogate_prof\n",
    "except:\n",
    "    surrogate_prof=FlopsProfiler(explainer.surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "\n",
    "\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "        masks=torch.Tensor(\n",
    "                    np.random.choice([0,1], \n",
    "                         size=(batch_size, 32, 196), \n",
    "                         replace=True)\n",
    "        )\n",
    "        \n",
    "        if step == profile_step:\n",
    "            surrogate_prof.start_profile()        \n",
    "\n",
    "        loss = explainer.surrogate(pixel_values=pixel_values.to(device), \n",
    "                                   masks=masks,\n",
    "                                   return_loss=False)\n",
    "        \n",
    "        if step == profile_step:\n",
    "            flops = surrogate_prof.get_total_flops(as_string=False)\n",
    "            params = surrogate_prof.get_total_params(as_string=False)\n",
    "            macs = surrogate_prof.get_total_macs(as_string=False)\n",
    "            duration = surrogate_prof.get_total_duration(as_string=False)\n",
    "            \n",
    "            surrogate_prof.print_model_profile(profile_step=profile_step)\n",
    "            surrogate_prof.end_profile() \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dabb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops/1e+12, macs/1e+12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa86f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops,macs*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04178a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "macs/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    explainer_prof\n",
    "except:\n",
    "    explainer_prof=FlopsProfiler(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f21fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6101244",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer(pixel_values=torch.ones((64,3,224,224))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c967181",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "        if step == profile_step:\n",
    "            explainer_prof.start_profile()\n",
    "\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "\n",
    "        loss = explainer(pixel_values=pixel_values.to(device), \n",
    "                                   return_loss=False)\n",
    "        \n",
    "        if step == profile_step:\n",
    "            flops = explainer_prof.get_total_flops(as_string=False)\n",
    "            params = explainer_prof.get_total_params(as_string=False)\n",
    "            macs = explainer_prof.get_total_macs(as_string=False)\n",
    "            duration = explainer_prof.get_total_duration(as_string=False)\n",
    "            #explainer_prof.print_model_profile(profile_step=profile_step, output_file='profiler_log.txt')\n",
    "            explainer_prof.print_model_profile(profile_step=profile_step)\n",
    "            explainer_prof.end_profile() \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da162cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "optimizer=torch.optim.AdamW(explainer.parameters())\n",
    "\n",
    "for step in range(5):\n",
    "\n",
    "\n",
    "    pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "    masks=torch.Tensor(\n",
    "                np.random.choice([0,1], \n",
    "                     size=(batch_size, 32, 196), \n",
    "                     replace=True)\n",
    "    )        \n",
    "    model_outputs=torch.randn((batch_size, 32, 10))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = explainer(pixel_values=pixel_values.to(device),\n",
    "                     masks=masks,\n",
    "                     model_outputs=model_outputs,\n",
    "                     return_loss=True)\n",
    "\n",
    "    if step == profile_step:\n",
    "        explainer_prof.start_profile() \n",
    "        \n",
    "    loss.loss.backward()\n",
    "    optimizer.step()        \n",
    "        \n",
    "    if step == profile_step:\n",
    "        flops = explainer_prof.get_total_flops(as_string=False)\n",
    "        params = explainer_prof.get_total_params(as_string=False)\n",
    "        #explainer_prof.print_model_profile(profile_step=profile_step, output_file='profiler_log.txt')\n",
    "        explainer_prof.print_model_profile(profile_step=profile_step)\n",
    "        explainer_prof.end_profile() \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad1340",
   "metadata": {},
   "source": [
    "# reg explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235487fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9999636",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    regexplainer_prof\n",
    "except:\n",
    "    regexplainer_prof=FlopsProfiler(regexplainer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_size)\n",
    "items=[dataset_explainer[\"train\"][i] for i in range(batch_size)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(5):\n",
    "        pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "        \n",
    "        if step == profile_step:\n",
    "            regexplainer_prof.start_profile()        \n",
    "\n",
    "        loss = regexplainer(pixel_values=pixel_values.to(device), return_loss=False)\n",
    "        \n",
    "        if step == profile_step:\n",
    "            flops = regexplainer_prof.get_total_flops(as_string=False)\n",
    "            params = regexplainer_prof.get_total_params(as_string=False)\n",
    "            macs = regexplainer_prof.get_total_macs(as_string=False)\n",
    "            duration = regexplainer_prof.get_total_duration(as_string=False)            \n",
    "            regexplainer_prof.print_model_profile(profile_step=profile_step)\n",
    "            regexplainer_prof.end_profile() \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(macs/duration)/1e+12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch size \n",
    "8 170.68 GMACs 0.341 T\n",
    "16 341.36 GMACs 0.683 T\n",
    "32 682.72 GMACs 1.37 T\n",
    "64 1.37 TMACs 2.73 T \n",
    "128 2.73 TMACs 5.47 T\n",
    "256 5.46 TMACs 10.93 T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch size \n",
    "8 170.68 GMACs 0.341 T\n",
    "16 341.36 GMACs 0.683 T\n",
    "32 682.72 GMACs 1.37 T\n",
    "64 1.37 TMACs 5.47 T \n",
    "128 2.73 TMACs 5.47 T\n",
    "256 5.46 TMACs 10.93 T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notations:\n",
    "data parallel size (dp_size), model parallel size(mp_size),\n",
    "number of parameters (params), number of multiply-accumulate operations(MACs),\n",
    "number of floating-point operations (flops), floating-point operations per second (FLOPS),\n",
    "fwd latency (forward propagation latency), bwd latency (backward propagation latency),\n",
    "step (weights update latency), iter latency (sum of fwd, bwd and step latency)\n",
    "\n",
    "params per GPU:                                                         171.61 M\n",
    "params of model = params per GPU * mp_size:                             0       \n",
    "fwd MACs per GPU:                                                       22.02 TMACs\n",
    "fwd flops per GPU:                                                      44.08 T \n",
    "fwd flops of model = fwd flops per GPU * mp_size:                       44.08 T \n",
    "fwd latency:                                                            1.92 s  \n",
    "fwd FLOPS per GPU = fwd flops per GPU / fwd latency:                    22.97 TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02127e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.\n",
    "\n",
    "SurrogateForImageClassification(\n",
    "  171.61 M = 100% Params, 22.02 TMACs = 100% MACs, 1.92 s = 100% latency, 22.97 TFLOPS\n",
    "  (surrogate): ViTForImageClassification(\n",
    "    85.81 M = 50% Params, 17.6 TMACs = 79.9% MACs, 1.43 s = 74.78% latency, 24.55 TFLOPS\n",
    "    (vit): ViTModel(\n",
    "      85.8 M = 50% Params, 17.6 TMACs = 79.9% MACs, 1.43 s = 74.69% latency, 24.58 TFLOPS\n",
    "      (embeddings): ViTEmbeddings(\n",
    "        742.66 K = 0.43% Params, 115.84 GMACs = 0.53% MACs, 40.14 ms = 2.09% latency, 5.78 TFLOPS\n",
    "        (patch_embeddings): ViTPatchEmbeddings(\n",
    "          590.59 K = 0.34% Params, 115.84 GMACs = 0.53% MACs, 34.19 ms = 1.78% latency, 6.78 TFLOPS\n",
    "          (projection): Conv2d(590.59 K = 0.34% Params, 115.84 GMACs = 0.53% MACs, 33.59 ms = 1.75% latency, 6.9 TFLOPS, 3, 768, kernel_size=(16, 16), stride=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate 22.04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8aad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.print_model_profile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.print_model_profile??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84793ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.AdamW(regexplainer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(10)):\n",
    "    if step == profile_step:\n",
    "        prof.start_profile()\n",
    "\n",
    "    pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "    shapley_ground_truth=torch.randn(32,196,10)\n",
    "\n",
    "    loss = regexplainer(pixel_values=pixel_values.to(device), \n",
    "                        shapley_values=shapley_ground_truth.to(device),\n",
    "                        return_loss=True)\n",
    "    \n",
    "   \n",
    "\n",
    "    if step == profile_step:\n",
    "        flops = prof.get_total_flops(as_string=True)\n",
    "        params = prof.get_total_params(as_string=True)\n",
    "        prof.print_model_profile(profile_step=profile_step)\n",
    "        prof.end_profile() \n",
    "        break\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "for step in range(100):\n",
    "    if step == profile_step:\n",
    "        prof.start_profile()\n",
    "        \n",
    "    pixel_values=torch.cat([item[\"pixel_values\"].unsqueeze(0) for item in items])\n",
    "\n",
    "    loss = regexplainer(pixel_values=pixel_values)\n",
    "    \n",
    "    sdds\n",
    "\n",
    "    if step == profile_step:\n",
    "        flops = prof.get_total_flops(as_string=True)\n",
    "        params = prof.get_total_params(as_string=True)\n",
    "        prof.print_model_profile(profile_step=profile_step)\n",
    "        prof.end_profile()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = FlopsProfiler(regexplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed.profiling.flops_profiler.profiler.FlopsProfiler(model, ds_engine=None, recompute_fwd_factor=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ccf85",
   "metadata": {},
   "source": [
    "# move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer_normalize.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940cc96",
   "metadata": {},
   "source": [
    "# visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12693847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /System/Library/Fonts/Supplemental ~/.local/share/fonts/\n",
    "# rm -fr ~/.cache/matplotlib\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "# plt.rcParams['legend.fancybox'] = False\n",
    "# plt.rcParams['legend.edgecolor']='1.0'\n",
    "# plt.rcParams['legend.framealpha']=1\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)\n",
    "\n",
    "# https://github.com/dsc/colorbrewer-python/blob/master/colorbrewer.py\n",
    "\n",
    "Set1 = {\n",
    "    3: [[228,26,28], [55,126,184], [77,175,74]],\n",
    "    4: [[228,26,28], [55,126,184], [77,175,74], [152,78,163]],\n",
    "    5: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0]],\n",
    "    6: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51]],\n",
    "    7: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40]],\n",
    "    8: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191]],\n",
    "    9: [[228,26,28], [55,126,184], [77,175,74], [152,78,163], [255,127,0], [255,255,51], [166,86,40], [247,129,191], [153,153,153]],\n",
    "}\n",
    "\n",
    "Paired = {\n",
    "    3: [(166,206,227), [31,120,180], [178,223,138]],\n",
    "    4: [[166,206,227], [31,120,180], [178,223,138], [51,160,44]],\n",
    "    5: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153]],\n",
    "    6: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28]],\n",
    "    7: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111]],\n",
    "    8: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0]],\n",
    "    9: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214]],\n",
    "    10: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154]],\n",
    "    11: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153]],\n",
    "    12: [[166,206,227], [31,120,180], [178,223,138], [51,160,44], [251,154,153], [227,26,28], [253,191,111], [255,127,0], [202,178,214], [106,61,154], [255,255,153], [177,89,40]]\n",
    "}\n",
    "\n",
    "color_qual_7=['#F53345',\n",
    "            '#87D303',\n",
    "            '#04CBCC',\n",
    "            '#8650CD',\n",
    "            (160/256, 95/256, 0),\n",
    "            '#F5A637',              \n",
    "            '#DBD783',            \n",
    "             ]\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.edgecolor']='1.0'\n",
    "plt.rcParams['legend.framealpha']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa78404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cee014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4841e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_metric_with_explainer(\n",
    "    attribution_values,\n",
    "    explainer,\n",
    "    dataset,\n",
    "    iters_ground_truth,\n",
    "    meta_info,\n",
    "    check_class_efficiency=True,\n",
    "    ground_truth_key_select=None,\n",
    "    transform_mode=None\n",
    "):\n",
    "    record_dict_list= []\n",
    "    ground_truth_list = []\n",
    "    estimated_list = []\n",
    "    explainer.eval()\n",
    "    \n",
    "    # for sample_idx, tracking_dict in tqdm(attribution_values.items()):\n",
    "    for sample_idx, tracking_dict in tqdm(\n",
    "        attribution_values.items() if ground_truth_key_select is None else {key: attribution_values[key] for key in ground_truth_key_select}.items()\n",
    "    ):\n",
    "        # Prepare input and make prediction.\n",
    "        data = dataset[sample_idx]\n",
    "        with torch.no_grad():\n",
    "            estimated = explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "            \n",
    "        # Prepare ground truth values.\n",
    "        if isinstance(tracking_dict[\"iters\"], np.ndarray):\n",
    "            tracking_dict[\"iters\"] = tracking_dict[\"iters\"].tolist()\n",
    "        \n",
    "        ground_truth = tracking_dict[\"values\"][tracking_dict[\"iters\"].index(iters_ground_truth)]\n",
    "\n",
    "        if transform_mode is None:\n",
    "            pass\n",
    "        elif transform_mode==\"global\":\n",
    "            pass\n",
    "        elif transform_mode==\"sqrt\":\n",
    "            pass        \n",
    "        elif transform_mode==\"perinstance\":\n",
    "            ground_truth = ground_truth / np.linalg.norm(ground_truth, axis=(0, 1), keepdims=True)\n",
    "        elif transform_mode==\"perinstanceperclass\":\n",
    "            ground_truth = ground_truth / np.linalg.norm(ground_truth, axis=0, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError(transform_mode)\n",
    "        \n",
    "        estimated = estimated.T.cpu().detach().numpy()\n",
    "        ground_truth_list.append(ground_truth)\n",
    "        estimated_list.append(estimated)\n",
    "        \n",
    "        # Calculate MSE.\n",
    "        diff = estimated - ground_truth\n",
    "        mse_class= (diff * diff).sum(axis=0)\n",
    "\n",
    "        # Calculate other metrics.\n",
    "        record = {\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_all\": mse_class.mean(),\n",
    "            \"pearsonr_all\": stats.pearsonr(estimated.flatten(), ground_truth.flatten())[0],\n",
    "            \"pearsonr_all_per_class\": np.mean([stats.pearsonr(estimated[:, class_idx], ground_truth[:, class_idx])[0] for class_idx in np.arange(ground_truth.shape[1])]),\n",
    "            \"spearmanr_all\": stats.spearmanr(estimated.flatten(), ground_truth.flatten())[0],\n",
    "            \"spearmanr_all_per_class\": np.mean([stats.spearmanr(estimated[:, class_idx], ground_truth[:, class_idx])[0] for class_idx in np.arange(ground_truth.shape[1])]),\n",
    "            \"sign_agreement_all\": ((estimated>0)==(ground_truth>0)).astype(int).mean(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        if check_class_efficiency:\n",
    "            target_class_idx=np.argmax(tracking_dict[\"values\"][0].sum(axis=0))\n",
    "            assert data[\"labels\"]==target_class_idx\n",
    "            \n",
    "            record.update({\n",
    "                \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "                \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(), \n",
    "                \"pearsonr_target\": stats.pearsonr(estimated[:, target_class_idx], ground_truth[:, target_class_idx])[0],                \n",
    "                \"spearmanr_target\": stats.spearmanr(estimated[:, target_class_idx], ground_truth[:, target_class_idx])[0],                \n",
    "            })        \n",
    "        \n",
    "        # Append result for this image.\n",
    "        record.update(meta_info)\n",
    "        record_dict_list.append(record)\n",
    "\n",
    "    # Calculate global metrics.\n",
    "    ground_truth_all = np.array(ground_truth_list)\n",
    "    estimated_all = np.array(estimated_list)\n",
    "    pearson = stats.pearsonr(estimated_all.flatten(), ground_truth_all.flatten())[0]\n",
    "    spearman = stats.spearmanr(estimated_all.flatten(), ground_truth_all.flatten())[0]\n",
    "    for record in record_dict_list:\n",
    "        record['pearson_global'] = pearson\n",
    "        record['spearman_global'] = spearman\n",
    "        \n",
    "    return record_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fe328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_metric_with_value(\n",
    "    attribution_values_ground_truth,\n",
    "    iters_ground_truth,\n",
    "    attribution_values_calculated,\n",
    "    iters_calculated,\n",
    "    meta_info,\n",
    "    check_class_efficiency=True,\n",
    "    ground_truth_key_select=None,\n",
    "):\n",
    "    record_dict_list = []\n",
    "    ground_truth_list = []\n",
    "    estimated_list = []\n",
    "\n",
    "    for sample_idx, tracking_dict_ground_truth in tqdm(\n",
    "        attribution_values_ground_truth.items() if ground_truth_key_select is None else {key: attribution_values_ground_truth[key] for key in ground_truth_key_select}.items()\n",
    "    ):\n",
    "        \n",
    "        tracking_dict_calculated = attribution_values_calculated[sample_idx]\n",
    "\n",
    "        if isinstance(tracking_dict_ground_truth[\"iters\"], np.ndarray):\n",
    "            tracking_dict_ground_truth[\"iters\"] = tracking_dict_ground_truth[\n",
    "                \"iters\"\n",
    "            ].tolist()\n",
    "\n",
    "        if isinstance(tracking_dict_calculated[\"iters\"], np.ndarray):\n",
    "            tracking_dict_calculated[\"iters\"] = tracking_dict_calculated[\n",
    "                \"iters\"\n",
    "            ].tolist()\n",
    "\n",
    "        # Prepare ground truth values and model's estimates.\n",
    "        ground_truth = tracking_dict_ground_truth[\"values\"][\n",
    "            tracking_dict_ground_truth[\"iters\"].index(iters_ground_truth)\n",
    "        ]\n",
    "        estimated = tracking_dict_calculated[\"values\"][\n",
    "            tracking_dict_calculated[\"iters\"].index(iters_calculated)\n",
    "        ]\n",
    "        ground_truth_list.append(ground_truth)\n",
    "        estimated_list.append(estimated)\n",
    "\n",
    "        # Calculate MSE.\n",
    "        diff = estimated - ground_truth\n",
    "        mse_class = (diff * diff).sum(axis=0)\n",
    "       \n",
    "        \n",
    "        # Calculate other metrics.\n",
    "        record = {\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_all\": mse_class.mean(),\n",
    "\n",
    "            \"pearsonr_all\": stats.pearsonr(estimated.flatten(), ground_truth.flatten())[0],\n",
    "            \"pearsonr_all_per_class\": np.mean([\n",
    "                stats.pearsonr(estimated[:, class_idx], ground_truth[:, class_idx])[0]\n",
    "                for class_idx in np.arange(ground_truth.shape[1])\n",
    "            ]),\n",
    "\n",
    "            \"spearmanr_all\": stats.spearmanr(estimated.flatten(), ground_truth.flatten())[0],\n",
    "            \"spearmanr_all_per_class\": np.mean([\n",
    "                stats.spearmanr(estimated[:, class_idx], ground_truth[:, class_idx])[0]\n",
    "                for class_idx in np.arange(ground_truth.shape[1])\n",
    "            ]),\n",
    "            \"sign_agreement_all\": ((estimated>0)==(ground_truth>0)).astype(int).mean(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        if check_class_efficiency:\n",
    "            target_class_idx_ground_truth = np.argmax(tracking_dict_ground_truth[\"values\"][0].sum(axis=0))\n",
    "            target_class_idx_calculated = np.argmax(tracking_dict_calculated[\"values\"][0].sum(axis=0))            \n",
    "            assert target_class_idx_ground_truth == target_class_idx_calculated        \n",
    "            \n",
    "            record.update({                \n",
    "                \"mse_target\": mse_class[\n",
    "                    np.arange(len(mse_class)) == target_class_idx_ground_truth\n",
    "                ].mean(),\n",
    "                \"mse_nontarget\": mse_class[\n",
    "                    np.arange(len(mse_class)) != target_class_idx_ground_truth\n",
    "                ].mean(),                \n",
    "                \n",
    "                \"pearsonr_target\": stats.pearsonr(\n",
    "                    estimated[:, target_class_idx_ground_truth],\n",
    "                    ground_truth[:, target_class_idx_ground_truth],\n",
    "                )[0],  \n",
    "                \n",
    "                \"spearmanr_target\": stats.spearmanr(\n",
    "                    estimated[:, target_class_idx_ground_truth],\n",
    "                    ground_truth[:, target_class_idx_ground_truth],\n",
    "                )[0],                \n",
    "                \n",
    "            })        \n",
    "\n",
    "        # Append result for this image.\n",
    "        record.update(meta_info)\n",
    "        record_dict_list.append(record)\n",
    "\n",
    "    # Calculate global metrics.\n",
    "    ground_truth_all = np.array(ground_truth_list)\n",
    "    estimated_all = np.array(estimated_list)\n",
    "    pearson = stats.pearsonr(estimated_all.flatten(), ground_truth_all.flatten())[0]\n",
    "    spearman = stats.spearmanr(estimated_all.flatten(), ground_truth_all.flatten())[0]\n",
    "    for record in record_dict_list:\n",
    "        record['pearson_global'] = pearson\n",
    "        record['spearman_global'] = spearman\n",
    "\n",
    "    return record_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc9e79",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918aeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f13bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"]\\\n",
    "# =load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\", attribution_name=\"shapley\")\n",
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\", attribution_name=\"shapley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c254ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                  attribution_name=\"shapley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc643a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\",\n",
    "                 attribution_name=\"shapley\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\"]\\\n",
    "# =load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\",\n",
    "#              target_subset_size=196, attribution_name=\"shapley\",\n",
    "# sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aaca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "    attribution_name=\"shapley\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deafc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\"]\\\n",
    "# =load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\",\n",
    "#                      attribution_name=\"shapley\",\n",
    "# sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\",\n",
    "             attribution_name=\"shapley\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"]\\\n",
    "# =load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\",\n",
    "# attribution_name=\"shapley\",                 \n",
    "# sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100]                 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in shapley_loaded_dict.keys():\n",
    "    print(len(shapley_loaded_dict[key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e425c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                 attribution_name=\"banzhaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d55ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                 attribution_name=\"banzhaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "                 attribution_name=\"banzhaf\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6726a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\",\n",
    "                 attribution_name=\"banzhaf\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ef3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import rmtree\n",
    "# for path_temp in glob.glob(\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train/*\"):\n",
    "#     if int(path_temp.split('/')[-1]) in np.random.RandomState(seed=42).permutation(list(range(9469)))[:100]:\n",
    "#         pass\n",
    "#     else:\n",
    "#         rmtree(path_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in banzhaf_loaded_dict.keys():\n",
    "    print(key, len(banzhaf_loaded_dict[key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_binomial*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82107df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc880c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_loaded_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                 attribution_name=\"lime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                 attribution_name=\"lime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\",\n",
    "                 attribution_name=\"lime\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_binomial_eval_validation/extract_output/validation\"]\\\n",
    "# =load_attribution(\"logs/vitbase_imagenette_surrogate_binomial_eval_validation/extract_output/validation\",\n",
    "#                  attribution_name=\"lime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8ff0c",
   "metadata": {},
   "source": [
    "# distribution check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer[\"train\"][774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sample[\"iters\"][-10:], banzhaf_sample[\"iters\"][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sample[\"values\"][shapley_sample[\"iters\"].index(1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9bad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20079a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_target=[]\n",
    "# shapley_nontarget=[]\n",
    "\n",
    "# banzhaf_target=[]\n",
    "# banzhaf_nontarget=[]\n",
    "\n",
    "# for i in range(5000):\n",
    "#     label_target=dataset_explainer[\"train\"][i]['labels']\n",
    "#     shapley_target_nontarget=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"][i][\"values\"][-2]\n",
    "#     banzhaf_target_nontarget=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"][i][\"values\"][-5]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     shapley_target+=shapley_target_nontarget[:,label_target].tolist()\n",
    "#     shapley_nontarget+=shapley_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist()\n",
    "    \n",
    "    \n",
    "#     banzhaf_target+=banzhaf_target_nontarget[:,label_target].tolist()\n",
    "#     banzhaf_nontarget+=banzhaf_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ffb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sample_list=[]\n",
    "banzhaf_sample_list=[]\n",
    "lime_sample_list=[]\n",
    "\n",
    "\n",
    "    \n",
    "    label_target=dataset_explainer[\"train\"][idx]['labels']\n",
    "    shapley_sample=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][idx]\n",
    "    shapley_sample=shapley_sample[\"values\"][shapley_sample[\"iters\"].index(1000000)]\n",
    "    \n",
    "    banzhaf_sample=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"][idx]\n",
    "    banzhaf_sample=banzhaf_sample[\"values\"][banzhaf_sample[\"iters\"].index(1000000)]\n",
    "    \n",
    "    lime_sample=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"][idx]\n",
    "    lime_sample=lime_sample[\"values\"][lime_sample[\"iters\"].index(1000000)]    \n",
    "    \n",
    "\n",
    "    shapley_sample_list+=shapley_sample.flatten().tolist()\n",
    "    banzhaf_sample_list+=banzhaf_sample.flatten().tolist()\n",
    "    lime_sample_list+=lime_sample.flatten().tolist()\n",
    "    \n",
    "#     shapley_target+=shapley_target_nontarget[:,label_target].tolist()\n",
    "#     shapley_nontarget+=shapley_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist()\n",
    "    \n",
    "    \n",
    "#     banzhaf_target+=banzhaf_target_nontarget[:,label_target].tolist()\n",
    "#     banzhaf_nontarget+=banzhaf_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_norm=[]\n",
    "for idx in np.random.RandomState(seed=42).permutation(list(range(9469)))[:100].tolist():\n",
    "    shapley_sample=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][idx]\n",
    "    shapley_sample=shapley_sample[\"values\"][shapley_sample[\"iters\"].index(1000000)] \n",
    "    \n",
    "    metric_list_plot_norm.append({\"sample_idx\": idx,\n",
    "                                 \"norm\": np.linalg.norm(shapley_sample),\n",
    "                                 \"method_type\": \"KernelSHAP\"\n",
    "                                })\n",
    "    \n",
    "for idx in np.random.RandomState(seed=42).permutation(list(range(9469)))[:100].tolist():\n",
    "    banzhaf_sample=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"][idx]\n",
    "    banzhaf_sample=banzhaf_sample[\"values\"][banzhaf_sample[\"iters\"].index(1000000)]\n",
    "\n",
    "    metric_list_plot_norm.append({\"sample_idx\": idx,\n",
    "                                 \"norm\": np.linalg.norm(banzhaf_sample),\n",
    "                                 \"method_type\": \"BanzhafMSR\"\n",
    "                                })  \n",
    "    \n",
    "for idx in np.random.RandomState(seed=42).permutation(list(range(9469)))[:100].tolist():\n",
    "    lime_sample=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"][idx]\n",
    "    lime_sample=lime_sample[\"values\"][lime_sample[\"iters\"].index(1000000)]\n",
    "\n",
    "    metric_list_plot_norm.append({\"sample_idx\": idx,\n",
    "                                 \"norm\": np.linalg.norm(lime_sample),\n",
    "                                 \"method_type\": \"LIME\"\n",
    "                                })      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11453373",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_norm_df=pd.DataFrame(metric_list_plot_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726dc59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 3, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, method_type in enumerate([\"KernelSHAP\", \"BanzhafMSR\", \"LIME\"]):\n",
    "    ax=plt.Subplot(fig, box1[idx1])\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    plot_key=(method_type)\n",
    "    axd[plot_key]=ax  \n",
    "    \n",
    "for idx1, method_type in enumerate([\"KernelSHAP\", \"BanzhafMSR\", \"LIME\"]):\n",
    "\n",
    "    plot_key=(method_type)                      \n",
    "    \n",
    "    metric_list_plot_norm_df[metric_list_plot_norm_df[\"method_type\"]==method_type][\"norm\"].hist(ax=axd[plot_key], bins=10)\n",
    "    \n",
    "    axd[plot_key].set_title({\"KernelSHAP\": \"Shapley values\", \"BanzhafMSR\": \"Banzhaf values\", \"LIME\": \"LIME\"}[method_type])\n",
    "    \n",
    "    axd[plot_key].set_xlabel(\"L2 norm\")\n",
    "    axd[plot_key].set_ylabel(\"Count\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"feature_attribution_distribution.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"feature_attribution_distribution.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb184c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    ax=plt.Subplot(fig, box1[idx1])\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    plot_key=(metric)\n",
    "    axd[plot_key]=ax   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542bf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527b90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=plt.subplots(2,3, figsize=(20,10))\n",
    "axes[0][0].hist(shapley_nontarget+shapley_target, bins=100)\n",
    "axes[0][0].set_xlim([-0.3,0.3])\n",
    "axes[0][0].set_title(\"All classes\")\n",
    "\n",
    "axes[0][1].hist(shapley_target, bins=100)\n",
    "axes[0][1].set_xlim([-0.3,0.3])\n",
    "axes[0][1].set_title(\"Target classes\")\n",
    "\n",
    "\n",
    "axes[0][2].hist(shapley_nontarget, bins=100)\n",
    "axes[0][2].set_xlim([-0.3,0.3])\n",
    "axes[0][2].set_title(\"Non-target classes\")\n",
    "\n",
    "axes[1][0].hist(shapley_nontarget+shapley_target, bins=100)\n",
    "axes[1][0].set_xlim([-0.3,0.3])\n",
    "axes[1][0].set_title(\"All classesâ€“log scale\")\n",
    "axes[1][0].set_yscale(\"log\")\n",
    "\n",
    "axes[1][1].hist(shapley_target, bins=100)\n",
    "axes[1][1].set_xlim([-0.3,0.3])\n",
    "axes[1][1].set_title(\"Target classesâ€“log scale\")\n",
    "axes[1][1].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "axes[1][2].hist(shapley_nontarget, bins=100)\n",
    "axes[1][2].set_xlim([-0.3,0.3])\n",
    "axes[1][2].set_title(\"Non-target classesâ€“log scale\")\n",
    "axes[1][2].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f901b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=plt.subplots(2,3, figsize=(20,10))\n",
    "axes[0][0].hist(banzhaf_nontarget+banzhaf_target, bins=100)\n",
    "axes[0][0].set_xlim([-0.3,0.3])\n",
    "axes[0][0].set_title(\"All classes\")\n",
    "\n",
    "axes[0][1].hist(banzhaf_target, bins=100)\n",
    "axes[0][1].set_xlim([-0.3,0.3])\n",
    "axes[0][1].set_title(\"Target classes\")\n",
    "\n",
    "\n",
    "axes[0][2].hist(banzhaf_nontarget, bins=100)\n",
    "axes[0][2].set_xlim([-0.3,0.3])\n",
    "axes[0][2].set_title(\"Non-target classes\")\n",
    "\n",
    "axes[1][0].hist(banzhaf_nontarget+banzhaf_target, bins=100)\n",
    "axes[1][0].set_xlim([-0.3,0.3])\n",
    "axes[1][0].set_title(\"All classesâ€“log scale\")\n",
    "axes[1][0].set_yscale(\"log\")\n",
    "\n",
    "axes[1][1].hist(banzhaf_target, bins=100)\n",
    "axes[1][1].set_xlim([-0.3,0.3])\n",
    "axes[1][1].set_title(\"Target classesâ€“log scale\")\n",
    "axes[1][1].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "axes[1][2].hist(banzhaf_nontarget, bins=100)\n",
    "axes[1][2].set_xlim([-0.3,0.3])\n",
    "axes[1][2].set_title(\"Non-target classesâ€“log scale\")\n",
    "axes[1][2].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=plt.subplots(2,3, figsize=(20,10))\n",
    "axes[0][0].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_nontarget+banzhaf_target)), bins=100)\n",
    "axes[0][0].set_xlim([-0.6,0.6])\n",
    "axes[0][0].set_title(\"All classes\")\n",
    "\n",
    "axes[0][1].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_target)), bins=100)\n",
    "axes[0][1].set_xlim([-0.6,0.6])\n",
    "axes[0][1].set_title(\"Target classes\")\n",
    "\n",
    "\n",
    "axes[0][2].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_nontarget)), bins=100)\n",
    "axes[0][2].set_xlim([-0.6,0.6])\n",
    "axes[0][2].set_title(\"Non-target classes\")\n",
    "\n",
    "axes[1][0].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_nontarget+banzhaf_target)), bins=100)\n",
    "axes[1][0].set_xlim([-0.6,0.6])\n",
    "axes[1][0].set_title(\"All classesâ€“log scale\")\n",
    "axes[1][0].set_yscale(\"log\")\n",
    "\n",
    "axes[1][1].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_target)), bins=100)\n",
    "axes[1][1].set_xlim([-0.6,0.6])\n",
    "axes[1][1].set_title(\"Target classesâ€“log scale\")\n",
    "axes[1][1].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "axes[1][2].hist(list(map(lambda x: np.sign(x) * np.power(np.abs(x), 0.35), banzhaf_nontarget)), bins=100)\n",
    "axes[1][2].set_xlim([-0.6,0.6])\n",
    "axes[1][2].set_title(\"Non-target classesâ€“log scale\")\n",
    "axes[1][2].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d719186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_value(vec):\n",
    "    print(\"min:\", np.min(vec))\n",
    "    print(\"mean:\", np.mean(vec))\n",
    "    print(\"max:\", np.max(vec))\n",
    "    print(\"std:\", np.std(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_target=[]\n",
    "shapley_nontarget=[]\n",
    "\n",
    "banzhaf_target=[]\n",
    "banzhaf_nontarget=[]\n",
    "\n",
    "for i in range(1000):\n",
    "    label_target=dataset_explainer[\"train\"][i]['labels']\n",
    "    shapley_target_nontarget=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"][i][\"values\"][-2]\n",
    "    banzhaf_target_nontarget=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"][i][\"values\"][-5]\n",
    "    \n",
    "    shapley_target.append(shapley_target_nontarget[:,label_target].tolist())\n",
    "    shapley_nontarget.append(shapley_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist())\n",
    "    \n",
    "    \n",
    "    banzhaf_target.append(banzhaf_target_nontarget[:,label_target].tolist())\n",
    "    banzhaf_nontarget.append(banzhaf_target_nontarget[:,np.arange(10)!=label_target].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac129c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapley target\")\n",
    "summarize_value(shapley_target)\n",
    "print(\"Banzhaf target\")\n",
    "summarize_value(banzhaf_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d42450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapley nontarget\")\n",
    "summarize_value(shapley_nontarget)\n",
    "print(\"Banzhaf nontarget\")\n",
    "summarize_value(banzhaf_nontarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([np.max(i) for i in shapley_target])\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"max of each sample (Shapley)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([np.max(i) for i in banzhaf_target])\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"max of each sample (Banzhaf)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b04d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_target_nontarget[:,label_target].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860f759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_list_value=[]\n",
    "# for num_subsets in range(500, 100000, 500):\n",
    "#     metric_list_value+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"], \n",
    "#                                        iters_ground_truth=1000000, \n",
    "#                                        attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "#                                                  })\n",
    "    \n",
    "\n",
    "# for num_subsets in range(500, 100000, 500):\n",
    "#     metric_list_value+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"], \n",
    "#                                        iters_ground_truth=1000000, \n",
    "#                                        attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "#                                                  })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df=pd.DataFrame(metric_list_value)\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"num_subsets\",\n",
    "    y=\"mse_all\",\n",
    "    hue=\"\",\n",
    "    data=plot_df\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a028d0d",
   "metadata": {},
   "source": [
    "# Training target quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33689f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value_shapley=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd483646",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512, 1024, 2048, 3072]:\n",
    "    metric_list_value_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "                                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6394620",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [196, 392, 588, 1176, 3136]:\n",
    "    metric_list_value_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\",\n",
    "                                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05632a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_subsets=196\n",
    "# for i in range(16):\n",
    "#     shapley_loaded_dict_temp={}\n",
    "#     for sample_idx, tracking_dict in shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\"].items():\n",
    "#         shapley_loaded_dict_temp[sample_idx]=tracking_dict[i]\n",
    "\n",
    "#     metric_list_value_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict_temp,\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\",\n",
    "#                                                   \"nth\": i+1,\n",
    "#                                                  }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [258, 514, 1026, 2050, 4098, 5122, 9986]:\n",
    "    metric_list_value_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\",\n",
    "                                                 })   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(metric_list_value_shapley, \"logs/experiment_results/metric_list_value_shapley.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value_banzhaf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [5, 10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "    metric_list_value_banzhaf+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\",\n",
    "                                                 },\n",
    "                                       check_class_efficiency=False)\n",
    "\n",
    "for num_subsets in [100, 200, 300, 400, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]:\n",
    "    metric_list_value_banzhaf+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\",\n",
    "                                                 },\n",
    "                                       check_class_efficiency=False)\n",
    "#                                        ground_truth_key_select=\\\n",
    "#                                     banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"].keys()\n",
    "#                                                          )\n",
    "for num_subsets in list(range(6000, 100000+1000, 10000)):\n",
    "    metric_list_value_banzhaf+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                 },\n",
    "                                       check_class_efficiency=False)    \n",
    "\n",
    "# for num_subsets in [100, 200, 300, 400, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]:\n",
    "#     metric_list_value+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "#                                        iters_ground_truth=1000000, \n",
    "#                                        attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train\",\n",
    "#                                                  },\n",
    "#                                         check_class_efficiency=False,\n",
    "#                                        ground_truth_key_select=\\\n",
    "#                                     banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"].keys()                                                         \n",
    "#                                                          )                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21240a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_subsets in [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]+list(range(6000, 100000+1000, 10000)):\n",
    "#     metric_list_value_banzhaf+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\"], \n",
    "#                                        iters_ground_truth=1000000, \n",
    "#                                        attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "#                                                  },\n",
    "#                                        check_class_efficiency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(metric_list_value_banzhaf, \"logs/experiment_results/metric_list_value_banzhaf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71069b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value_lime=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f053c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in list(range(128, 3200, 128)):\n",
    "    metric_list_value_lime+=get_ground_truth_metric_with_value(attribution_values_ground_truth=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\",\n",
    "                                                 },\n",
    "                                       check_class_efficiency=False)\n",
    "#                                        ground_truth_key_select=\\\n",
    "#                                     banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"].keys()\n",
    "#                                                          )\n",
    "\n",
    "\n",
    "for num_subsets in list(range(100000, 1000000+100000, 100000)):\n",
    "    metric_list_value_lime+=get_ground_truth_metric_with_value(attribution_values_ground_truth=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                                 },\n",
    "                                       check_class_efficiency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(metric_list_value_lime, \"logs/experiment_results/metric_list_value_lime.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_model_checkpoint(model_path=\"logs/vitbase_imagenette_shapley_objexplainer_newsample_32\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791976d",
   "metadata": {},
   "source": [
    "# evaluate explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32543088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_checkpoint_value(current_checkpoint, best_checkpoint):\n",
    "    if current_checkpoint<best_checkpoint:\n",
    "        return \"before\"\n",
    "    elif current_checkpoint==best_checkpoint:\n",
    "        return \"best\"\n",
    "    elif current_checkpoint>best_checkpoint:\n",
    "        return \"after\"\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a53704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_checkpoint(model_path):\n",
    "    if os.path.exists(model_path+\"/trainer_state.json\"):\n",
    "        with open(model_path+\"/trainer_state.json\") as f:\n",
    "            trainer_state = json.load(f) \n",
    "        return trainer_state[\"best_model_checkpoint\"]\n",
    "    else:\n",
    "        checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "        with open(checkpoint_path_list[-1]+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)                \n",
    "        return checkpoint_trainer_state[\"best_model_checkpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "for model_path in glob.glob(\"/sdata/chanwkim/xai-amortization/logs_0901/*\"):\n",
    "    print(model_path)\n",
    "    if len(glob.glob(model_path+\"/checkpoint-*\"))==0:\n",
    "        #print(\"pass\", model_path)\n",
    "        pass\n",
    "    else:\n",
    "        best_checkpoint_path=get_best_model_checkpoint(model_path)\n",
    "        checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "        \n",
    "        epoch_step_count=pd.Series([int(i.split('-')[-1]) for i in checkpoint_path_list]).sort_values().diff().min()\n",
    "        checkpoint_to_delete=[checkpoint_path for checkpoint_path in checkpoint_path_list if int(checkpoint_path.split('-')[-1])-int(best_checkpoint_path.split('-')[-1])>epoch_step_count*10]\n",
    "        print(len(checkpoint_to_delete))\n",
    "        if len(checkpoint_to_delete)!=0:\n",
    "            print(best_checkpoint_path)\n",
    "            for checkpoint_path in tqdm(checkpoint_to_delete):\n",
    "                rmtree(checkpoint_path)\n",
    "                print(checkpoint_path)\n",
    "                \n",
    "            sdsds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_shapley=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9dda3",
   "metadata": {},
   "source": [
    "### Reg-AO (upfront, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512, 1024, 2048, 3072]:\n",
    "# for num_subsets in [2048, 3072]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"test\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "                                          })\n",
    "\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"train\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "                                          })        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24739c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_subsets in [512]:\n",
    "# # for num_subsets in [2048, 3072]:\n",
    "#     model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_antithetical_upfront_{num_subsets}\"\n",
    "#     with open(model_path+\"/trainer_state.json\") as f:\n",
    "#         trainer_state = json.load(f)\n",
    "\n",
    "#     checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "#     for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "#         checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "#         with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "#             checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "#         regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "#         metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                 explainer=regexplainer,\n",
    "#                                 dataset=dataset_explainer[\"test\"],\n",
    "#                                 iters_ground_truth=999424,\n",
    "#                                 meta_info={\n",
    "#                                            \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "#                                            \"model_path\": model_path,\n",
    "#                                            \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "#                                            \"is_best_checkpoint\": \n",
    "#                                             compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "#                                                                      best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "#                                           })\n",
    "\n",
    "\n",
    "#         metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                 explainer=regexplainer,\n",
    "#                                 dataset=dataset_explainer[\"train\"],\n",
    "#                                 iters_ground_truth=999424,\n",
    "#                                 meta_info={\n",
    "#                                            \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                            \"model_path\": model_path,\n",
    "#                                            \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "#                                            \"is_best_checkpoint\": \n",
    "#                                             compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "#                                                                      best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "#                                           })        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f50e6",
   "metadata": {},
   "source": [
    "### Reg-AO (upfront, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c17b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [196, 392, 588, 1176, 3136]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"test\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "                                          })\n",
    "\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"train\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(trainer_state[\"best_model_checkpoint\"].split('-')[-1]))\n",
    "                                          })        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661a534",
   "metadata": {},
   "source": [
    "### Reg-AO (newsample, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_subsets in [196]:\n",
    "#     model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_{num_subsets}\"\n",
    "# #     with open(model_path+\"/trainer_state.json\") as f:\n",
    "# #         trainer_state = json.load(f)\n",
    "\n",
    "#     checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "#     for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "#         checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "#         with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "#             checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "#         regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "#         metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                 explainer=regexplainer,\n",
    "#                                 dataset=dataset_explainer[\"test\"],\n",
    "#                                 iters_ground_truth=999424,\n",
    "#                                 meta_info={\n",
    "#                                            \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "#                                            \"model_path\": model_path,\n",
    "#                                            \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "#                                            \"is_best_checkpoint\": \n",
    "#                                             compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "#                                                                      best_checkpoint=1184)\n",
    "#                                           })\n",
    "\n",
    "\n",
    "#         metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                 explainer=regexplainer,\n",
    "#                                 dataset=dataset_explainer[\"train\"],\n",
    "#                                 iters_ground_truth=999424,\n",
    "#                                 meta_info={\n",
    "#                                            \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                            \"model_path\": model_path,\n",
    "#                                            \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "#                                            \"is_best_checkpoint\": \n",
    "#                                             compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "#                                                                      best_checkpoint=1184)\n",
    "#                                           })        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2a743",
   "metadata": {},
   "source": [
    "### SGD-shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [9986]:\n",
    "    model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\"\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"test\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                          })\n",
    "\n",
    "\n",
    "        metric_list_shapley+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"train\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                          })        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f60f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_9986/checkpoint-9324/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f84690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_9986/checkpoint-148/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ae175",
   "metadata": {},
   "source": [
    "## load banzhaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f07e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_banzhaf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef914c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target_transform_mode, num_subsets_list in zip([\"global\",\"sqrt\", \"perinstance\", \"perinstanceperclass\"],\n",
    "#                                   [[10,100,500], [10,100,500], [100,500], [10, 100,500]]):\n",
    "for target_transform_mode, num_subsets_list in zip([\"global\", \"perinstanceperclass\"],\n",
    "                                  [[10,100,500], [10, 100,500]]):\n",
    "    regexplainer_normalize.config.target_transform_mode=target_transform_mode\n",
    "    for num_subsets in num_subsets_list:\n",
    "        model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_{target_transform_mode}_{num_subsets}\"\n",
    "\n",
    "        checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "        for checkpoint_path in tqdm(checkpoint_path_list[:]):\n",
    "            checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "            with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "                checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "            regexplainer_normalize.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "            metric_list_banzhaf+=get_ground_truth_metric_with_explainer(attribution_values=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\"], \n",
    "                                    explainer=regexplainer_normalize,\n",
    "                                    dataset=dataset_explainer[\"test\"],\n",
    "                                    iters_ground_truth=1000000,\n",
    "                                    meta_info={\n",
    "                                               \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                               \"model_path\": model_path,\n",
    "                                               \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                               \"is_best_checkpoint\": \n",
    "                                                compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                         best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                              },                                   \n",
    "                                    check_class_efficiency=False,\n",
    "                                    transform_mode=target_transform_mode)\n",
    "\n",
    "\n",
    "            metric_list_banzhaf+=get_ground_truth_metric_with_explainer(attribution_values=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "                                    explainer=regexplainer_normalize,\n",
    "                                    dataset=dataset_explainer[\"train\"],\n",
    "                                    iters_ground_truth=1000000,\n",
    "                                    meta_info={\n",
    "                                               \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                               \"model_path\": model_path,\n",
    "                                               \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                               \"is_best_checkpoint\": \n",
    "                                                compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                         best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                              },\n",
    "                                    check_class_efficiency=False,\n",
    "                                    transform_mode=target_transform_mode)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(metric_list_banzhaf, \"logs/experiment_results/metric_list_banzhaf.pt\")\n",
    "    metric_list_banzhaf=torch.load(\"logs/experiment_results/metric_list_banzhaf.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d676e",
   "metadata": {},
   "source": [
    "### load lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c46976",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_lime=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target_transform_mode, num_subsets_list in zip([\"global\",\"sqrt\", \"perinstance\", \"perinstanceperclass\"],\n",
    "#                                   [[128,256,512], [128,256,512], [256,512], [256,512]]):\n",
    "for target_transform_mode, num_subsets_list in zip([\"global\", \"perinstanceperclass\"],\n",
    "                                  [[256,512], [256,512]]):    \n",
    "    regexplainer_normalize.config.target_transform_mode=target_transform_mode\n",
    "    for num_subsets in num_subsets_list:\n",
    "        model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_{target_transform_mode}_{num_subsets}\"\n",
    "\n",
    "        checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "        for checkpoint_path in tqdm(checkpoint_path_list[:]):\n",
    "            checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "            with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "                checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "            regexplainer_normalize.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "            metric_list_lime+=get_ground_truth_metric_with_explainer(attribution_values=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\"], \n",
    "                                    explainer=regexplainer_normalize,\n",
    "                                    dataset=dataset_explainer[\"test\"],\n",
    "                                    iters_ground_truth=1000000,\n",
    "                                    meta_info={\n",
    "                                               \"true_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                               \"model_path\": model_path,\n",
    "                                               \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                               \"is_best_checkpoint\": \n",
    "                                                compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                         best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                              },                                   \n",
    "                                    check_class_efficiency=False,\n",
    "                                    transform_mode=target_transform_mode)\n",
    "\n",
    "\n",
    "            metric_list_lime+=get_ground_truth_metric_with_explainer(attribution_values=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"], \n",
    "                                    explainer=regexplainer_normalize,\n",
    "                                    dataset=dataset_explainer[\"train\"],\n",
    "                                    iters_ground_truth=1000000,\n",
    "                                    meta_info={\n",
    "                                               \"true_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                               \"model_path\": model_path,\n",
    "                                               \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                               \"is_best_checkpoint\": \n",
    "                                                compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                         best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                              },\n",
    "                                    check_class_efficiency=False,\n",
    "                                    transform_mode=target_transform_mode)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d58399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=pd.DataFrame(metric_list_banzhaf)\n",
    "df_temp[(df_temp[\"is_best_checkpoint\"]==\"best\")&\n",
    "        (df_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\")\n",
    "].groupby([\"model_path\"])[\"mse_all\"].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(metric_list_lime, \"logs/experiment_results/metric_list_lime.pt\")\n",
    "    metric_list_lime=torch.load(\"logs/experiment_results/metric_list_lime.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374c1a3",
   "metadata": {},
   "source": [
    "# Training target quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3aefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_value_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]}, antithetical)',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": True\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Permutation ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )       \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Permutation ({metric_temp[\"num_subsets\"]}, antithetical)',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": True\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Permutation ({metric_temp[\"num_subsets\"]}, newsample, {metric_temp[\"nth\"]})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'SGD-Shapley ({metric_temp[\"num_subsets\"]}, antithetical)',\n",
    "             \"method_type\": 'SGD-Shapley',\n",
    "             \"antithetical\": True\n",
    "            }\n",
    "        )          \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df.groupby([\"method_name\",\"num_subsets\",\n",
    "                            \"true_name\", \"estimated_name\",\n",
    "                            ])[[\"pearsonr_all_per_class\", \"spearmanr_all_per_class\",\n",
    "                               \"pearsonr_all\", \"spearmanr_all\"\n",
    "                               ]].mean().reset_index().sort_values(\"num_subsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(metric_list_plot_df[[\"method_type\",\"antithetical\"]]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d6a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632ea20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ea391",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    ax=plt.Subplot(fig, box1[idx1])\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    plot_key=(idx1)\n",
    "    axd[plot_key]=ax   \n",
    "    \n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax    \n",
    "    \n",
    "    \n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "\n",
    "    plot_key=(idx1)\n",
    "\n",
    "\n",
    "    if metric==\"each\":\n",
    "        sns.barplot(\n",
    "            x=\"mse_all\",\n",
    "            y=\"method_name\",\n",
    "        #     hue=\"method\",\n",
    "        #     style=\"AO type\",\n",
    "        #     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_ylabel(\"Method\")#, fontsize=20)\n",
    "        axd[plot_key].set_xlabel(\"MSE (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        # axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "        # axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "        # axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        # axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(1))\n",
    "        axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "#         axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=-90, labelsize=20, labelright=True)\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0, labelsize=10)  \n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#         leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"MSE_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"mse_all\",\n",
    "            x=\"num_subsets\",\n",
    "            #style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_title(\"Error\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Error\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3100)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 0.45)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0) \n",
    "            \n",
    "    elif metric==\"pearsonr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            #style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            errorbar=None, \n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Correlation\")\n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Pearson Correlation\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3200)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        leg.remove()\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"spearmanr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"spearmanr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            #style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            errorbar=None,\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Rank correlation\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Spearman Correlation\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3200)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "        leg.remove()\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)  \n",
    "\n",
    "        \n",
    "    elif metric==\"sign_agreement_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"sign_agreement_all\",\n",
    "            x=\"num_subsets\",\n",
    "            #style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            errorbar=None,\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Sign Agreement\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Sign Agreement\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3200)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "        leg.remove()            \n",
    "\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_shapley.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_shapley.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf9169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ground_truth_metric_with_value??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ab061",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\"][0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_value_banzhaf:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )        \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        ) \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "        continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )         \n",
    "        \n",
    "        \n",
    "#     elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\" and\\\n",
    "#        metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train\":\n",
    "#         metric_temp.update(\n",
    "#             {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]})',\n",
    "#              \"method_type\": 'BanzhafMSR',\n",
    "#              \"antithetical\": False\n",
    "#             }\n",
    "#         )\n",
    "        \n",
    "#     elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train\" and\\\n",
    "#        metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train\":\n",
    "#         metric_temp.update(\n",
    "#             {\"method_name\": f'Banzhaf MSR ({metric_temp[\"num_subsets\"]}, antithetical)',\n",
    "#              \"method_type\": 'BanzhafMSR',\n",
    "#              \"antithetical\": True\n",
    "#             }\n",
    "#         )            \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df.groupby([\"method_name\",\"num_subsets\",\n",
    "                            \"true_name\", \"estimated_name\",\n",
    "                            ])[[\"pearsonr_all_per_class\", \"spearmanr_all_per_class\",\n",
    "                               \"pearsonr_all\", \"spearmanr_all\"\n",
    "                               ]].mean().reset_index().sort_values(\"num_subsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092eea0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 25)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(5, 1, hspace=0.4)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "    ax=plt.Subplot(fig, box1[idx1])\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    plot_key=(idx1)\n",
    "    axd[plot_key]=ax   \n",
    "    \n",
    "    \n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "\n",
    "    plot_key=(idx1)\n",
    "\n",
    "\n",
    "    if metric==\"each\":\n",
    "        sns.barplot(\n",
    "            x=\"mse_all\",\n",
    "            y=\"method_name\",\n",
    "        #     hue=\"method\",\n",
    "        #     style=\"AO type\",\n",
    "        #     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_ylabel(\"Method\", fontsize=20)\n",
    "        axd[plot_key].set_xlabel(\"MSE (all classes)\", fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        # axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "        # axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "        # axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        # axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(1))\n",
    "        axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        # axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=-90, labelsize=20, labelright=True)\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0, labelsize=10)  \n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#         leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"MSE_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"mse_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_title(\"Error\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"MSE (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 5100)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        #axd[plot_key].set_ylim(0, 1.05)\n",
    "        axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0) \n",
    "            \n",
    "    elif metric==\"pearsonr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Correlation\")\n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Pearson corr. (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 5100)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"spearmanr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"spearmanr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Rank correlation\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Spearman corr. (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 5100)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"pearsonr_all_per_class\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all_per_class\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Correlation\")\n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Pearson correlation (Per class)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 5100)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "            \n",
    "    elif metric==\"spearmanr_all_per_class\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all_per_class\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Rank correlation\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Spearman corr. (Per class)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 5100)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_banzhaf.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_banzhaf.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68942fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68418dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_value_lime:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'LIME ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "        continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'LIME ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"antithetical\": False\n",
    "            }\n",
    "        )        \n",
    "                  \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75402018",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 25)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(5, 1, hspace=0.4)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "    ax=plt.Subplot(fig, box1[idx1])\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    plot_key=(idx1)\n",
    "    axd[plot_key]=ax   \n",
    "    \n",
    "    \n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "\n",
    "    plot_key=(idx1)\n",
    "\n",
    "\n",
    "    if metric==\"each\":\n",
    "        sns.barplot(\n",
    "            x=\"mse_all\",\n",
    "            y=\"method_name\",\n",
    "        #     hue=\"method\",\n",
    "        #     style=\"AO type\",\n",
    "        #     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_ylabel(\"Method\", fontsize=20)\n",
    "        axd[plot_key].set_xlabel(\"MSE (all classes)\", fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        # axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "        # axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "        # axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        # axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(1))\n",
    "        axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        # axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=-90, labelsize=20, labelright=True)\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0, labelsize=10)  \n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#         leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "#         for line in leg.get_lines():\n",
    "#             line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"MSE_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"mse_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_title(\"Error\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"MSE (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3400)\n",
    "\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "        #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "        #axd[plot_key].set_ylim(0, 1.05)\n",
    "        axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0) \n",
    "            \n",
    "    elif metric==\"pearsonr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Correlation\")\n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Pearson corr. (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3400)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"spearmanr_all\":\n",
    "        sns.lineplot(\n",
    "            y=\"spearmanr_all\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Rank correlation\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Spearman corr. (all classes)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3400)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "    elif metric==\"pearsonr_all_per_class\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all_per_class\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Correlation\")\n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Pearson correlation (Per class)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3400)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)  \n",
    "            \n",
    "            \n",
    "    elif metric==\"spearmanr_all_per_class\":\n",
    "        sns.lineplot(\n",
    "            y=\"pearsonr_all_per_class\",\n",
    "            x=\"num_subsets\",\n",
    "            style=\"antithetical\",\n",
    "            hue=\"method_type\",\n",
    "            #palette=\"tab10\",\n",
    "            marker='o',    \n",
    "            markeredgecolor=None,\n",
    "            #markersize=10,   \n",
    "            #alpha=0.8,            \n",
    "            #linewidth=3,\n",
    "            data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "            ax=axd[plot_key]\n",
    "        )\n",
    "        \n",
    "        axd[plot_key].set_title(\"Rank correlation\")\n",
    "        \n",
    "        \n",
    "        axd[plot_key].set_xlabel(\"# Samples / Point\")#, fontsize=20)\n",
    "        axd[plot_key].set_ylabel(\"Spearman corr. (Per class)\")#, fontsize=20)\n",
    "\n",
    "        # xaxis\n",
    "        axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "        #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "        axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_xlim(0, 3400)\n",
    "\n",
    "        # yaxis\n",
    "        axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "        #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "        axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "        axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "        axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "        axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "        axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "        # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "        \n",
    "\n",
    "        axd[plot_key].spines['right'].set_visible(False)\n",
    "        axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "        leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58738d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_LIME.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_quality_LIME.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0de0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec27c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d8733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe751d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba773b65",
   "metadata": {},
   "source": [
    "# Training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_196/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "148*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c62f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_196/checkpoint-296/trainer_state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9963b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(metric_list, \"logs/experiment_results/metric_list.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list)[\"model_path\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff804cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\" for num_subsets in [512, 1024, 2048, 3072]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (KernelSHAP, {num_subsets})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )    \n",
    "    \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (Permutation, {num_subsets})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )      \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_antithetical_upfront_{num_subsets}\" for num_subsets in [512, 1024, 2048, 3072]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (KernelSHAP, {num_subsets})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )            \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\" for num_subsets in [9986]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (SGD-Shapley, {num_subsets})',\n",
    "             \"method_type\": 'SGD-Shapley',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )             \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_newsample_32\"] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Obj-AO',\n",
    "             \"method_type\": 'Obj',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )   \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_antithetical_newsample_32\"] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Obj-AO',\n",
    "             \"method_type\": 'Obj',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )           \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"antithetical\"]][\"model_path\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a88027",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(27, 30)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(5, 1, hspace=0.4)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 3, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"MSE (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) # labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "\n",
    "\n",
    "        elif metric==\"pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)              \n",
    "            \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "                \n",
    "                \n",
    "                  \n",
    "\n",
    "        elif metric==\"pearsonr_all_per_class\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (Per classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all_per_class\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (Per classes)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_curve_shapley_train.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_curve_shapley_train.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_banzhaf:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_global_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (BanzhafMSR, global {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR (global)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_sqrt_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (BanzhafMSR, sqrt {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR (sqrt)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_perinstance_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (BanzhafMSR, perinstance {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR (perinstance)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        ) \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_perinstanceperclass_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (BanzhafMSR, perinstanceperclass {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR (perinstanceperclass)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )         \n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[[\"true_name\", \"model_path\", \"epoch\", \"sample_idx\"]].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ba5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[\"pearsonr_all\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44013b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[\"method_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2240c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bd35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e26828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4*9, 6*5)\n",
    "#(4*7, 6*4)\n",
    "\n",
    "fig = plt.figure(figsize=(35, 24)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(5, 1, hspace=0.4)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"BanzhafMSR (sqrt)\", \"BanzhafMSR (global)\", \"BanzhafMSR (perinstance)\", \"BanzhafMSR (perinstanceperclass)\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"BanzhafMSR (sqrt)\", \"BanzhafMSR (global)\", \"BanzhafMSR (perinstance)\", \"BanzhafMSR (perinstanceperclass)\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"MSE (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) # labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "\n",
    "\n",
    "        elif metric==\"pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)              \n",
    "            \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "                \n",
    "                \n",
    "                  \n",
    "\n",
    "        elif metric==\"pearsonr_all_per_class\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (Per classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all_per_class\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (Per classes)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_curve_banzhaf_train.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_curve_banzhaf_train.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70678d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb199a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot=[]\n",
    "for metric in metric_list_lime:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_global_{num_subsets}\" for num_subsets in [128, 256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (LIME, global {num_subsets})',\n",
    "             \"method_type\": 'LIME (global)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_sqrt_{num_subsets}\" for num_subsets in [128, 256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (LIME, sqrt {num_subsets})',\n",
    "             \"method_type\": 'LIME (sqrt)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_perinstance_{num_subsets}\" for num_subsets in [256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (LIME, perinstance {num_subsets})',\n",
    "             \"method_type\": 'LIME (perinstance)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )            \n",
    "\n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_perinstanceperclass_{num_subsets}\" for num_subsets in [256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"model_name\": f'Reg-AO (LIME, perinstanceperclass {num_subsets})',\n",
    "             \"method_type\": 'LIME (perinstanceperclass)',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split\n",
    "            }\n",
    "        )            \n",
    "        \n",
    "     \n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acce5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4*9, 6*5)\n",
    "#(4*7, 6*4)\n",
    "\n",
    "fig = plt.figure(figsize=(35, 24)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(5, 1, hspace=0.4)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"LIME (sqrt)\", \"LIME (global)\", \"LIME (perinstance)\", \"LIME (perinstanceperclass)\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"pearsonr_all_per_class\", \"spearmanr_all_per_class\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"LIME (sqrt)\", \"LIME (global)\", \"LIME (perinstance)\", \"LIME (perinstanceperclass)\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"MSE (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) # labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "\n",
    "\n",
    "        elif metric==\"pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)              \n",
    "            \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (all classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "                \n",
    "                \n",
    "                  \n",
    "\n",
    "        elif metric==\"pearsonr_all_per_class\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"pearsonr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. (Per classes)\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)   \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all_per_class\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)]\n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"epoch\",\n",
    "                y=\"spearmanr_all_per_class\",\n",
    "                hue=\"model_name\",\n",
    "#                 style=\"antithetical\",\n",
    "#                 palette=\"tab10\",\n",
    "#                 alpha=0.8,            \n",
    "#                 linewidth=3,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"Epoch\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. (Per classes)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_curve_lime_train.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_curve_lime_train.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747785ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ae252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b1491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e71b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6702e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4035e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "# axd={\"main\":ax}\n",
    "\n",
    "# plot_key=\"main\"\n",
    "\n",
    "\n",
    "# def get_reg_type(x):\n",
    "#     if \"regression\" in x:\n",
    "#         return \"regression\"\n",
    "#     elif \"permutation\" in x:\n",
    "#         return \"permutation\"\n",
    "#     else:\n",
    "#         return \"none\"\n",
    "    \n",
    "\n",
    "# metric_df=pd.DataFrame(metric_list+metric_list_)\n",
    "# metric_df[\"explainer\"]=metric_df[\"explainer\"].str.replace(\n",
    "#     \"Reg-AO (upfront, regression, 512, antithetical)\",\n",
    "#     \"Reg-AO (upfront, regression, antithetical, 512)\")\\\n",
    "#     .str.replace(\n",
    "#     \"Obj-AO (newsample, 32, antithetical)\",\n",
    "#     \"Obj-AO (newsample, antithetical, 32)\",)\n",
    "\n",
    "# print(metric_df[\"explainer\"].value_counts())\n",
    "\n",
    "\n",
    "# metric_df[\"AO type\"]=metric_df[\"explainer\"].map(lambda x: x.split('(')[0].strip())\n",
    "# metric_df[\"num_subsets\"]=metric_df[\"explainer\"].map(lambda x: int(x.split(',')[-1][:-1].strip()))\n",
    "# metric_df[\"reg type\"]=metric_df[\"explainer\"].map(get_reg_type)\n",
    "\n",
    "# metric_df=metric_df.sort_values([\"AO type\", \"reg type\", \"num_subsets\"], ascending=True)\n",
    "# # metric_df=metric_df[metric_df[\"explainer\"].str.contains(\"Obj-AO\")]\n",
    "# metric_df=metric_df[metric_df[\"explainer\"].str.contains(\"permutation\")]\n",
    "\n",
    "# sns.lineplot(\n",
    "#     x=\"epoch\",\n",
    "#     y=\"mse_target\",\n",
    "#     hue=\"explainer\",\n",
    "#     style=\"AO type\",\n",
    "#     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "#     palette=\"tab10\",\n",
    "#     linewidth=3,\n",
    "#     data=metric_df,\n",
    "#     ax=axd[plot_key]\n",
    "# )\n",
    "\n",
    "\n",
    "# axd[plot_key].set_ylabel(\"MSE\", fontsize=20)\n",
    "# axd[plot_key].set_xlabel(\"Epoch\", fontsize=20)\n",
    "\n",
    "          \n",
    "# axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "# axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "# axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "# axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "# axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "# axd[plot_key].spines['right'].set_visible(False)\n",
    "# axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "# # axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "# # axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))    \n",
    "# # axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "# # axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# # axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "# axd[plot_key].set_xlim(0, 40)\n",
    "# axd[plot_key].set_ylim(0, 0.030)\n",
    "\n",
    "# leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "# for line in leg.get_lines():\n",
    "#     line.set_linewidth(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174daeb",
   "metadata": {},
   "source": [
    "# FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_ground_truth_flops=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "    metric_list_ground_truth_flops+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flops_subset_eval = 17_563_067_904 * num_train_sample * num_subsets\n",
    "# flops_forward = 38_898_221_568 * 1 * metric_temp[\"epoch\"] * num_train_sample\n",
    "# flops_backward = 38_898_221_568 * 2 * metric_temp[\"epoch\"] * num_train_sample    \n",
    "# flops_parameter_update = 104_730_000 * metric_temp[\"epoch\"] * (num_train_sample//64) * (2+3+4+3+3+4) # need to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58470fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_sample=9469\n",
    "\n",
    "metric_list_plot=[]\n",
    "for metric in metric_list_ground_truth_flops:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        \n",
    "        flops_subset_eval = 17_563_067_904 * metric_temp[\"num_subsets\"] * num_train_sample\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "             \"flops\": flops_subset_eval,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)\n",
    "\n",
    "for metric in metric_list_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\" for num_subsets in [512, 1024, 2048, 3072]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "            \n",
    "            \n",
    "        flops_subset_eval = 17_563_067_904 * num_train_sample * num_subsets\n",
    "        flops_forward = 21_335_153_664 * 1 * metric_temp[\"epoch\"] * num_train_sample\n",
    "        flops_backward = 21_335_153_664 * 2 * metric_temp[\"epoch\"] * num_train_sample    \n",
    "        flops_parameter_update = 104_730_000 * metric_temp[\"epoch\"] * (num_train_sample//64) * (2+3+4+3+3+4) # need to verify\n",
    "                \n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'{num_subsets}',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split,\n",
    "             \"flops\":  flops_subset_eval + flops_forward + flops_backward + flops_parameter_update,\n",
    "            }\n",
    "        )    \n",
    "    \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "            \n",
    "        flops_subset_eval = 17_563_067_904 * num_train_sample * num_subsets\n",
    "        flops_forward = 21_335_153_664 * 1 * metric_temp[\"epoch\"] * num_train_sample\n",
    "        flops_backward = 21_335_153_664 * 2 * metric_temp[\"epoch\"] * num_train_sample    \n",
    "        flops_parameter_update = 104_730_000 * metric_temp[\"epoch\"] * (num_train_sample//64) * (2+3+4+3+3+4) # need to verify            \n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (Permutation, {num_subsets})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": split,\n",
    "             \"flops\":  flops_subset_eval + flops_forward + flops_backward + flops_parameter_update,\n",
    "            }\n",
    "        )               \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_newsample_{num_subsets}\" for num_subsets in [32]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue   \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_antithetical_newsample_{num_subsets}\" for num_subsets in [32]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\" for num_subsets in [9986]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue         \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot.append(metric_temp)    \n",
    "    \n",
    "    \n",
    "\n",
    "metric_list_plot_df=pd.DataFrame(metric_list_plot)\n",
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892816e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_shapley)[\"model_path\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[[\"model_path\", \"antithetical\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f6641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97661c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b633ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "  (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "  (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "  (0,0,0)]) \n",
    "\n",
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df[\"is_best_checkpoint\"].fillna(\"before\")==\"before\")\\\n",
    "                                                          ]\n",
    "\n",
    "            \n",
    "\n",
    "                        \n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],    \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)   #labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Error')\n",
    "\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)\n",
    "\n",
    "\n",
    "\n",
    "        elif metric==\"pearsonr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                  \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr.\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #, labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Correlation')\n",
    "            \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            \n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)            \n",
    "            \n",
    "            \n",
    "         \n",
    "            \n",
    "\n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"spearmanr_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr.\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)#, labelsize=20)  \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_title('Rank Correlation')\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)             \n",
    "\n",
    "            \n",
    "        elif metric==\"sign_agreement_all\":\n",
    "\n",
    "            metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"sign_agreement_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Sign agreement\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)#, labelsize=20)  \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_title('Sign agreement')\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', \n",
    "                                     bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "                                     ncols=4,\n",
    "                                     #bbox_to_anchor=(1.0, 0, 0.5, 1)\n",
    "                                    )#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             import matplotlib.patches as mpatches\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             empty_handle = mpatches.Patch(color='none', label='Empty Label')\n",
    "#             labels.append('')\n",
    "#             leg=axd[plot_key].legend(handles=[empty_handle]+handles, labels=[\"\"]+labels, \n",
    "#                                  loc='center', \n",
    "#                                  bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "#                                  ncols=6,)              \n",
    "            handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "            \n",
    "            leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['512', '1024', '2048', '3072']], \n",
    "                                     labels=['512', '1024', '2048', '3072'], \n",
    "                                 loc='upper left', \n",
    "                                 bbox_to_anchor=(-2.3, -0.22, 3, 0),\n",
    "                                 ncols=4,)               \n",
    "            leg.set_title(\"Amortized (# Samples / Point)\")\n",
    "            axd[plot_key].add_artist(leg)\n",
    "            # Adding the text to the left of the first legend\n",
    "#             x_offset = -2.6  # Adjust this value as needed to position the text\n",
    "#             y_offset = -0.25  # Adjust this value as needed for vertical positioning\n",
    "#             axd[plot_key].text(x_offset, y_offset, \"Amortized (# Samples / Point)\", transform=axd[plot_key].transAxes, \n",
    "#                                verticalalignment='top', horizontalalignment='left')\n",
    "            \n",
    "            leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['KernelSHAP']], \n",
    "                                     labels=['KernelSHAP'], \n",
    "                                 loc='upper left', \n",
    "                                 bbox_to_anchor=(-0.8, -0.32, 3, 0),\n",
    "                                 ncols=4,)              \n",
    "            #\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)   \n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df_epoch=metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_epoch_appendix.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_epoch_appendix.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e7167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b747c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1b31c",
   "metadata": {},
   "source": [
    "# Error from prediction vs Error from targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_df[metric_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets\"])[['sample_idx',  \"num_subsets\", \n",
    "#         'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "#        'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f86636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prettify_metric_name(metric_name):\n",
    "#     if metric_name==\"mse_all\":\n",
    "#         return \"MSE (all classes)\"\n",
    "#     elif metric_name==\"pearsonr_all\":\n",
    "#         return \"Pearson corr. (all classes)\"\n",
    "#     elif metric_name==\"spearmanr_all\":\n",
    "#         return \"Spearman corr. (all classes)\"\n",
    "#     elif metric_name==\"pearsonr_all_per_class\":\n",
    "#         return \"Pearson corr. (Per classes)\"\n",
    "#     elif metric_name==\"spearmanr_all_per_class\":\n",
    "#         return \"Spearman corr. (Per classes)\"\n",
    "#     else:\n",
    "#         raise ValueError(metric_name)\n",
    "        \n",
    "def prettify_metric_name(metric_name):\n",
    "    if metric_name==\"mse_all\":\n",
    "        return \"Error\"\n",
    "    elif metric_name==\"pearsonr_all\":\n",
    "        return \"Correlation\"\n",
    "    elif metric_name==\"spearmanr_all\":\n",
    "        return \"Rank Correlation\"\n",
    "    elif metric_name==\"sign_agreement_all\":\n",
    "        return \"Sign Agreement\"    \n",
    "    elif metric_name==\"pearsonr_all_per_class\":\n",
    "        return \"Pearson corr. (Per classes)\"\n",
    "    elif metric_name==\"spearmanr_all_per_class\":\n",
    "        return \"Spearman corr. (Per classes)\"\n",
    "    else:\n",
    "        raise ValueError(metric_name)\n",
    "         \n",
    "        \n",
    "def prettify_method_type(method_type):\n",
    "    if method_type==\"KernelSHAP\":\n",
    "        return \"KernelSHAP\"\n",
    "    elif method_type==\"Permutation\":\n",
    "        return \"Permutation Sampling\"\n",
    "    elif method_type==\"SGD-Shapley\":\n",
    "        return \"SGD-Shapley\"  \n",
    "    elif method_type==\"BanzhafMSR\":\n",
    "        return \"Banzhaf (MSR)\"  \n",
    "    elif method_type==\"LIME\":\n",
    "        return \"LIME\"      \n",
    "    else:\n",
    "        raise ValueError(method_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1130052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_transform_mode(transform_mode):\n",
    "    if transform_mode==\"global\":\n",
    "        return \"\"\n",
    "    elif transform_mode==\"sqrt\":\n",
    "        return \"Sqrt\"       \n",
    "    elif transform_mode==\"perinstance\":\n",
    "        return \"Per-sample Norm.\"\n",
    "    elif transform_mode==\"perinstanceperclass\":\n",
    "        #return \"Per-sample/Per-class Norm.\"\n",
    "        return \"Per-Label Scaling\"\n",
    "    else:\n",
    "        raise ValueError(transform_mode)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_list_value_shapley_=[]\n",
    "# for num_subsets in [512, 1024, 2048, 3072]:\n",
    "#     metric_list_value_shapley_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "#                                                  })\n",
    "    \n",
    "#     metric_list_value_shapley_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                                    \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\",\n",
    "#                                                  })  \n",
    "\n",
    "# metric_list_plot_=[]\n",
    "# for metric in metric_list_value_shapley_:\n",
    "#     metric_temp=copy.copy(metric)\n",
    "    \n",
    "#     if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\" and\\\n",
    "#        metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "#         metric_temp.update(\n",
    "#             {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]})',\n",
    "#              \"method_type\": 'KernelSHAP',\n",
    "#              \"antithetical\": False\n",
    "#             }\n",
    "#         )\n",
    "        \n",
    "#     elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\" and\\\n",
    "#        metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "#         metric_temp.update(\n",
    "#             {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]}, antithetical)',\n",
    "#              \"method_type\": 'KernelSHAP',\n",
    "#              \"antithetical\": True\n",
    "#             }\n",
    "#         ) \n",
    "#     metric_list_plot_.append(metric_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_ground_truth_=[]\n",
    "\n",
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "    metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))    \n",
    "\n",
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "    metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "#     metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\",\n",
    "#                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\",\n",
    "#                                                  },\n",
    "                                                                \n",
    "#                                       ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\"].keys()).intersection(\n",
    "#                                       shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\"].keys()\n",
    "                                      \n",
    "#                                       ))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6]]:\n",
    "    metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09daf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6]]:\n",
    "    metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3142f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6]]:\n",
    "    metric_list_ground_truth_+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda7bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015bf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b22a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd5fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ec94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292451a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_reference_=[]\n",
    "for metric in metric_list_ground_truth_:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        #continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        #continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )          \n",
    "        \n",
    "    #\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical_/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        ) \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )         \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_reference_.append(metric_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_plot_reference_).groupby([\"true_name\", \"estimated_name\", \"num_subsets\"])[\"mse_all\"].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65293935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e592649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "200k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace12bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c514b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_plot_reference_temp).groupby([\"true_name\", \"estimated_name\", \"num_subsets\"])[\"mse_all\"].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0990bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af536a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_ground_truth_shapley=[]\n",
    "\n",
    "# for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "#     metric_list_ground_truth+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "#                                                  },\n",
    "                                                                \n",
    "#                                       ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()).intersection(\n",
    "#                                       shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"].keys()\n",
    "                                      \n",
    "#                                       ))    \n",
    "\n",
    "# for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "#     metric_list_ground_truth_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "#                                        iters_ground_truth=999424, \n",
    "#                                        attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"],\n",
    "#                                        iters_calculated=num_subsets,\n",
    "#                                        meta_info={\"num_subsets\": num_subsets,\n",
    "#                                                   \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "#                                                   \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "#                                                  },\n",
    "                                                                \n",
    "#                                       ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()).intersection(\n",
    "#                                       shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()\n",
    "                                      \n",
    "#                                       ))\n",
    "\n",
    "for num_subsets in [512*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]+list(range(512*20, 512*20*20, 512*20)):\n",
    "    metric_list_ground_truth_shapley+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                 },\n",
    "                                                                \n",
    "                                      ground_truth_key_select=set(shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()).intersection(\n",
    "                                      shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"].keys()\n",
    "                                      \n",
    "                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_reference=[]\n",
    "for metric in metric_list_ground_truth_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        continue\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )        \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_reference.append(metric_temp)\n",
    "\n",
    "metric_list_plot_target=[]\n",
    "for metric in metric_list_value_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Permutation ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"         \n",
    "            }\n",
    "        )\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\":\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'SGD-Shapley ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'SGD-Shapley',\n",
    "             \"antithetical\": True,\n",
    "             \"split\": \"train\"         \n",
    "            }\n",
    "        )        \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_target.append(metric_temp)\n",
    "    \n",
    "metric_list_plot_explainer=[]    \n",
    "for metric in metric_list_shapley:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\" for num_subsets in [512, 1024, 2048, 3072]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (KernelSHAP, {num_subsets})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )    \n",
    "    \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "            \n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (Permutation, {num_subsets})',\n",
    "             \"method_type\": 'Permutation',\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,\n",
    "             \"split\": split,\n",
    "            }\n",
    "        )   \n",
    "        \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_{num_subsets}\" for num_subsets in [196, 392, 588, 1176, 3136]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue\n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\" for num_subsets in [9986]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "            \n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (SGD-Shapley, {num_subsets})',\n",
    "             \"method_type\": 'SGD-Shapley',\n",
    "             \"antithetical\": True,\n",
    "             \"num_subsets\":num_subsets,\n",
    "             \"split\": split,\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_newsample_{num_subsets}\" for num_subsets in [32]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"logs/vitbase_imagenette_shapley_objexplainer_antithetical_newsample_{num_subsets}\" for num_subsets in [32]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\",\n",
    "                                   ]:\n",
    "        continue         \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()        \n",
    "        \n",
    "    metric_list_plot_explainer.append(metric_temp)\n",
    "\n",
    "\n",
    "metric_list_plot_explainer_df=pd.DataFrame(metric_list_plot_explainer)\n",
    "metric_list_plot_explainer_df[\"is_best_checkpoint\"][(metric_list_plot_explainer_df['method_type']==\"SGD-Shapley\")&\n",
    "                              (metric_list_plot_explainer_df['epoch']==20)\n",
    "                             ]=\"best\"\n",
    "metric_list_plot_explainer_df=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                                                           ]\n",
    "\n",
    "\n",
    "metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "metric_list_plot_target_df_=metric_list_plot_target_df.copy()\n",
    "metric_list_plot_target_df_[\"split\"]=\"test\"\n",
    "idx_mapping=dict(zip(np.random.RandomState(seed=42).permutation(list(range(9469)))[:100],\n",
    "list(range(100))))\n",
    "metric_list_plot_target_df_[\"sample_idx\"]=metric_list_plot_target_df_[\"sample_idx\"].map(lambda x: idx_mapping[x])\n",
    "\n",
    "metric_list_plot_df=metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "                          left_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )\n",
    "# sdsd\n",
    "# metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "# [['sample_idx',  \"num_subsets\", \n",
    "# 'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "# 'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T\n",
    "\n",
    "metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "[['sample_idx', \"num_subsets\", \n",
    "'mse_target_explainer', 'mse_target_target',\n",
    "'mse_nontarget_explainer', 'mse_nontarget_target',\n",
    "'mse_all_explainer', 'mse_all_target',\n",
    "'pearsonr_target_explainer', 'pearsonr_target_target', \n",
    "'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "'spearmanr_target_explainer', 'spearmanr_target_target',\n",
    "'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target', \n",
    "\"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean()#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba911e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=pd.DataFrame(metric_list_plot_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a0031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_list_plot_explainer_df=pd.DataFrame(metric_list_plot_explainer)\n",
    "# metric_list_plot_explainer_df[\"is_best_checkpoint\"][(metric_list_plot_explainer_df['method_type']==\"SGD-Shapley\")&\n",
    "#                               (metric_list_plot_explainer_df['epoch']==20)\n",
    "#                              ]=\"best\"\n",
    "# metric_list_plot_explainer_df=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "#                                                            ]\n",
    "\n",
    "\n",
    "\n",
    "# metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "# metric_list_plot_target_df_=metric_list_plot_target_df.copy()\n",
    "# metric_list_plot_target_df_[\"split\"]=\"test\"\n",
    "# idx_mapping=dict(zip(np.random.RandomState(seed=42).permutation(list(range(9469)))[:100],\n",
    "# list(range(100))))\n",
    "# metric_list_plot_target_df_[\"sample_idx\"]=metric_list_plot_target_df_[\"sample_idx\"].map(lambda x: idx_mapping[x])\n",
    "# metric_list_plot_target_df=pd.concat([metric_list_plot_target_df, metric_list_plot_target_df_])\n",
    "\n",
    "# metric_list_plot_df=metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "#                           left_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "#                           right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "#                           suffixes=('_explainer', '_target')\n",
    "#                          )\n",
    "# # sdsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fee1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"method_type\"]==method_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"method_type\"]==method_type]#[\"method_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(12, 7)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 3, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\"]):\n",
    "\n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&(metric_list_plot_df[\"method_type\"]==method_type)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_target_explainer', 'mse_target_target',\n",
    "                                    'mse_nontarget_explainer', 'mse_nontarget_target',\n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_target_explainer', 'pearsonr_target_target', \n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_target_explainer', 'spearmanr_target_target',\n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target']].mean().reset_index()          \n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "\n",
    "            if method_type==\"KernelSHAP\":\n",
    "                reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "                reference_df_idx_list=[]\n",
    "    #             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "    #                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "    #                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "                for idx, row in reference_df.iterrows():\n",
    "                    if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "                        reference_df_idx_list.append(idx)\n",
    "\n",
    "                count=0\n",
    "                for idx in sorted(list(set(reference_df_idx_list))):\n",
    "                    row=reference_df.loc[idx]\n",
    "                    axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "                                         x=row[metric_name], linewidth=1, color=list(sns.color_palette(\"Set2\"))[count],\n",
    "                                         label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "                    count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error from target\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error from prediction\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-3, right=1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-3, 1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            if method_type==\"KernelSHAP\":\n",
    "                reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "                reference_df_idx_list=[]\n",
    "    #             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "    #                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "    #                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "                for idx, row in reference_df.iterrows():\n",
    "                    if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "                        reference_df_idx_list.append(idx)                \n",
    "                count=0\n",
    "                for idx in sorted(list(set(reference_df_idx_list))):\n",
    "                    row=reference_df.loc[idx]\n",
    "                    axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "                                         x=row[metric_name], linewidth=1, color=list(sns.color_palette(\"Set2\"))[count],\n",
    "                                         label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "                    count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson corr. with target\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson corr. with prediction\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            if method_type==\"KernelSHAP\":\n",
    "\n",
    "                reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "                reference_df_idx_list=[]\n",
    "    #             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "    #                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "    #                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "                for idx, row in reference_df.iterrows():\n",
    "                    if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "                        reference_df_idx_list.append(idx)\n",
    "                count=0\n",
    "                for idx in sorted(list(set(reference_df_idx_list))):\n",
    "                    row=reference_df.loc[idx]\n",
    "                    axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "                                         x=row[metric_name], linewidth=1, color=list(sns.color_palette(\"Set2\"))[count],\n",
    "                                         label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "                    count+=1                \n",
    "\n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman corr. with target\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman corr. with prediction\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.2, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.set_title(\"# Samples / Point\")   \n",
    "            \n",
    "            for legend_text in leg.get_texts():\n",
    "                try:\n",
    "                    int(legend_text.get_text())\n",
    "                except:\n",
    "                    legend_text.set_text(f\"Reference ({legend_text.get_text()[-5:]})\")         \n",
    "                else:\n",
    "                    legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "                        \n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc9ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1268923",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_plot_reference)\\\n",
    ".groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70897c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_plot_reference)#[\"method_name\"]#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51445f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136)(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.8666666666666667*256, 0.5176470588235295*256, 0.3215686274509804*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e5907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "#                               ]):\n",
    "#     ax=plt.Subplot(fig, box1[idx1])\n",
    "#     fig.add_subplot(ax)\n",
    "\n",
    "#     plot_key=(idx1)\n",
    "#     axd[plot_key]=ax  \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax     \n",
    "\n",
    "\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "#                               ]):\n",
    "\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax    \n",
    "\n",
    "\n",
    "for idx1, metric in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "\n",
    "\n",
    "        if metric==\"each\":\n",
    "            sns.barplot(\n",
    "                x=\"mse_all\",\n",
    "                y=\"method_name\",\n",
    "            #     hue=\"method\",\n",
    "            #     style=\"AO type\",\n",
    "            #     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "                #palette=\"tab10\",\n",
    "                #marker='o',    \n",
    "                markeredgecolor=None,\n",
    "                #markersize=10,   \n",
    "                #alpha=0.8,            \n",
    "                #linewidth=3,\n",
    "                data=metric_list_plot_df[~metric_list_plot_df[\"method_name\"].str.contains(\"newsample\")],\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Method\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"MSE (all classes)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            # axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "            # axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "            # axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            # axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_xlim(0, 40)\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(1))\n",
    "            axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "    #         axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=-90, labelsize=20, labelright=True)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0, labelsize=10)  \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "    #         leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "    #         for line in leg.get_lines():\n",
    "    #             line.set_linewidth(3.0)  \n",
    "\n",
    "        elif metric==\"mse_all\":\n",
    "            sns.lineplot(\n",
    "                y=metric,\n",
    "                x=\"num_subsets\",\n",
    "                #style=\"antithetical\",\n",
    "                hue=\"method_type\",\n",
    "                palette=[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)],\n",
    "                #palette=\"tab10\",\n",
    "                #marker='o',    \n",
    "                markeredgecolor=None,\n",
    "                errorbar=None,\n",
    "                #markersize=10,   \n",
    "                #alpha=0.8,            \n",
    "                #linewidth=3,\n",
    "                data=pd.DataFrame(metric_list_plot_reference),\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "            metric_list_plot_explainer_df_mean=metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]\\\n",
    "            .groupby([\"method_name\", \"num_subsets\"])[metric].mean().reset_index().sort_values(\"num_subsets\").set_index(\"num_subsets\")\n",
    "            count=0\n",
    "            for num_subsets in metric_list_plot_explainer_df_mean.index:\n",
    "                row=metric_list_plot_explainer_df_mean.loc[num_subsets]\n",
    "                #print(row)\n",
    "                axd[plot_key].hlines(xmin=0, xmax=1000000, \n",
    "                                     y=row[metric], linewidth=2, color=Blue_scalar_color_mapping(num_subsets, color_map=plt.cm.Blues, data_min=-500, data_max=3136),\n",
    "                                     label=f'{num_subsets}')\n",
    "                count+=1                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_title(f\"Error\")# ({prettify_method_type(method_type)})\")\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Samples / Point (KernelSHAP)\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Error\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))  \n",
    "            axd[plot_key].get_xaxis().set_major_formatter(\n",
    "                mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))                        \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=0.5)#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0, 110001)\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))              \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0.0001, 0.015)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "\n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "    #         for line in leg.get_lines():\n",
    "    #             line.set_linewidth(3.0) \n",
    "\n",
    "        elif metric==\"pearsonr_all\":\n",
    "\n",
    "            sns.lineplot(\n",
    "                y=metric,\n",
    "                x=\"num_subsets\",\n",
    "                #style=\"antithetical\",\n",
    "                hue=\"method_type\",\n",
    "                palette=[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)],\n",
    "                #marker='o',    \n",
    "                markeredgecolor=None,\n",
    "                errorbar=None,\n",
    "                #markersize=10,   \n",
    "                #alpha=0.8,            \n",
    "                #linewidth=3,\n",
    "                data=pd.DataFrame(metric_list_plot_reference),\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "            metric_list_plot_explainer_df_mean=metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]\\\n",
    "            .groupby([\"method_name\", \"num_subsets\"])[metric].mean().reset_index().sort_values(\"num_subsets\").set_index(\"num_subsets\")\n",
    "            count=0\n",
    "            for num_subsets in metric_list_plot_explainer_df_mean.index:\n",
    "                row=metric_list_plot_explainer_df_mean.loc[num_subsets]\n",
    "                #print(row)\n",
    "                axd[plot_key].hlines(xmin=0, xmax=1000000, \n",
    "                                     y=row[metric], linewidth=2, color=Blue_scalar_color_mapping(num_subsets, color_map=plt.cm.Blues, data_min=-500, data_max=3136),\n",
    "                                     label=f'{num_subsets}')\n",
    "                count+=1                  \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_title(f\"Correlation\")# ({prettify_method_type(method_type)})\")\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Samples / Point (KernelSHAP)\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100)) \n",
    "            axd[plot_key].get_xaxis().set_major_formatter(\n",
    "                mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))                        \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0, 110001)\n",
    "\n",
    "            # yaxis\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "            leg.remove()\n",
    "    #         for line in leg.get_lines():\n",
    "    #             line.set_linewidth(3.0)  \n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "\n",
    "            sns.lineplot(\n",
    "                y=metric,\n",
    "                x=\"num_subsets\",\n",
    "                #style=\"antithetical\",\n",
    "                hue=\"method_type\",\n",
    "                palette=[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)],\n",
    "                #marker='o',    \n",
    "                markeredgecolor=None,\n",
    "                errorbar=None,\n",
    "                #markersize=10,   \n",
    "                #alpha=0.8,            \n",
    "                #linewidth=3,\n",
    "                data=pd.DataFrame(metric_list_plot_reference),\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "            metric_list_plot_explainer_df_mean=metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]\\\n",
    "            .groupby([\"method_name\", \"num_subsets\"])[metric].mean().reset_index().sort_values(\"num_subsets\").set_index(\"num_subsets\")\n",
    "            count=0\n",
    "            for num_subsets in metric_list_plot_explainer_df_mean.index:\n",
    "                row=metric_list_plot_explainer_df_mean.loc[num_subsets]\n",
    "                #print(row)\n",
    "                axd[plot_key].hlines(xmin=0, xmax=1000000, \n",
    "                                     y=row[metric], linewidth=2, color=Blue_scalar_color_mapping(num_subsets, color_map=plt.cm.Blues, data_min=-500, data_max=3136),\n",
    "                                     label=f'{num_subsets}')\n",
    "                count+=1                 \n",
    "\n",
    "\n",
    "            axd[plot_key].set_title(f\"Rank correlation\")# ({prettify_method_type(method_type)})\")\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Samples / Point (KernelSHAP)\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Spearman Correlation\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100)) \n",
    "            axd[plot_key].get_xaxis().set_major_formatter(\n",
    "                mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))                        \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0, 110001)\n",
    "\n",
    "            # yaxis\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "    #         for line in leg.get_lines():\n",
    "    #             line.set_linewidth(3.0)  \n",
    "\n",
    "\n",
    "        elif metric==\"sign_agreement_all\":\n",
    "\n",
    "            sns.lineplot(\n",
    "                y=metric,\n",
    "                x=\"num_subsets\",\n",
    "                #style=\"antithetical\",\n",
    "                hue=\"method_type\",\n",
    "                palette=[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)],\n",
    "                #marker='o',    \n",
    "                markeredgecolor=None,\n",
    "                errorbar=None,\n",
    "                #markersize=10,   \n",
    "                #alpha=0.8,            \n",
    "                #linewidth=3,\n",
    "                data=pd.DataFrame(metric_list_plot_reference),\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "\n",
    "            metric_list_plot_explainer_df_mean=metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]\\\n",
    "            .groupby([\"method_name\", \"num_subsets\"])[metric].mean().reset_index().sort_values(\"num_subsets\").set_index(\"num_subsets\")\n",
    "            count=0\n",
    "            for num_subsets in metric_list_plot_explainer_df_mean.index:\n",
    "                row=metric_list_plot_explainer_df_mean.loc[num_subsets]\n",
    "                #print(row)\n",
    "                axd[plot_key].hlines(xmin=0, xmax=1000000, \n",
    "                                     y=row[metric], linewidth=2, color=Blue_scalar_color_mapping(num_subsets, color_map=plt.cm.Blues, data_min=-500, data_max=3136),\n",
    "                                     label=f'{num_subsets}')\n",
    "                count+=1                 \n",
    "\n",
    "\n",
    "            axd[plot_key].set_title(f\"Sign Agreement\")# ({prettify_method_type(method_type)})\")#\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Samples / Point (KernelSHAP)\")#, fontsize=20)\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100)) \n",
    "            axd[plot_key].get_xaxis().set_major_formatter(\n",
    "                mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))                        \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0, 110001)\n",
    "\n",
    "            # yaxis\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=0.8, alpha=0.6)\n",
    "            axd[plot_key].yaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(0, 1.05)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  # , labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best')#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()            \n",
    "\n",
    "    #         for line in leg.get_lines():\n",
    "    #             line.set_linewidth(3.0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_prediction_contextualize.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_prediction_contextualize.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaa49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f95b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3529abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "            metric_list_plot_explainer_df_mean=metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]\\\n",
    "            .groupby([\"method_name\", \"num_subsets\"])[metric].mean().reset_index().sort_values(\"num_subsets\").set_index(\"num_subsets\")\n",
    "            count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d935b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df[metric_list_plot_explainer_df[\"method_type\"]==method_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf1810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcd9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"method_type\"]==method_type]\\\n",
    ".groupby([\"method_name\", \"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"method_type\"]==method_type]\\\n",
    ".columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51d455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437365e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d9122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324ca50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "\n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&(metric_list_plot_df[\"method_type\"]==method_type)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_target_explainer', 'mse_target_target',\n",
    "                                    'mse_nontarget_explainer', 'mse_nontarget_target',\n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_target_explainer', 'pearsonr_target_target', \n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_target_explainer', 'spearmanr_target_target',\n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()          \n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-3, right=1.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-3, 1.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #leg.set_title(\"# Samples / Point\")   \n",
    "            \n",
    "            for legend_text in leg.get_texts():\n",
    "                try:\n",
    "                    int(legend_text.get_text())\n",
    "                except:\n",
    "                    legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                else:\n",
    "                    legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "                        \n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "    \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f876989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_appendix.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_appendix.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\", \"SGD-Shapley\"]):\n",
    "\n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"method_type\"]==method_type)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_target_explainer', 'mse_target_target',\n",
    "                                    'mse_nontarget_explainer', 'mse_nontarget_target',\n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_target_explainer', 'pearsonr_target_target', \n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_target_explainer', 'spearmanr_target_target',\n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()          \n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-3, right=1.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-3, 1.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #leg.set_title(\"# Samples / Point\")   \n",
    "            \n",
    "            for legend_text in leg.get_texts():\n",
    "                try:\n",
    "                    int(legend_text.get_text())\n",
    "                except:\n",
    "                    legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                else:\n",
    "                    legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "                        \n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "    \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd26517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_external_appendix.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_external_appendix.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d7ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14411514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "def Blue_scalar_color_mapping(value, color_map, data_min, data_max):    \n",
    "    norm = mcolors.Normalize(vmin=data_min, vmax=data_max)\n",
    "    scalar_map = plt.cm.ScalarMappable(norm=norm, cmap=color_map)\n",
    "    return scalar_map.to_rgba(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74177049",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "# fig = plt.figure(figsize=(4*4 + 3*0.3, 3*4 + 2*0.8)\n",
    "#                 )\n",
    "fig = plt.figure(figsize=(4*4 + 3*0.2, 1*3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, wspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, method_type in enumerate([\"KernelSHAP\", \"Permutation\"]):\n",
    "     \n",
    "    for idx2, metric_name in enumerate([\"mse_all\", \"pearsonr_all\"]):\n",
    "        #box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1])#, wspace=0.2, hspace=0.1)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box1[idx1*2+idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\",\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\", \"Permutation\"]):\n",
    "\n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&(metric_list_plot_df[\"method_type\"]==method_type)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_target_explainer', 'mse_target_target',\n",
    "                                    'mse_nontarget_explainer', 'mse_nontarget_target',\n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_target_explainer', 'pearsonr_target_target', \n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_target_explainer', 'spearmanr_target_target',\n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()          \n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                #palette=[sns.color_palette(\"Blues\")[i] for i in [1,2,3,4,5]],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-3, right=1.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-3, 1.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', \n",
    "                                     bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #leg.set_title(\"# Samples / Point\")   \n",
    "            \n",
    "            for legend_text in leg.get_texts():\n",
    "                try:\n",
    "                    int(legend_text.get_text())\n",
    "                except:\n",
    "                    legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                else:\n",
    "                    legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "                        \n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "    \n",
    "            axd[plot_key].set_title(f\"{prettify_method_type(method_type)}\")#, fontsize=20)\n",
    "                        \n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                #palette=[sns.color_palette(\"Blues\")[i] for i in [1,2,3,4,5]],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(f\"{prettify_method_type(method_type)}\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Correlation with target\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Correlation with prediction\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_method_type(method_type)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Correlation with target\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Correlation with prediction\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c603cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_two.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_shapley_two.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc51ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18efda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4345976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade19db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504267f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfd76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28600530",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"][3126]\\\n",
    "[\"iters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"][3126]\\\n",
    "[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb04c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54907f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_ground_truth_banzahf=[]\n",
    "\n",
    "for num_subsets in [500*i for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 80, 100, 200, 400, 800, 1000]]:\n",
    "    metric_list_ground_truth_banzahf+=get_ground_truth_metric_with_value(attribution_values_ground_truth=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=banzhaf_loaded_dict[\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                                 },\n",
    "                                      )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_reference=[]\n",
    "for metric in metric_list_ground_truth_banzahf:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'BanzhafMSR',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_reference.append(metric_temp)\n",
    "\n",
    "    \n",
    "\n",
    "metric_list_plot_target=[]\n",
    "for metric in metric_list_value_banzhaf:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'BanzhafMSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_short/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'BanzhafMSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )          \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'BanzhafMSR ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"test\"\n",
    "            }\n",
    "        )          \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "        continue        \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_target.append(metric_temp)\n",
    "    \n",
    "metric_list_plot_explainer=[]    \n",
    "for metric in metric_list_banzhaf:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_global_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (BanzhafMSR, global, {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"transform_mode\": \"global\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_sqrt_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "\n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (BanzhafMSR, sqrt, {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"transform_mode\": \"sqrt\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_perinstance_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (BanzhafMSR, perinstance, {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"transform_mode\": \"perinstance\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )   \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_perinstanceperclass_{num_subsets}\" for num_subsets in [10, 100, 500]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (BanzhafMSR, perinstanceperclass, {num_subsets})',\n",
    "             \"method_type\": 'BanzhafMSR',\n",
    "             \"transform_mode\": \"perinstanceperclass\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )           \n",
    "\n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()        \n",
    "        \n",
    "    metric_list_plot_explainer.append(metric_temp)\n",
    "\n",
    "\n",
    "metric_list_plot_explainer_df=pd.DataFrame(metric_list_plot_explainer)\n",
    "metric_list_plot_explainer_df=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                                                           ]\n",
    "\n",
    "\n",
    "# metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "# metric_list_plot_target_df_=metric_list_plot_target_df.copy()\n",
    "# metric_list_plot_target_df_[\"split\"]=\"test\"\n",
    "# metric_list_plot_target_df=pd.concat([metric_list_plot_target_df, metric_list_plot_target_df_])\n",
    "\n",
    "metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "metric_list_plot_target_df_=metric_list_plot_target_df.copy()\n",
    "metric_list_plot_target_df_[\"split\"]=\"test\"\n",
    "idx_mapping=dict(zip(np.random.RandomState(seed=42).permutation(list(range(9469)))[:100],\n",
    "list(range(100))))\n",
    "metric_list_plot_target_df_[\"sample_idx\"]=metric_list_plot_target_df_[\"sample_idx\"].map(lambda x: idx_mapping[x])\n",
    "metric_list_plot_target_df=pd.concat([metric_list_plot_target_df, metric_list_plot_target_df_])\n",
    "\n",
    "metric_list_plot_df=metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "                          left_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )\n",
    "# sdsd\n",
    "# metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "# [['sample_idx',  \"num_subsets\", \n",
    "# 'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "# 'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T\n",
    "\n",
    "metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"transform_mode\" , \"num_subsets\"])\\\n",
    "[['sample_idx', \"num_subsets\", \n",
    "'mse_all_explainer', 'mse_all_target',\n",
    "'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target']].mean()#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e146d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_plot_explainer_df)[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_target_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a5de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):       \n",
    "        \n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&(metric_list_plot_df[\"transform_mode\"]==transform_mode)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()                  \n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-5, right=10.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-5, 10.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            if idx2==0:\n",
    "                leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "                #leg.set_title(\"# Samples / Point\")   \n",
    "\n",
    "                for legend_text in leg.get_texts():\n",
    "                    try:\n",
    "                        int(legend_text.get_text())\n",
    "                    except:\n",
    "                        legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                    else:\n",
    "                        legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "\n",
    "\n",
    "    #             for line in leg.get_lines():\n",
    "    #                 line.set_linewidth(3.0) \n",
    "                #leg.remove()\n",
    "\n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.set_title(\"# Samples / Point\")   \n",
    "            leg.remove()\n",
    "    \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e983b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_banzhaf.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_banzhaf.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e38ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1088f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):       \n",
    "        \n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"transform_mode\"]==transform_mode)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()                  \n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-5, right=10.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-5, 10.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            if idx2==0:\n",
    "                leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "                #leg.set_title(\"# Samples / Point\")   \n",
    "\n",
    "                for legend_text in leg.get_texts():\n",
    "                    try:\n",
    "                        int(legend_text.get_text())\n",
    "                    except:\n",
    "                        legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                    else:\n",
    "                        legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "\n",
    "\n",
    "    #             for line in leg.get_lines():\n",
    "    #                 line.set_linewidth(3.0) \n",
    "                #leg.remove()\n",
    "\n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-200, data_max=500) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.set_title(\"# Samples / Point\")   \n",
    "            leg.remove()\n",
    "    \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_banzhaf_external.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_banzhaf_external.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b998d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0aab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_ground_truth_lime=[]\n",
    "\n",
    "for num_subsets in [100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000]:\n",
    "    metric_list_ground_truth_lime+=get_ground_truth_metric_with_value(attribution_values_ground_truth=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"], \n",
    "                                       iters_ground_truth=1000000, \n",
    "                                       attribution_values_calculated=lime_loaded_dict[\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                                 },\n",
    "                                      )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_reference=[]\n",
    "for metric in metric_list_ground_truth_lime:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "        #continue\n",
    "        \n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'LIME',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_reference.append(metric_temp)\n",
    "\n",
    "    \n",
    "\n",
    "metric_list_plot_target=[]\n",
    "for metric in metric_list_value_lime:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    \n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_binomial_eval_train/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'LIME ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )   \n",
    "        \n",
    "    elif metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'LIME ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )           \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_target.append(metric_temp)\n",
    "    \n",
    "metric_list_plot_explainer=[]    \n",
    "for metric in metric_list_lime:\n",
    "    metric_temp=copy.copy(metric)\n",
    "\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_global_{num_subsets}\" for num_subsets in [128, 256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (LIME, global, {num_subsets})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"transform_mode\": \"global\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )  \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_sqrt_{num_subsets}\" for num_subsets in [128, 256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (LIME, sqrt, {num_subsets})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"transform_mode\": \"sqrt\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )   \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_perinstance_{num_subsets}\" for num_subsets in [256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (LIME, perinstance, {num_subsets})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"transform_mode\": \"perinstance\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )     \n",
    "        \n",
    "    elif metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_lime_regexplainer_upfront_perinstanceperclass_{num_subsets}\" for num_subsets in [256, 512]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_train_regression_long/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_lime_eval_test_regression_long/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (LIME, perinstanceperclass, {num_subsets})',\n",
    "             \"method_type\": 'LIME',\n",
    "             \"transform_mode\": \"perinstanceperclass\",\n",
    "             \"antithetical\": False,\n",
    "             \"num_subsets\":num_subsets,             \n",
    "             \"split\": split,\n",
    "            }\n",
    "        )          \n",
    "\n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()        \n",
    "        \n",
    "    metric_list_plot_explainer.append(metric_temp)\n",
    "\n",
    "\n",
    "metric_list_plot_explainer_df=pd.DataFrame(metric_list_plot_explainer)\n",
    "metric_list_plot_explainer_df=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                                                           ]\n",
    "\n",
    "# metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "\n",
    "metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "metric_list_plot_target_df_=metric_list_plot_target_df.copy()\n",
    "metric_list_plot_target_df_[\"split\"]=\"test\"\n",
    "idx_mapping=dict(zip(np.random.RandomState(seed=42).permutation(list(range(9469)))[:100],\n",
    "list(range(100))))\n",
    "metric_list_plot_target_df_[\"sample_idx\"]=metric_list_plot_target_df_[\"sample_idx\"].map(lambda x: idx_mapping[x])\n",
    "metric_list_plot_target_df=pd.concat([metric_list_plot_target_df, metric_list_plot_target_df_])\n",
    "\n",
    "metric_list_plot_df=metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "                          left_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )\n",
    "# sdsd\n",
    "# metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "# [['sample_idx',  \"num_subsets\", \n",
    "# 'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "# 'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T\n",
    "\n",
    "metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"transform_mode\" , \"num_subsets\"])\\\n",
    "[['sample_idx', \"num_subsets\", \n",
    "'mse_all_explainer', 'mse_all_target',\n",
    "'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target']].mean()#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):       \n",
    "        \n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"train\")&(metric_list_plot_df[\"transform_mode\"]==transform_mode)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()                  \n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-5, right=1.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-5, 1.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            if idx2==0:                \n",
    "                leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "                #leg.set_title(\"# Samples / Point\")   \n",
    "\n",
    "                for legend_text in leg.get_texts():\n",
    "                    try:\n",
    "                        int(legend_text.get_text())\n",
    "                    except:\n",
    "                        legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                    else:\n",
    "                        legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "\n",
    "\n",
    "    #             for line in leg.get_lines():\n",
    "    #                 line.set_linewidth(3.0) \n",
    "                #leg.remove()                \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "    \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_lime.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_lime.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 15)\n",
    "#                 )\n",
    "\n",
    "# box1 = gridspec.GridSpec(3, 1, hspace=0.3)\n",
    "\n",
    "# axd={}\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "     \n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "#         box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "#         ax=plt.Subplot(fig, box2[idx2])\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "#         axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "# for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \n",
    "#                               ]):\n",
    "#     for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "#         plot_key=(metric, method_type)\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(4*4+3*0.3, 3*4+2*0.8)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.4)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\",\n",
    "                              ]):\n",
    "    for idx2, transform_mode in enumerate([\"global\", \"perinstanceperclass\"]):       \n",
    "        \n",
    "        metric_list_plot_df_select=metric_list_plot_df[(metric_list_plot_df[\"split\"]==\"test\")&(metric_list_plot_df[\"transform_mode\"]==transform_mode)].groupby([\"method_type\", \"num_subsets\"])\\\n",
    "                                    [['sample_idx', # \"num_subsets\", \n",
    "                                    'mse_all_explainer', 'mse_all_target',\n",
    "                                    'pearsonr_all_explainer', 'pearsonr_all_target',\n",
    "                                    'pearsonr_all_per_class_explainer', 'pearsonr_all_per_class_target', \n",
    "                                    'spearmanr_all_explainer', 'spearmanr_all_target',\n",
    "                                    'spearmanr_all_per_class_explainer', 'spearmanr_all_per_class_target',\n",
    "                                     \"sign_agreement_all_explainer\", \"sign_agreement_all_target\"]].mean().reset_index()                  \n",
    "\n",
    "        plot_key=(metric_name, transform_mode)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                                \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "\n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Error (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Error (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor')#, linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(left=1e-5, right=1.1)\n",
    "            axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(1e-5, 1.1)\n",
    "            axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            \n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(3.0) \n",
    "                \n",
    "            if idx2==0:                \n",
    "                leg=axd[plot_key].legend(loc='lower right', bbox_to_anchor=(0.97, 0.03))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "                #leg.set_title(\"# Samples / Point\")   \n",
    "\n",
    "                for legend_text in leg.get_texts():\n",
    "                    try:\n",
    "                        int(legend_text.get_text())\n",
    "                    except:\n",
    "                        legend_text.set_text(f\"{prettify_method_type(method_type)} ({legend_text.get_text()[-5:]})\")         \n",
    "                    else:\n",
    "                        legend_text.set_text(f\"{int(legend_text.get_text())}\")\n",
    "\n",
    "\n",
    "    #             for line in leg.get_lines():\n",
    "    #                 line.set_linewidth(3.0) \n",
    "                #leg.remove()                \n",
    "                \n",
    "            #axd[plot_key].set_title(prettify_method_type(method_type)+ \" - \" + prettify_metric_name(metric_name))#, fontsize=20)\n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "            reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)                \n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                              \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Pearson Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Pearson Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            #axd[plot_key].text(x=1.1, y=1.1, s=method_type,  ha='center')\n",
    "            \n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Spearman Corr. (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Spearman Corr. (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "            \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x=metric_name+\"_explainer\", \n",
    "                y=metric_name+\"_target\", \n",
    "                hue=\"num_subsets\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                s=200,\n",
    "                #palette=[i[\"color\"] for i in list(plt.rcParams['axes.prop_cycle'])],\n",
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=0, data_max=512) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],                 \n",
    "                alpha=0.9,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "#             reference_df=pd.DataFrame(metric_list_plot_reference).groupby([\"method_name\",\"num_subsets\"])[metric_name].mean().reset_index().sort_values(\"num_subsets\")    \n",
    "#             reference_df_idx_list=[]\n",
    "#             for i, metric_value in metric_list_plot_df_select[metric_name+\"_explainer\"].items():\n",
    "#                 reference_df_idx_list.append((reference_df[metric_name]-metric_value)[(reference_df[metric_name]-metric_value)>0].idxmin())\n",
    "#                 reference_df_idx_list.append((metric_value-reference_df[metric_name])[(metric_value-reference_df[metric_name])>0].idxmin())   \n",
    "#             for idx, row in reference_df.iterrows():\n",
    "#                 if row[\"num_subsets\"] in [10240, 20480, 40960]:\n",
    "#                     reference_df_idx_list.append(idx)\n",
    "#             count=0\n",
    "#             for idx in sorted(list(set(reference_df_idx_list))):\n",
    "#                 row=reference_df.loc[idx]\n",
    "#                 axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "#                                      x=row[metric_name], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "#                                      label=f'{row[\"method_name\"]} {row[\"num_subsets\"]}')\n",
    "#                 count+=1                \n",
    "    \n",
    "            axd[plot_key].plot(np.linspace(0,1,100), np.linspace(0,1,100), color=\"grey\", alpha=0.5, linestyle='--')\n",
    "\n",
    "\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement (Label)\")#, fontsize=20)\n",
    "            axd[plot_key].set_xlabel(\"Sign Agreement (Prediction)\")#, fontsize=20)\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major')#, linewidth=2, alpha=0.6)\n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_xlim(0,1.01)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major')#, linewidth=2, alpha=0.6\n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "            axd[plot_key].set_ylim(0,1.01)\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False)             \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.1, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "            #leg.remove()\n",
    "    \n",
    "            if prettify_transform_mode(transform_mode)==\"\":\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)}\")#, fontsize=20)\n",
    "            else:\n",
    "                axd[plot_key].set_title(f\"{prettify_metric_name(metric_name)} ({prettify_transform_mode(transform_mode)})\")#, fontsize=20)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_lime_external.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"training_target_prediction_lime_external.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140fc933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c662d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24cb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b275b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=pd.DataFrame(metric_list_plot_explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf274b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[temp_df[\"is_best_checkpoint\"]==\"best\"][[\"model_path\", \"epoch\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79877ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510dd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs/vitbase_imagenette_shapley_regexplainer_upfront_512\"+\"/trainer_state.json\") as f:\n",
    "    trainer_state = json.load(f)\n",
    "print(trainer_state[\"best_model_checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_subsets, checkpoint_path in {\n",
    "#     512: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_512/checkpoint-888\",\n",
    "#     1024: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_1024/checkpoint-1036\",\n",
    "#     1536: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_1536/checkpoint-1480\",\n",
    "#     2048: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_2048/checkpoint-1480\",\n",
    "#     3072: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_3072/checkpoint-1924\",\n",
    "# }.items():\n",
    "    \n",
    "\n",
    "#     with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "#         trainer_state = json.load(f)\n",
    "#     num_epoch=int(trainer_state[\"epoch\"])\n",
    "    \n",
    "#     print(checkpoint_path, num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daef42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf60679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8c126e",
   "metadata": {},
   "source": [
    "# compute-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_flops=[]\n",
    "\n",
    "for num_train in [100, 250, 500, 1000, 2000, 5000]:\n",
    "\n",
    "    model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_upfront_2257_numtrain_{num_train}\"\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+f\"/checkpoint-{int(get_best_model_checkpoint(model_path).split('-')[-1])}\"), key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[:50]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "        metric_list_flops+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"test\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                          })\n",
    "\n",
    "\n",
    "        metric_list_flops+=get_ground_truth_metric_with_explainer(attribution_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                explainer=regexplainer,\n",
    "                                dataset=dataset_explainer[\"train\"],\n",
    "                                iters_ground_truth=999424,\n",
    "                                meta_info={\n",
    "                                           \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                           \"model_path\": model_path,\n",
    "                                           \"epoch\": int(checkpoint_trainer_state[\"epoch\"]),\n",
    "                                           \"is_best_checkpoint\": \n",
    "                                            compare_checkpoint_value(current_checkpoint=int(checkpoint_path.split('-')[-1]), \n",
    "                                                                     best_checkpoint=int(get_best_model_checkpoint(model_path).split('-')[-1]))\n",
    "                                          })        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ee7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440\"]\\\n",
    "=load_attribution(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\",\n",
    "             target_subset_size=2440,\n",
    "                  attribution_name=\"shapley\",\n",
    "sample_select=np.random.RandomState(seed=42).permutation(list(range(9469)))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value_flops_matched=[]\n",
    "num_subsets=2440\n",
    "for i in range(1):\n",
    "    shapley_loaded_dict_temp={}\n",
    "    for sample_idx, tracking_dict in shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440\"].items():\n",
    "        shapley_loaded_dict_temp[sample_idx]=tracking_dict[i]\n",
    "\n",
    "    metric_list_value_flops_matched+=get_ground_truth_metric_with_value(attribution_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       attribution_values_calculated=shapley_loaded_dict_temp,\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"num_subsets\": num_subsets,\n",
    "                                                  \"true_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                                  \"estimated_name\": \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440\",\n",
    "                                                 }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_target=[]\n",
    "for metric in metric_list_value_flops_matched:\n",
    "    metric_temp=copy.copy(metric)\n",
    "\n",
    "    if metric_temp[\"estimated_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440\" and\\\n",
    "       metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'KernelSHAP ({metric_temp[\"num_subsets\"]})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"split\": \"train\"\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()\n",
    "        \n",
    "    metric_list_plot_target.append(metric_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26faf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_value_flops)[\"estimated_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_flops)[\"model_path\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer=[]    \n",
    "for metric in metric_list_flops:\n",
    "    metric_temp=copy.copy(metric)\n",
    "    \n",
    "    if metric_temp[\"model_path\"] in [f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_shapley_regexplainer_upfront_2257_numtrain_{num_train}\" for num_train in [100, 250, 500, 1000, 2000, 5000]] and\\\n",
    "       metric_temp[\"true_name\"] in [\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\",\n",
    "                                    \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\",\n",
    "                                   ]:\n",
    "        num_train=int(metric_temp[\"model_path\"].split('_')[-1])\n",
    "        if num_train<250:\n",
    "            continue\n",
    "        \n",
    "        num_subsets=int(metric_temp[\"model_path\"].split('_')[-3])\n",
    "        num_subsets_per_sample={2257:2440}[num_subsets]\n",
    "        \n",
    "        if metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\":\n",
    "            split=\"train\"\n",
    "        elif metric_temp[\"true_name\"]==\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression/extract_output/test\":\n",
    "            split=\"test\"\n",
    "        else:\n",
    "            print(metric_temp)\n",
    "            raise RuntimError()\n",
    "            \n",
    "                \n",
    "\n",
    "        metric_temp.update(\n",
    "            {\"method_name\": f'Reg-AO (KernelSHAP, {num_subsets})',\n",
    "             \"method_type\": 'KernelSHAP',\n",
    "             \"antithetical\": False,\n",
    "             \"num_train\":num_train, \n",
    "             \"num_subsets\": num_subsets,\n",
    "             \"num_subsets_per_sample\":num_subsets_per_sample,\n",
    "             \"split\": split,\n",
    "            }\n",
    "        )    \n",
    "        \n",
    "        metric_list_plot.append(metric_temp)\n",
    "        \n",
    "    else:\n",
    "        print(metric_temp)\n",
    "        raise RuntimError()        \n",
    "        \n",
    "    metric_list_plot_explainer.append(metric_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0706f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df=pd.DataFrame(metric_list_plot_explainer)\n",
    "metric_list_plot_explainer_df=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")|\n",
    "                                                            (metric_list_plot_explainer_df[\"method_type\"]==\"KernelSHAP\")\n",
    "                                                           \n",
    "                                                           ]\n",
    "\n",
    "metric_list_plot_target_df=pd.DataFrame(metric_list_plot_target)\n",
    "\n",
    "metric_list_plot_df=metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "                          left_on=[\"method_type\", \"sample_idx\", \"num_subsets_per_sample\", \"split\"],\n",
    "                          right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )\n",
    "metric_list_plot_df[metric_list_plot_df[\"split\"]==\"train\"].groupby([\"method_type\", \"num_subsets_per_sample\", \"num_train\"])[[\\\n",
    "        'sample_idx',  \"num_subsets_per_sample\", \n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e832cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_target_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac26772",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df.merge(right=metric_list_plot_target_df, \n",
    "                          left_on=[\"method_type\", \"sample_idx\", \"num_subsets_per_sample\", \"split\"],\n",
    "                          right_on=[\"method_type\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f49505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45474a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01060bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dac270",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_df[metric_list_plot_df[\"method_name\"]==\"KernelSHAP\"][\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5e2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a94f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a706509",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")&(metric_list_plot_df[\"method_type\"]==method_type)].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8dd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['legend.fancybox'] = False\n",
    "# plt.rcParams['legend.edgecolor']='1.0'\n",
    "# plt.rcParams['legend.framealpha']=1\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "  (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "  (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "  (0,0,0)]) \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "        \n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)])          \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class',]\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )            \n",
    "            \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, .045)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0,  labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "        \n",
    "        \n",
    "        \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(\"mse_all\"))#, fontsize=20)\n",
    "        \n",
    "            from matplotlib.lines import Line2D\n",
    "\n",
    "            custom_lines = [Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1], lw=1, linestyle=\"-\")]\n",
    "\n",
    "            axd[plot_key].legend(custom_lines, ['Amortized', 'KernelSHAP'], \n",
    "                                 #ncols=2,\n",
    "                                 loc='best', \n",
    "                                 #bbox_to_anchor=(-0.6, -1.3, 0.5, 1)\n",
    "                                 bbox_to_anchor=(0, 0, 1, 1)\n",
    "                                )\n",
    "            #bbox_to_anchor=(-0.8, -0.32, 3, 0),             \n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()            \n",
    "        \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "\n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\", ) #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor',alpha=0.1) # linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=2, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            #leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #handles_, labels_ = axd[plot_key].get_legend_handles_labels()\n",
    "            #print(handles_)\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) # labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#             leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             handles.append(handles_[0])\n",
    "#             labels.append(labels_[0])\n",
    "#             leg._legend_box = None\n",
    "#             leg._init_legend_box(handles, labels)\n",
    "#             leg._set_loc(leg._loc)   \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "    \n",
    "            \n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "\n",
    "        \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class',\n",
    "                                                    \"sign_agreement_all\"]\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            #leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #handles_, labels_ = axd[plot_key].get_legend_handles_labels()\n",
    "            #print(handles_)\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class',\n",
    "                                    'sign_agreement_all']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) # linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor',  alpha=0.1) #linewidth=1,\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) # labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#             leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             handles.append(handles_[0])\n",
    "#             labels.append(labels_[0])\n",
    "#             leg._legend_box = None\n",
    "#             leg._init_legend_box(handles, labels)\n",
    "#             leg._set_loc(leg._loc)   \n",
    "            \n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)   \n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180af3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_trainsamples.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_trainsamples.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4519e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['legend.fancybox'] = False\n",
    "# plt.rcParams['legend.edgecolor']='1.0'\n",
    "# plt.rcParams['legend.framealpha']=1\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "  (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "  (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "  (0,0,0)]) \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "        \n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    " (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)])          \n",
    "\n",
    "for idx1, metric_name in enumerate([\"mse_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "        plot_key=(metric_name, method_type)\n",
    "        \n",
    "        if metric_name==\"mse_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"test\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class',]\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )            \n",
    "            \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, .045)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0,  labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "        \n",
    "        \n",
    "        \n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(\"mse_all\"))#, fontsize=20)\n",
    "        \n",
    "            from matplotlib.lines import Line2D\n",
    "\n",
    "            custom_lines = [Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1], lw=1, linestyle=\"-\")]\n",
    "\n",
    "            axd[plot_key].legend(custom_lines, ['Amortized', 'KernelSHAP'], \n",
    "                                 #ncols=2,\n",
    "                                 loc='best', \n",
    "                                 #bbox_to_anchor=(-0.6, -1.3, 0.5, 1)\n",
    "                                 bbox_to_anchor=(0, 0, 1, 1)\n",
    "                                )\n",
    "            #bbox_to_anchor=(-0.8, -0.32, 3, 0),             \n",
    "\n",
    "\n",
    "        elif metric_name==\"pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"test\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()            \n",
    "        \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "\n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\", ) #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor',alpha=0.1) # linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=2, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "\n",
    "\n",
    "        elif metric_name==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"test\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            #leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #handles_, labels_ = axd[plot_key].get_legend_handles_labels()\n",
    "            #print(handles_)\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) # labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#             leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             handles.append(handles_[0])\n",
    "#             labels.append(labels_[0])\n",
    "#             leg._legend_box = None\n",
    "#             leg._init_legend_box(handles, labels)\n",
    "#             leg._set_loc(leg._loc)   \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "    \n",
    "            \n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "\n",
    "        \n",
    "        elif metric_name==\"sign_agreement_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"test\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class',\n",
    "                                                    \"sign_agreement_all\"]\n",
    "                                                    ].mean().reset_index()\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=metric_name, \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            #leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            #handles_, labels_ = axd[plot_key].get_legend_handles_labels()\n",
    "            #print(handles_)\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class',\n",
    "                                    'sign_agreement_all']].mean().loc[metric_name], \n",
    "                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) # linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor',  alpha=0.1) #linewidth=1,\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) # labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "#             leg=axd[plot_key].legend(loc='center', bbox_to_anchor=(1.0, 0, 0.5, 1))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             handles.append(handles_[0])\n",
    "#             labels.append(labels_[0])\n",
    "#             leg._legend_box = None\n",
    "#             leg._init_legend_box(handles, labels)\n",
    "#             leg._set_loc(leg._loc)   \n",
    "            \n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(metric_name))#, fontsize=20)\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)   \n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_trainsamples_external.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute_trainsamples_external.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5842e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba5b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc3c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aad566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f847f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['legend.fancybox'] = False\n",
    "# plt.rcParams['legend.edgecolor']='1.0'\n",
    "# plt.rcParams['legend.framealpha']=1\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "  (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "  (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "  (0,0,0)]) \n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                                                 for i in [512, 1024, 2048, 3072]]+[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)])\n",
    "\n",
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"MSE_all\", \"pearsonr_all\", \"spearmanr_all\", \"sign_agreement_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\")==\"before\")\\\n",
    "                                                          ]\n",
    "\n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"mse_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"mse_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"mse_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"mse_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()\n",
    "\n",
    "                        \n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072', \"KernelSHAP\"],    \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(top=0.08, bottom=0.00008)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)   #labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Error')\n",
    "\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)            \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='center', \n",
    "                                     bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "                                     ncols=4,\n",
    "                                     #bbox_to_anchor=(1.0, 0, 0.5, 1)\n",
    "                                    )#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             import matplotlib.patches as mpatches\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             empty_handle = mpatches.Patch(color='none', label='Empty Label')\n",
    "#             labels.append('')\n",
    "#             leg=axd[plot_key].legend(handles=[empty_handle]+handles, labels=[\"\"]+labels, \n",
    "#                                  loc='center', \n",
    "#                                  bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "#                                  ncols=6,)              \n",
    "            handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "            \n",
    "#             leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['512', '1024', '2048', '3072']], \n",
    "#                                      labels=['512', '1024', '2048', '3072'], \n",
    "#                                  loc='upper left', \n",
    "#                                  bbox_to_anchor=(0,0,1,1),\n",
    "#                                  ncols=1,) \n",
    "            #leg.set_title(\"Amortized (# Samples / Point)\")\n",
    "            axd[plot_key].add_artist(leg)\n",
    "            # Adding the text to the left of the first legend\n",
    "#             x_offset = -2.6  # Adjust this value as needed to position the text\n",
    "#             y_offset = -0.25  # Adjust this value as needed for vertical positioning\n",
    "#             axd[plot_key].text(x_offset, y_offset, \"Amortized (# Samples / Point)\", transform=axd[plot_key].transAxes, \n",
    "#                                verticalalignment='top', horizontalalignment='left')\n",
    "            \n",
    "            leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['512', '2048', 'KernelSHAP', '1024','3072']],  #512 2048, KernelSHAP, 1024, 3072\n",
    "                                     #labels=['512 Samples', '1024 Samples', '2048 Samples', '3072 Samples','KernelSHAP'], \n",
    "                                     labels=['512', '2048', 'KernelSHAP', '1024', '3072'], \n",
    "                                 loc='upper left', \n",
    "                                 bbox_to_anchor=(0, 0.05, 0.5, 0.3))\n",
    "#                                  columnspacing=1,\n",
    "#                                  #loc='best',\n",
    "#                                  #bbox_to_anchor=(0, 0, 1, 1),                                     \n",
    "#                                  ncols=2,)\n",
    "            leg.remove()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            from matplotlib.lines import Line2D\n",
    "            import matplotlib.lines as mlines\n",
    "            from matplotlib.legend_handler import HandlerBase\n",
    "\n",
    "            class CustomHandler(HandlerBase):\n",
    "                def create_artists(self, legend, orig_handle, x0, y0, width, height, fontsize, trans):\n",
    "                    if orig_handle.get_color()==\"black\":\n",
    "                        line_o = mlines.Line2D([x0, x0 + width], [y0 + height/2., y0 + height/2.], \n",
    "                                               linestyle='-', color=orig_handle.get_color())                        \n",
    "                        return [line_o]\n",
    "                    else:\n",
    "                        # Create a line with the 'o' marker\n",
    "                        line_o = mlines.Line2D([x0, x0 + width], [y0 + height/2., y0 + height/2.], \n",
    "                                               linewidth=0.8,\n",
    "                                               linestyle='-', color=orig_handle.get_color())\n",
    "                        # Create a line with the 'X' marker\n",
    "                        marker_o = mlines.Line2D([x0 + width], [y0 + height/2.], \n",
    "                                               linestyle='', color=orig_handle.get_color(), marker='o', markersize=5)\n",
    "#                         marker_x = mlines.Line2D([x0], [y0 + height/2.], \n",
    "#                                                linestyle='', color=orig_handle.get_color(), marker='X', markersize=5)                    \n",
    "                        return [line_o, marker_o]            \n",
    "\n",
    "            custom_lines = [Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][2], lw=1),\n",
    "                            Line2D([0], [0], color='black', lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][3], lw=1),\n",
    "                            ]\n",
    "\n",
    "            axd[plot_key].legend(custom_lines, ['512', '2048','KernelSHAP', '1024', '3072', ], \n",
    "                                 ncols=2,\n",
    "                                 loc='upper left', \n",
    "                                 handler_map={mlines.Line2D: CustomHandler()}, \n",
    "                                 #bbox_to_anchor=(-0.6, -1.3, 0.5, 1)\n",
    "                                 bbox_to_anchor=(0, 0.05, 0.5, 0.3),\n",
    "                                 columnspacing=0.5,\n",
    "                                )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        elif metric==\"pearsonr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"pearsonr_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"pearsonr_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()            \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                  \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #, labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Correlation')\n",
    "            \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            \n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "        elif metric==\"spearmanr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"spearmanr_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"spearmanr_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"pearsonr_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()            \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"spearmanr_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                  \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Spearman Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #, labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Rank Correlation')\n",
    "            \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            \n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif metric==\"sign_agreement_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"sign_agreement_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"sign_agreement_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"pearsonr_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()            \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"sign_agreement_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                  \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Sign Agreement\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #, labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Sign Agrement')\n",
    "            \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            \n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()            \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)   \n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"flops_matched_appendix.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"flops_matched_appendix.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbe281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['legend.fancybox'] = False\n",
    "# plt.rcParams['legend.edgecolor']='1.0'\n",
    "# plt.rcParams['legend.framealpha']=1\n",
    "plt.rcParams['legend.fancybox'] = True\n",
    "plt.rcParams['legend.edgecolor']='0.8'\n",
    "plt.rcParams['legend.framealpha']=0.8\n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "  (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "  (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "  (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "  (0,0,0)]) \n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[sns.color_palette(\"Blues\")[i] for i in [1,2,3,4]]+\\\n",
    "                                           #[(0,0,0)]\n",
    "                                            [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "                                          ) \n",
    "\n",
    "plt.rcParams['axes.prop_cycle']=plt.cycler(color=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                                                 for i in [512, 1024, 2048, 3072]]+[(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)])\n",
    "\n",
    "fig = plt.figure(figsize=(4*(4.3), 3)\n",
    "                )\n",
    "\n",
    "box1 = gridspec.GridSpec(1, 4, hspace=0.3)\n",
    "\n",
    "axd={}\n",
    "for idx1, metric in enumerate([\"epoch_MSE_all\", \"epoch_pearsonr_all\", \"trainsamples_MSE_all\", \"trainsamples_pearsonr_all\"\n",
    "                              ]):\n",
    "     \n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=box1[idx1], wspace=0.8, hspace=0.0)    \n",
    "\n",
    "        ax=plt.Subplot(fig, box2[idx2])\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        axd[plot_key]=ax          \n",
    "        \n",
    "\n",
    "for idx1, metric in enumerate([\"epoch_MSE_all\", \"epoch_pearsonr_all\", \"trainsamples_MSE_all\", \"trainsamples_pearsonr_all\"\n",
    "                              ]):\n",
    "    for idx2, method_type in enumerate([\"KernelSHAP\"]):\n",
    "\n",
    "        plot_key=(metric, method_type)\n",
    "        \n",
    "        if metric==\"epoch_MSE_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\")==\"before\")\\\n",
    "                                                          ]\n",
    "\n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"mse_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"mse_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"mse_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"mse_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()\n",
    "\n",
    "                        \n",
    "            \n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"mse_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072', \"KernelSHAP\"],    \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) # linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].set_ylim(top=0.08, bottom=0.00008)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)   #labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Error')\n",
    "\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)            \n",
    "            \n",
    "            leg=axd[plot_key].legend(loc='center', \n",
    "                                     bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "                                     ncols=4,\n",
    "                                     #bbox_to_anchor=(1.0, 0, 0.5, 1)\n",
    "                                    )#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "#             import matplotlib.patches as mpatches\n",
    "#             handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "#             empty_handle = mpatches.Patch(color='none', label='Empty Label')\n",
    "#             labels.append('')\n",
    "#             leg=axd[plot_key].legend(handles=[empty_handle]+handles, labels=[\"\"]+labels, \n",
    "#                                  loc='center', \n",
    "#                                  bbox_to_anchor=(-3.0, -0.35, 3, 0),\n",
    "#                                  ncols=6,)              \n",
    "            handles, labels = axd[plot_key].get_legend_handles_labels()\n",
    "            \n",
    "#             leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['512', '1024', '2048', '3072']], \n",
    "#                                      labels=['512', '1024', '2048', '3072'], \n",
    "#                                  loc='upper left', \n",
    "#                                  bbox_to_anchor=(0,0,1,1),\n",
    "#                                  ncols=1,) \n",
    "            #leg.set_title(\"Amortized (# Samples / Point)\")\n",
    "            axd[plot_key].add_artist(leg)\n",
    "            # Adding the text to the left of the first legend\n",
    "#             x_offset = -2.6  # Adjust this value as needed to position the text\n",
    "#             y_offset = -0.25  # Adjust this value as needed for vertical positioning\n",
    "#             axd[plot_key].text(x_offset, y_offset, \"Amortized (# Samples / Point)\", transform=axd[plot_key].transAxes, \n",
    "#                                verticalalignment='top', horizontalalignment='left')\n",
    "            \n",
    "            leg=axd[plot_key].legend(handles=[handles[labels.index(i)] for i in ['512', '2048', 'KernelSHAP', '1024','3072']],  #512 2048, KernelSHAP, 1024, 3072\n",
    "                                     #labels=['512 Samples', '1024 Samples', '2048 Samples', '3072 Samples','KernelSHAP'], \n",
    "                                     labels=['512', '2048', 'KernelSHAP', '1024', '3072'], \n",
    "                                 loc='upper left', \n",
    "                                 bbox_to_anchor=(0, 0.05, 0.5, 0.3))\n",
    "#                                  columnspacing=1,\n",
    "#                                  #loc='best',\n",
    "#                                  #bbox_to_anchor=(0, 0, 1, 1),                                     \n",
    "#                                  ncols=2,)\n",
    "            leg.remove()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            from matplotlib.lines import Line2D\n",
    "            import matplotlib.lines as mlines\n",
    "            from matplotlib.legend_handler import HandlerBase\n",
    "\n",
    "            class CustomHandler(HandlerBase):\n",
    "                def create_artists(self, legend, orig_handle, x0, y0, width, height, fontsize, trans):\n",
    "                    if orig_handle.get_color()==\"black\":\n",
    "                        line_o = mlines.Line2D([x0, x0 + width], [y0 + height/2., y0 + height/2.], \n",
    "                                               linestyle='-', color=orig_handle.get_color())                        \n",
    "                        return [line_o]\n",
    "                    else:\n",
    "                        # Create a line with the 'o' marker\n",
    "                        line_o = mlines.Line2D([x0, x0 + width], [y0 + height/2., y0 + height/2.], \n",
    "                                               linewidth=0.8,\n",
    "                                               linestyle='-', color=orig_handle.get_color())\n",
    "                        # Create a line with the 'X' marker\n",
    "                        marker_o = mlines.Line2D([x0 + width], [y0 + height/2.], \n",
    "                                               linestyle='', color=orig_handle.get_color(), marker='o', markersize=5)\n",
    "#                         marker_x = mlines.Line2D([x0], [y0 + height/2.], \n",
    "#                                                linestyle='', color=orig_handle.get_color(), marker='X', markersize=5)                    \n",
    "                        return [line_o, marker_o]            \n",
    "\n",
    "            custom_lines = [Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][2], lw=1),\n",
    "                            Line2D([0], [0], color='black', lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][3], lw=1),\n",
    "                            ]\n",
    "\n",
    "            axd[plot_key].legend(custom_lines, ['512', '2048','KernelSHAP', '1024', '3072', ], \n",
    "                                 ncols=2,\n",
    "                                 loc='upper left', \n",
    "                                 handler_map={mlines.Line2D: CustomHandler()}, \n",
    "                                 #bbox_to_anchor=(-0.6, -1.3, 0.5, 1)\n",
    "                                 bbox_to_anchor=(0, 0.05, 0.5, 0.3),\n",
    "                                )            \n",
    "\n",
    "        elif metric==\"epoch_pearsonr_all\":\n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_df_epoch[(metric_list_plot_df_epoch[\"split\"]==\"train\")&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"method_type\"]==method_type)&\\\n",
    "                                                           (metric_list_plot_df_epoch[\"is_best_checkpoint\"].fillna(\"before\").isin([\"before\", \"best\"]))\\\n",
    "                                                          ]\n",
    "            \n",
    "            \n",
    "            sns.scatterplot(\n",
    "            x=\"flops\",\n",
    "            y=\"pearsonr_all\",\n",
    "            hue=\"method_name\",\n",
    "            hue_order=[\n",
    "                     '512',\n",
    "                     '1024',\n",
    "                     '2048',\n",
    "                     '3072',\n",
    "                        'KernelSHAP',],      \n",
    "            data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[-1])\n",
    "                                                                     ).reset_index(),\n",
    "            ax=axd[plot_key],\n",
    "                s=40,\n",
    "\n",
    "            )     \n",
    "            axd[plot_key].get_legend().remove()\n",
    "            \n",
    "#             sns.scatterplot(\n",
    "#             x=\"flops\",\n",
    "#             y=\"pearsonr_all\",\n",
    "#             hue=\"method_name\",\n",
    "#             hue_order=[\n",
    "#                      '512',\n",
    "#                      '1024',\n",
    "#                      '2048',\n",
    "#                      '3072',],      \n",
    "#             data=metric_list_plot_df_select.groupby([\"method_name\"]).apply(lambda x: (x.groupby(\"flops\")[\"pearsonr_all\"].mean().sort_index().reset_index().iloc[0])\n",
    "#                                                                      ).reset_index(),\n",
    "#             ax=axd[plot_key],\n",
    "#                 s=40,\n",
    "#                 style=True,\n",
    "#                 markers=[\"X\"]\n",
    "\n",
    "#             )     \n",
    "#             axd[plot_key].get_legend().remove()            \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"flops\",\n",
    "                y=\"pearsonr_all\",\n",
    "                hue=\"method_name\",\n",
    "                hue_order=[\n",
    "                         '512',\n",
    "                         '1024',\n",
    "                         '2048',\n",
    "                         '3072',\n",
    "                            'KernelSHAP',],                  \n",
    "                #style=\"antithetical\",\n",
    "                #palette=\"tab10\",\n",
    "                errorbar=None,                \n",
    "                alpha=0.8,            \n",
    "                linewidth=1.5,\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key]\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            axd[plot_key].set_xlabel(\"FLOPs\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].ticklabel_format(axis='x',style='sci',useOffset=True)            \n",
    "            axd[plot_key].set_xlim(1e+16, 2e+19)\n",
    "            axd[plot_key].set_xscale('log')\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            #axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0) #, labelsize=20\n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale('log')\n",
    "            \n",
    "            axd[plot_key].set_title('Correlation')\n",
    "            \n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "                \n",
    "            \n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            #leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.5, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            axd[plot_key].get_legend().remove()\n",
    "\n",
    "\n",
    "\n",
    "        elif metric==\"trainsamples_MSE_all\":\n",
    "#             plt.rcParams['axes.prop_cycle']=plt.cycler(color=\\\n",
    "#                 [(0,0,1),\n",
    "#                  (0,0,0)])        \n",
    "            plt.rcParams['axes.prop_cycle']=plt.cycler(color=[sns.color_palette(\"Blues\")[i] for i in [4]]+\\\n",
    "                                                       #[(0,0,0)]\n",
    "                                                       [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "                                                      ) \n",
    "    \n",
    "            plt.rcParams['axes.prop_cycle']=plt.cycler(color=[Blue_scalar_color_mapping(2257, color_map=plt.cm.Blues, data_min=-500, data_max=3136)]+\\\n",
    "                                                       [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "                                                      )     \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class',]\n",
    "                                                    ].mean().reset_index()\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=\"mse_all\", \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0],\n",
    "                #linewidth=3,\n",
    "                #palette=\"Set2\",\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "            \n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[\"mse_all\"], \n",
    "                                 linestyle=\"-\",\n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )            \n",
    "            \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #, fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Error\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            #axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=1, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, .045)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0,  labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #, labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(1, 0, 0.3, 0.5))#, bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "            leg.remove()\n",
    "\n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0) \n",
    "                \n",
    "            axd[plot_key].set_title(prettify_metric_name(\"mse_all\"))#, fontsize=20)\n",
    "        \n",
    "            from matplotlib.lines import Line2D\n",
    "\n",
    "            custom_lines = [Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], lw=1),\n",
    "                            Line2D([0], [0], color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1], lw=1, linestyle=\"-\")]\n",
    "\n",
    "            axd[plot_key].legend(custom_lines, ['Amortized', 'KernelSHAP'], \n",
    "                                 #ncols=2,\n",
    "                                 loc='best', \n",
    "                                 #bbox_to_anchor=(-0.6, -1.3, 0.5, 1)\n",
    "                                 bbox_to_anchor=(0, 0, 1, 1)\n",
    "                                )\n",
    "            #bbox_to_anchor=(-0.8, -0.32, 3, 0),           \n",
    "\n",
    "\n",
    "        elif metric==\"trainsamples_pearsonr_all\":\n",
    "            metric_list_plot_df_select=metric_list_plot_explainer_df[(metric_list_plot_explainer_df[\"split\"]==\"train\")\\\n",
    "                              &(metric_list_plot_explainer_df[\"method_type\"]==method_type)\\\n",
    "                              &(metric_list_plot_explainer_df[\"is_best_checkpoint\"]==\"best\")\n",
    "                             ].groupby([\"method_type\", \"num_train\"])\\\n",
    "                                                    [['sample_idx',\n",
    "                                                    'mse_target',\n",
    "                                                    'mse_nontarget',\n",
    "                                                    'mse_all',\n",
    "                                                    'pearsonr_target',\n",
    "                                                    'pearsonr_all',\n",
    "                                                    'pearsonr_all_per_class',\n",
    "                                                    'spearmanr_target',\n",
    "                                                    'spearmanr_all',\n",
    "                                                    'spearmanr_all_per_class']\n",
    "                                                    ].mean().reset_index()            \n",
    "        \n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"num_train\", \n",
    "                y=\"pearsonr_all\", \n",
    "                # hue=\"num_subsets\",\n",
    "                marker='o', \n",
    "                markersize=6,  \n",
    "                alpha=0.8,\n",
    "                #linewidth=3,\n",
    "                #palette=\"Set2\",\n",
    "                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0],\n",
    "                data=metric_list_plot_df_select,\n",
    "                ax=axd[plot_key],\n",
    "            )\n",
    "\n",
    "            \n",
    "            axd[plot_key].hlines(xmin=0, xmax=5000, \n",
    "                                 y=metric_list_plot_target_df[['sample_idx',\n",
    "                                    'mse_target',\n",
    "                                    'mse_nontarget',\n",
    "                                    'mse_all',\n",
    "                                    'pearsonr_target',\n",
    "                                    'pearsonr_all',\n",
    "                                    'pearsonr_all_per_class',\n",
    "                                    'spearmanr_target',\n",
    "                                    'spearmanr_all',\n",
    "                                    'spearmanr_all_per_class']].mean().loc[\"pearsonr_all\"], \n",
    "                                 linestyle=\"-\",                                 \n",
    "                                 #linewidth=3, \n",
    "                                 color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1],\n",
    "                                 label=f'KernelSHAP'\n",
    "                                )               \n",
    "\n",
    "            axd[plot_key].set_xlabel(\"# Training Datapoints (Amortized)\") #fontsize=20\n",
    "            axd[plot_key].set_ylabel(\"Pearson Correlation\") #, fontsize=20\n",
    "\n",
    "            # xaxis\n",
    "            #axd[plot_key].xaxis.set_major_locator(MultipleLocator(500))\n",
    "            #axd[plot_key].xaxis.set_minor_locator(MultipleLocator(100))            \n",
    "            axd[plot_key].xaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].xaxis.grid(True, which='minor',alpha=0.1) # linewidth=1, \n",
    "            axd[plot_key].set_xlim(left=-1e-3)\n",
    "            #axd[plot_key].set_xscale(\"log\")\n",
    "\n",
    "            axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "            #axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "            axd[plot_key].yaxis.grid(True, which='major', alpha=0.6) #linewidth=2, \n",
    "            axd[plot_key].yaxis.grid(True, which='minor', alpha=0.1) #linewidth=2, \n",
    "            # axd[plot_key].set_ylim(0, 3 * metric_list_plot_df_select.groupby([\"model_name\", \"epoch\"])[\"mse_all\"].mean().min())\n",
    "            axd[plot_key].set_ylim(0, 1.01)\n",
    "            #axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "            axd[plot_key].tick_params(axis='x', which='major', rotation=0, labelright=True) #labelsize=20, \n",
    "            axd[plot_key].tick_params(axis='y', which='major', rotation=0)  #labelsize=20\n",
    "            # axd[plot_key].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "            axd[plot_key].spines['right'].set_visible(False)\n",
    "            axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "            axd[plot_key].set_title(prettify_metric_name(\"pearsonr_all\"))#, fontsize=20)\n",
    "        \n",
    "         #\n",
    "            \n",
    "#             for line in leg.get_lines():\n",
    "#                 line.set_linewidth(3.0)   \n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_context('paper', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5f3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e56b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_compute.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ba708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ead80",
   "metadata": {},
   "outputs": [],
   "source": [
    "                palette=[Blue_scalar_color_mapping(i, color_map=plt.cm.Blues, data_min=-500, data_max=3136) \n",
    "                         for i in metric_list_plot_df_select[\"num_subsets\"]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0be0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeecd56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658925a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "783057e4",
   "metadata": {},
   "source": [
    "# qualitative evaluation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_figure(explainer, dataset, sample_idx_list):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    \n",
    "    explainer_output=[]\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        explainer.eval()\n",
    "        with torch.no_grad():\n",
    "            explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "            explanation=explanation[\"logits\"][0]\n",
    "        explainer_output.append(explanation.detach().cpu().numpy())\n",
    "\n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                explainer.eval()\n",
    "                with torch.no_grad():\n",
    "                    explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "                    explanation=explanation[\"logits\"][0]\n",
    "                #explainer_output.append(explanation.detach().cpu().numpy())\n",
    "                #print(explanation.shape)\n",
    "                if len(explanation.shape)==2:\n",
    "                    explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "                else:\n",
    "                    explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=mpl.colormaps['Greys'](1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "    return fig, explainer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_figure_attribution(dataset, sample_idx_list, attribution_value, attribution_value_key):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(attribution_value[sample_idx].keys()))\n",
    "                #print(plot_type, attribution_value[sample_idx][attribution_value_key].shape)\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])}[attribution_value_key][:,plot_type]\n",
    "                \n",
    "                #print(explanation_class.shape)\n",
    "#                 print(explanation_class.shape, plot_type)\n",
    "#                 explainer.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "#                     explanation=explanation[\"logits\"][0]\n",
    "#                 if len(explanation.shape)==2:\n",
    "#                     explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "#                 else:\n",
    "#                     explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "    return fig           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex=False)\n",
    "mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96408819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_target_prediction_groundtruth(dataset, \n",
    "                                       sample_idx_list,\n",
    "                                       attribution_value,\n",
    "                                       attribution_value_key,\n",
    "                                       explainer,\n",
    "                                       attribution_value_groundtruth,\n",
    "                                       attribution_value_key_groundtruth                                 \n",
    "                                      \n",
    "                                      ):\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\", \"target\", \"prediction\", \"groundtruth\"])+0.05*len([\"empty\"])), \n",
    "                              1.53*len(sample_idx_list) + 0.06* (len(sample_idx_list)-1)  ))\n",
    "    \n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+ [\"target\", \"prediction\", \"groundtruth\"]  ), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.05]+[1, 1, 1])  \n",
    "    \n",
    "    \n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+ [\"target\", \"prediction\", \"groundtruth\"]):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.0)\n",
    "        \n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "                \n",
    "                \n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+[\"target\", \"prediction\", \"groundtruth\"]):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                class_name_={'0': 'Tench',\n",
    "                 '1': 'English springer',\n",
    "                 '2': 'Cassette player',\n",
    "                 '3': 'Chain saw',\n",
    "                 '4': 'Church',\n",
    "                 '5': 'French horn',\n",
    "                 '6': 'Garbage truck',\n",
    "                 '7': 'Gas pump',\n",
    "                 '8': 'Golf ball',\n",
    "                 '9': 'Parachute'}[str(label)]\n",
    "                if idx1==0:\n",
    "                    axd[plot_key].set_title(\"Context\\n$b$\", pad=7, zorder=10)\n",
    "                axd[plot_key].set_ylabel(class_name_)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            elif plot_type==\"target\":  \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(attribution_value[sample_idx].keys()))\n",
    "                #print(plot_type, attribution_value[sample_idx][attribution_value_key].shape)\n",
    "                #print({n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])})\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])}[attribution_value_key][:,label]\n",
    "                \n",
    "                #print(explanation_class.shape)\n",
    "#                 print(explanation_class.shape, plot_type)\n",
    "#                 explainer.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "#                     explanation=explanation[\"logits\"][0]\n",
    "#                 if len(explanation.shape)==2:\n",
    "#                     explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "#                 else:\n",
    "#                     explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                #axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")\n",
    "                #axd[plot_key].set_title(r'$\\tilde{a}(b)$')\n",
    "                if idx1==0:\n",
    "                    axd[plot_key].set_title(\"Noisy label\\n\"+r'$\\tilde{a}(b)$')                                \n",
    "                \n",
    "            elif plot_type==\"prediction\":  \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(attribution_value[sample_idx].keys()))\n",
    "                #print(plot_type, attribution_value[sample_idx][attribution_value_key].shape)\n",
    "                #print({n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])})\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])}[attribution_value_key][:,label]\n",
    "                    \n",
    "                explainer.eval()\n",
    "                with torch.no_grad():\n",
    "                    explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "                    explanation=explanation[\"logits\"][0]\n",
    "                if len(explanation.shape)==2:\n",
    "                    explanation_class=explanation[label].detach().cpu().numpy()\n",
    "                else:\n",
    "                    explanation_class=explanation.detach().cpu().numpy()                    \n",
    "                    \n",
    "                print(explanation.shape)\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                #axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")                \n",
    "                if idx1==0:\n",
    "                    axd[plot_key].set_title(\"Prediction\\n\"+r'$a(b;\\theta)$')                \n",
    "                \n",
    "            elif plot_type==\"groundtruth\":  \n",
    "                \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(attribution_value[sample_idx].keys()))\n",
    "                #print(plot_type, attribution_value[sample_idx][attribution_value_key].shape)\n",
    "                #print({n_samples:values for n_samples, values in zip(attribution_value[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])})\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(attribution_value_groundtruth[sample_idx][\"iters\"], attribution_value[sample_idx][\"values\"])}[attribution_value_key_groundtruth][:,label]\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                #axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")\n",
    "                if idx1==0:\n",
    "                    axd[plot_key].set_title(\"Ground Truth\\n\"+r'$a(b)$')\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)     \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_target_prediction_groundtruth(\n",
    "    dataset=dataset_explainer[\"train\"],\n",
    "    sample_idx_list=[774, 3772, 3418, 7132, 2183, 683, 6310], # 6310\n",
    "    attribution_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train'],\n",
    "    attribution_value_key=512,\n",
    "    explainer=regexplainer,\n",
    "    attribution_value_groundtruth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train'],\n",
    "    attribution_value_key_groundtruth=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e9785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c22122",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"logs/plots/\"+f\"shapley_qualitative.png\", bbox_inches='tight')\n",
    "fig.savefig(\"logs/plots/\"+f\"shapley_qualitative.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8aa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets=512\n",
    "\n",
    "model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\"\n",
    "\n",
    "\n",
    "checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "checkpoint_state_dict = torch.load(model_path+f\"/checkpoint-{int(get_best_model_checkpoint(model_path).split('-')[-1])}\"+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "    checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "regexplainer.load_state_dict(checkpoint_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80039d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train'][6440][\"iters\"][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92664b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207ab4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad084a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6223907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567fec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c936c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c858532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915cce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919cdedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebabc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0def1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdeffaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "803eaedb",
   "metadata": {},
   "source": [
    "# banzhaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fa80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6534b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43960bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_attribution(\n",
    "            dataset=dataset_explainer[\"train\"], \n",
    "            sample_idx_list=[1087, 1076,\n",
    "                             4354, 4513,\n",
    "                             7065, 6673,\n",
    "                             2523, 2210,],\n",
    "            attribution_value=banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_long/extract_output/train'],\n",
    "            attribution_value_key=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train'][4513]\\\n",
    "[\"values\"][-1][:,:8].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d30b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a36ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da632d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_attribution(\n",
    "            dataset=dataset_explainer[\"train\"], \n",
    "            sample_idx_list=[1087, 1076,\n",
    "                             4354, 4513,\n",
    "                             7065, 6673,\n",
    "                             2523, 2210,],\n",
    "            attribution_value=banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling/extract_output/train'],\n",
    "            attribution_value_key=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [100, 500]:\n",
    "    model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in checkpoint_path_list[89:89+1]:\n",
    "        print(checkpoint_path)\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig, explainer_output=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[1087, 1076,\n",
    "                             4354, 4513,\n",
    "                             7065, 6673,\n",
    "                             2523, 2210,])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b4a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a55eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_attribution(\n",
    "            dataset=dataset_explainer[\"test\"], \n",
    "            sample_idx_list=[0, 10, 11, 17, 18],\n",
    "            attribution_value=banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_test_sampling_long/extract_output/test'],\n",
    "            attribution_value_key=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf81f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8716b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a0f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [100, 500]:\n",
    "    model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in [trainer_state[\"best_model_checkpoint\"]]:\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig, explainer_output=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[0, 10, 11])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcf288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d43bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8c634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [100, 500]:\n",
    "    model_path=f\"/sdata/chanwkim/xai-amortization/logs_0901/vitbase_imagenette_banzhaf_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    print([trainer_state[\"best_model_checkpoint\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c66be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15947ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec724d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "banzhaf_loaded_dict['logs/vitbase_imagenette_surrogate_banzhaf_eval_train_sampling_antithetical/extract_output/train'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8b5a0",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',                       \n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset[\"test_explainer\"], \n",
    "                sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "    fig.suptitle(f\"Reg-AO {num_eval}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b73689",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906be0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(\n",
    "            dataset=dataset_explainer[\"train\"], \n",
    "            sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639],\n",
    "            shapley_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'],\n",
    "            shapley_value_key=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(\n",
    "            dataset=dataset_explainer[\"test\"], \n",
    "            sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84],\n",
    "            shapley_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test'],\n",
    "            shapley_value_key=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24d7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea85be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a3d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f61ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26926a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [9986]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[20:20+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig, explainer_output=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\") \n",
    "    \n",
    "    fig=plot_figure_shapley(\n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639],\n",
    "                shapley_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'],\n",
    "                shapley_value_key=9986,\n",
    "    )\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4eb890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e1d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3662792",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\"\"]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_250\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[46:46+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig, explainer_output=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\") \n",
    "    \n",
    "    fig=plot_figure_shapley(\n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639],\n",
    "                shapley_value={key:value[0] for key,value in shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440'].items()},\n",
    "                shapley_value_key=2440,\n",
    "    )\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b067736",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_1000/trainer_state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_1000/checkpoint-512/trainer_state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88878eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\"\"]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_1000\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[32:32+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig, explainer_output=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\") \n",
    "    \n",
    "    fig=plot_figure_shapley(\n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639],\n",
    "                shapley_value={key:value[0] for key,value in shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train_2440'].items()},\n",
    "                shapley_value_key=2440,\n",
    "    )\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abfdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fedd65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212fffbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81688b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31b242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26acaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_idx in enumerate([4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]):\n",
    "    ground_truth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    targets=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    predictions=explainer_output\n",
    "    \n",
    "    plt.scatter(\n",
    "        targets[:, np.argmax(ground_truth.sum(axis=0))],\n",
    "        predictions[i][np.argmax(ground_truth.sum(axis=0)),:]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e78c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_idx in enumerate([4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]):\n",
    "    ground_truth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    targets=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    predictions=explainer_output\n",
    "    \n",
    "\n",
    "    plt.scatter(\n",
    "        targets[:, np.argmax(ground_truth.sum(axis=0))],\n",
    "        ground_truth[:, np.argmax(ground_truth.sum(axis=0))]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_idx in enumerate([4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]):\n",
    "    ground_truth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    targets=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    predictions=explainer_output\n",
    "    \n",
    "\n",
    "    plt.scatter(\n",
    "        np.arange(196),\n",
    "        predictions[i][np.argmax(ground_truth.sum(axis=0)),:][np.argsort(ground_truth[:, np.argmax(ground_truth.sum(axis=0))])],\n",
    "        alpha=0.8\n",
    "    )    \n",
    "    plt.title('explainer output')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15b70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeffc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_idx in enumerate([4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]):\n",
    "    ground_truth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    targets=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    predictions=explainer_output\n",
    "    \n",
    "\n",
    "    plt.scatter(\n",
    "        np.arange(196),\n",
    "        targets[:, np.argmax(ground_truth.sum(axis=0))][np.argsort(ground_truth[:, np.argmax(ground_truth.sum(axis=0))])],\n",
    "                alpha=0.8\n",
    "    )    \n",
    "    plt.title('training targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample_idx in enumerate([4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]):\n",
    "    ground_truth=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    targets=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][sample_idx][\"values\"][-1]\n",
    "    \n",
    "    predictions=explainer_output\n",
    "    \n",
    "\n",
    "    plt.scatter(\n",
    "        np.arange(196),\n",
    "        ground_truth[:, np.argmax(ground_truth.sum(axis=0))][np.argsort(ground_truth[:, np.argmax(ground_truth.sum(axis=0))])],\n",
    "    )   \n",
    "    plt.title('ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd956fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11099f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639]\n",
    "shapley_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_output[0].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train_SGD_antithetical/extract_output/train'][4832][\"values\"][-1]\\\n",
    ".sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bafe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5f6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112c419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac51e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e30bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fcb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\"\"]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_250\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[46:46+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ccff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_5000/checkpoint-1099/trainer_state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\"\"]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_5000\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[14:14+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cdc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\"\"]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2330_numtrain_1000\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[32:32+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b6a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94937f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e801a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [9986]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_SGD_antithetical_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "    for checkpoint_path in tqdm(checkpoint_path_list[20:20+1]):\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ced558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test'].keys())[:8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8f77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9908c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a1bd45",
   "metadata": {},
   "source": [
    "### kernelshap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57854c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512]:\n",
    "# for num_subsets in [2048, 3072]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "#     for checkpoint_path in tqdm(checkpoint_path_list[20:20+1]):\n",
    "    for checkpoint_path in [trainer_state[\"best_model_checkpoint\"]]:\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")\n",
    "    \n",
    "    fig=plot_figure_shapley(\n",
    "                dataset=dataset_explainer[\"train\"], \n",
    "                sample_idx_list=[4832, 1928, 2523, 2997, 4838, 2210, 9286, 3639],\n",
    "                shapley_value=shapley_loaded_dict['logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train'],\n",
    "                shapley_value_key=512,\n",
    "    )\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512]:\n",
    "# for num_subsets in [2048, 3072]:\n",
    "    model_path=f\"logs/vitbase_imagenette_shapley_regexplainer_upfront_{num_subsets}\"\n",
    "    with open(model_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "\n",
    "    checkpoint_path_list=sorted(glob.glob(model_path+\"/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "    \n",
    "#     for checkpoint_path in tqdm(checkpoint_path_list[20:20+1]):\n",
    "    for checkpoint_path in [trainer_state[\"best_model_checkpoint\"]]:\n",
    "        checkpoint_state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "        with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "            checkpoint_trainer_state = json.load(f)\n",
    "\n",
    "        regexplainer.load_state_dict(checkpoint_state_dict)\n",
    "        \n",
    "        \n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset_explainer[\"test\"], \n",
    "                sample_idx_list=[27, 50, 62, 15, 68, 86, 49, 84])\n",
    "    fig.suptitle(f\"Reg-AO {num_subsets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d68a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd393f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c611df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb7c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a793efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_explainer[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0534576",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6386e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc5cf197",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d56c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dfe32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30eaff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b1e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa178a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1309639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852dc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"mse_target_explainer\", \n",
    "                y=\"mse_target_calculated\", \n",
    "                hue=\"explainer\",\n",
    "                data=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c71a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbc37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be141659",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468517ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be48817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c45d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.fillna(\"None\").groupby([\"explainer\", \"sample_idx\"]).apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd3435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58efd0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbd701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3c285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_calculated=512*3, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"], \n",
    "    iters_calculated=512*1, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839429f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b8409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c5c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_calculated=512*2, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "199680/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428dee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fef3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"], \n",
    "    iters_calculated=512, \n",
    "    meta_info={}\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e75ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]=\\\n",
    "load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8600c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b15c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][9213][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0736b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][9213][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eeca45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70db19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246047f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8b928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list+=get_ground_truth_metric(shapley_values=shapley_loaded_test, \n",
    "                        explainer=regexplainer,\n",
    "                        dataset=dataset_explainer[\"test\"],\n",
    "                        iters_ground_truth=200192,\n",
    "                        meta_info={\"explainer\": \"Reg-AO (upfront, 512)\",\n",
    "                                   \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a1447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d9986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de98d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80301eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cf63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f793130",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_objexplainer_newsample_32/\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:100]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    explainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric(shapley_values=shapley_loaded_test, \n",
    "                            explainer=explainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=200192,\n",
    "                            meta_info={\"explainer\": \"Obj-AO (newsample, 32)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda32760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe486877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5384a3ae",
   "metadata": {},
   "source": [
    "# per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_ground_truth=99840\n",
    "\n",
    "record_dict_list=[]\n",
    "\n",
    "for sample_idx, num_eval_shapley_values in enumerate(shapley_values_dict[\"test\"]):\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"per-sample\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list=[]\n",
    "\n",
    "for sample_idx, num_eval_shapley_values in enumerate(shapley_loaded_test[\"test\"]):\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"per-sample\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1d9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_estimated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd84ee",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4babde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',                       \n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset[\"test_explainer\"], \n",
    "                sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "    fig.suptitle(f\"Reg-AO {num_eval}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae9a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b04791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(shapley_values_dict[\"test\"], dataset[\"test_explainer\"])):\n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        regexplainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=regexplainer(pixel_values=data[\"pixel_values\"].unsqueeze(0), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"regression_AO\",            \n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_obj in sorted(glob.glob(\"logs/vitbase_imagenette_explainer_objective/checkpoint-*\"), key=lambda x: int(x.split('-')[-1])):\n",
    "    num_eval=int(model_path_obj.split('-')[-1])/148*32\n",
    "    if int(int(model_path_obj.split('-')[-1])/148)%10!=1:\n",
    "        continue\n",
    "    state_dict = torch.load(f\"{model_path_obj}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    explainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_model_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(tqdm.tqdm(shapley_values_dict[\"test\"]), dataset[\"test_explainer\"])):        \n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        explainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.cpu().detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"objective_AO\",            \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2c7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(int(model_path_obj.split('-')[-1])/148)%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461153fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "444/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91304c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090995a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fac37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da40cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5134987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16300924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df,\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15561acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a497ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb68920",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.01)\n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "500/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a5318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d446c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce44723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a5f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426e85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf5a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76564e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76abcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d86bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febe09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9111265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fd24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d72efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c03e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609424dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb71e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb571e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2455520",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression_0/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_out=explainer.forward(pixel_values=dataset[\"validation_explainer\"][0]['pixel_values'].unsqueeze(0),\n",
    "                               return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09996826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75733ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.to(device)\n",
    "explainer.surrogate_null=explainer.surrogate_null.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd568cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409324e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51752451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.max_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76788cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6879770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7701de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec174b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a8c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030835e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_train=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_train/extract_output/train/\")\n",
    "shapley_loaded_train_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_train_validation_permutation/extract_output/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_validation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation/extract_output/validation/\")\n",
    "shapley_loaded_validation_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation_permutation/extract_output/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7252da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test/extract_output/test/\")\n",
    "shapley_loaded_test_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation/extract_output/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded2[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapley_loaded1), len(shapley_loaded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd334290",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_eval_train_permutation/extract_output/train/3 -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c738cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f924f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_shapley??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef410cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"values\"][-1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d869aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "explainer.surrogate.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def ShapleySampling(game,\n",
    "                    batch_size=512,\n",
    "                    detect_convergence=True,\n",
    "                    thresh=0.01,\n",
    "                    n_samples=None,\n",
    "                    antithetical=False,\n",
    "                    return_all=False,\n",
    "                    bar=True,\n",
    "                    verbose=False):\n",
    "    # Verify arguments.\n",
    "    stochastic = False\n",
    "#     if isinstance(game, CooperativeGame):\n",
    "#         stochastic = False\n",
    "#     elif isinstance(game, StochasticCooperativeGame):\n",
    "#         stochastic = True\n",
    "#     else:\n",
    "#         raise ValueError('game must be CooperativeGame or '\n",
    "#                          'StochasticCooperativeGame')\n",
    "\n",
    "    # Possibly force convergence detection.\n",
    "    if n_samples is None:\n",
    "        n_samples = 1e20\n",
    "        if not detect_convergence:\n",
    "            detect_convergence = True\n",
    "            if verbose:\n",
    "                print('Turning convergence detection on')\n",
    "\n",
    "    if detect_convergence:\n",
    "        assert 0 < thresh < 1\n",
    "\n",
    "    # Calculate null coalition value.\n",
    "    if stochastic:\n",
    "        null = game.null(batch_size=batch_size)\n",
    "    else:\n",
    "        null = game.null()\n",
    "\n",
    "    # Set up bar.\n",
    "    n_loops = int(np.ceil(n_samples / batch_size))\n",
    "    if bar:\n",
    "        if detect_convergence:\n",
    "            bar = tqdm(total=1)\n",
    "        else:\n",
    "            bar = tqdm(total=n_loops * batch_size)\n",
    "\n",
    "    # Setup.\n",
    "    num_players = game.players\n",
    "    if isinstance(null, np.ndarray):\n",
    "        values = np.zeros((num_players, len(null)))\n",
    "        sum_squares = np.zeros((num_players, len(null)))\n",
    "        deltas = np.zeros((batch_size, num_players, len(null)))\n",
    "    else:\n",
    "        values = np.zeros((num_players))\n",
    "        sum_squares = np.zeros((num_players))\n",
    "        deltas = np.zeros((batch_size, num_players))\n",
    "    permutations = np.tile(np.arange(game.players), (batch_size, 1))\n",
    "    arange = np.arange(batch_size)\n",
    "    n = 0\n",
    "\n",
    "    # For tracking progress.\n",
    "    if return_all:\n",
    "        N_list = []\n",
    "        std_list = []\n",
    "        val_list = []\n",
    "\n",
    "    # Begin sampling.\n",
    "    for it in range(n_loops):\n",
    "        for i in range(batch_size):\n",
    "            if antithetical and i % 2 == 1:\n",
    "                permutations[i] = permutations[i - 1][::-1]\n",
    "            else:\n",
    "                np.random.shuffle(permutations[i])\n",
    "        S = np.zeros((batch_size, game.players), dtype=int)\n",
    "\n",
    "        # Sample exogenous (if applicable).\n",
    "        if stochastic:\n",
    "            U = game.sample(batch_size)\n",
    "\n",
    "        # Unroll permutations.\n",
    "        prev_value = null\n",
    "        for i in tqdm(range(num_players)):\n",
    "            S[arange, permutations[:, i]] = 1\n",
    "            if stochastic:\n",
    "                next_value = game(S, U)\n",
    "            else:\n",
    "                next_value = game(S)\n",
    "            deltas[arange, permutations[:, i]] = next_value - prev_value\n",
    "            prev_value = next_value\n",
    "\n",
    "        # Welford's algorithm.\n",
    "        n += batch_size\n",
    "        diff = deltas - values\n",
    "        values += np.sum(diff, axis=0) / n\n",
    "        diff2 = deltas - values\n",
    "        sum_squares += np.sum(diff * diff2, axis=0)\n",
    "\n",
    "        # Calculate progress.\n",
    "        var = sum_squares / (n ** 2)\n",
    "        std = np.sqrt(var)\n",
    "        ratio = np.max(\n",
    "            np.max(std, axis=0) / (values.max(axis=0) - values.min(axis=0)))\n",
    "\n",
    "        # Print progress message.\n",
    "        if verbose:\n",
    "            if detect_convergence:\n",
    "                print(f'StdDev Ratio = {ratio:.4f} (Converge at {thresh:.4f})')\n",
    "            else:\n",
    "                print(f'StdDev Ratio = {ratio:.4f}')\n",
    "\n",
    "        # Check for convergence.\n",
    "        if detect_convergence:\n",
    "            if ratio < thresh:\n",
    "                if verbose:\n",
    "                    print('Detected convergence')\n",
    "\n",
    "                # Skip bar ahead.\n",
    "                if bar:\n",
    "                    bar.n = bar.total\n",
    "                    bar.refresh()\n",
    "                break\n",
    "\n",
    "        # Forecast number of iterations required.\n",
    "        if detect_convergence:\n",
    "            N_est = (it + 1) * (ratio / thresh) ** 2\n",
    "            if bar and not np.isnan(N_est):\n",
    "                bar.n = np.around((it + 1) / N_est, 4)\n",
    "                bar.refresh()\n",
    "        elif bar:\n",
    "            bar.update(batch_size)\n",
    "\n",
    "        # Save intermediate quantities.\n",
    "        if return_all:\n",
    "            val_list.append(np.copy(values))\n",
    "            std_list.append(np.copy(std))\n",
    "            if detect_convergence:\n",
    "                N_list.append(N_est)\n",
    "\n",
    "    # Return results.\n",
    "    if return_all:\n",
    "        # Dictionary for progress tracking.\n",
    "        iters = (np.arange(it + 1) + 1) * batch_size * num_players\n",
    "        tracking_dict = {\n",
    "            'values': val_list,\n",
    "            'std': std_list,\n",
    "            'iters': iters}\n",
    "        if detect_convergence:\n",
    "            tracking_dict['N_est'] = N_list\n",
    "\n",
    "        return tracking_dict\n",
    "    else:\n",
    "        return (values, std)\n",
    "    \n",
    "class CooperativeGame:\n",
    "    '''Base class for cooperative games.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''Evaluate cooperative game.'''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def grand(self):\n",
    "        '''Get grand coalition value.'''\n",
    "        return self.__call__(np.ones((1, self.players), dtype=int))[0]\n",
    "\n",
    "    def null(self):\n",
    "        '''Get null coalition value.'''\n",
    "        return self.__call__(np.zeros((1, self.players), dtype=int))[0]\n",
    "\n",
    "\n",
    "class PredictionGame(CooperativeGame):\n",
    "    '''\n",
    "    Cooperative game for an individual example's prediction.\n",
    "\n",
    "    Args:\n",
    "      extension: model extension (see removal.py).\n",
    "      sample: numpy array representing a single model input.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, surrogate, sample):\n",
    "        # Add batch dimension to sample.\n",
    "\n",
    "        self.surrogate = surrogate\n",
    "        self.sample = sample\n",
    "\n",
    "        # Store feature groups.\n",
    "\n",
    "        self.players = 196\n",
    "        self.groups_matrix = None\n",
    "\n",
    "        # Caching.\n",
    "        self.sample_repeat = sample\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''\n",
    "        Evaluate cooperative game.\n",
    "\n",
    "        Args:\n",
    "          S: array of player coalitions with size (batch, players).\n",
    "        '''\n",
    "        # Try to use caching for repeated data.\n",
    "        input_data = self.sample_repeat\n",
    "\n",
    "        # Evaluate.\n",
    "        with torch.no_grad():\n",
    "            output=self.surrogate(input_data[\"pixel_values\"].unsqueeze(0).to(device), \n",
    "                                  torch.Tensor(S).unsqueeze(0).to(device), return_loss=False)\n",
    "            logits=output.logits\n",
    "            return softmax(logits[0].detach().cpu().numpy(), axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "# shapley_sampling=ShapleySampling(game,\n",
    "#                     batch_size=128,\n",
    "#                     detect_convergence=True,\n",
    "#                     thresh=0.01,\n",
    "#                     antithetical=False,\n",
    "#                     return_all=True,\n",
    "#                     bar=True,\n",
    "#                     verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "\n",
    "            # Compute y_i\n",
    "            y_i = game(x_i.astype(bool)[np.newaxis])[0] - null\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        phi = np.mean(phi_iterates, axis=0)\n",
    "\n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class SGDshapley():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_Ï‰_k = OrderedDict() # weights per size k\n",
    "        dict_L_k = OrderedDict() # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            Ï‰_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = Ï‰_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_Ï‰_k.update({k: Ï‰_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "        # Probability distributions for sampling new instance\n",
    "        # Classic SGD\n",
    "        p = [ncr(d,k) for k in range(1,d)]\n",
    "        p /= np.sum(p)\n",
    "        # Importance Sampling proposal q\n",
    "#         print(dict_L_k.keys(), dict_L_k.values())\n",
    "#         sdsd\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.n = 2**d - 2\n",
    "        self.dict_Ï‰_k = dict_Ï‰_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _F_i(self, Î¦, x_i, y_i, Ï‰_i):\n",
    "        \"\"\"Function value per instance i\"\"\"\n",
    "        res = .5 * self.n * Ï‰_i * (np.dot(x_i, Î¦) - y_i)**2\n",
    "        return res\n",
    "\n",
    "    def _grad_F_i(self, Î¦, x_i, y_i, Ï‰_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        res = Ï‰_i * x_i[:,None].dot(x_i[None,:]).dot(Î¦) - Ï‰_i * y_i * x_i\n",
    "        return res\n",
    "\n",
    "    def _Î _1(self, x, b):\n",
    "        \"\"\"Projection Î  on convex set K_1\"\"\"\n",
    "        if np.abs((np.sum(x) - b)) <= 1e-6:\n",
    "            return x\n",
    "        else:\n",
    "            return x - (np.sum(x) - b)/len(x)\n",
    "\n",
    "    def _Î _2(self, x, D):\n",
    "        \"\"\"Projection Î  on convex set K_2\"\"\"\n",
    "        if np.linalg.norm(x) > D:\n",
    "            return x * D / np.linalg.norm(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _Dykstra_proj(self, x, D, b, iter_proj=100, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Dykstra's algorithm to find orthogonal projection\n",
    "        onto intersection of convex sets\n",
    "        \"\"\"\n",
    "        xk = x.copy()\n",
    "        d = len(x)\n",
    "        pk, qk = np.zeros(d), np.zeros(d)\n",
    "        for k in range(iter_proj):\n",
    "            yk = self._Î _2(xk + pk, D)\n",
    "            pk = xk + pk - yk\n",
    "            if np.linalg.norm(self._Î _1(yk + qk, b) - xk, 2) <= epsilon:\n",
    "                break\n",
    "            else:\n",
    "                xk = self._Î _1(yk + qk, b)\n",
    "                qk = yk + qk - xk\n",
    "        return xk\n",
    "\n",
    "    def sgd(self, game, dimension_select, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Î¦_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        \n",
    "        f_x = game(np.ones((1, self.d), dtype=int))[0][dimension_select]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=int))[0][dimension_select]\n",
    "\n",
    "        \n",
    "        v_M = f_x - f_r\n",
    "\n",
    "        d = self.d\n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_Ï‰_k = self.dict_Ï‰_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Î¦_0:\n",
    "            Î¦ = Î¦_0.copy()\n",
    "        else:\n",
    "            Î¦ = np.zeros(d)\n",
    "        Î¦_storage = np.zeros((n_iter,d))\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        Î¦ = Î¦ - (np.sum(Î¦) - v_M) / d\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            #z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])            \n",
    "            f_S = game(x_i[np.newaxis])[0][dimension_select]\n",
    "            y_i = f_S - f_r\n",
    "            # get weight Ï‰_i\n",
    "            Ï‰_i = dict_Ï‰_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Î¦, x_i, y_i, Ï‰_i)\n",
    "            # update Î¦\n",
    "            if step_type == \"constant\":\n",
    "                Î¦ = Î¦ - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                Î¦ = Î¦ - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                Î¦ = Î¦ - (step/(t)) * grad_i\n",
    "\n",
    "            # projection onto convex set K\n",
    "            # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "            Î¦ = Î¦ - (Î¦.sum() - v_M) / d\n",
    "\n",
    "            # update storage of Î¦\n",
    "            Î¦_storage[t-1,:] = Î¦\n",
    "\n",
    "\n",
    "        # Average all Î¦\n",
    "        Î¦ = np.mean(Î¦_storage,axis=0)\n",
    "\n",
    "        return Î¦\n",
    "    \n",
    "    def sgd_minibatch(self, game, batch_size, dimension_select, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Î¦_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        \n",
    "        f_x = game(np.ones((1, self.d), dtype=int))[0][dimension_select]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=int))[0][dimension_select]\n",
    "\n",
    "        \n",
    "        v_M = f_x - f_r\n",
    "\n",
    "        d = self.d\n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_Ï‰_k = self.dict_Ï‰_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Î¦_0:\n",
    "            Î¦ = Î¦_0.copy()\n",
    "        else:\n",
    "            Î¦ = np.zeros(d)\n",
    "        Î¦_storage = []\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        Î¦ = Î¦ - (np.sum(Î¦) - v_M) / d\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        grad_i_accum=[]\n",
    "        \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            #z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])            \n",
    "            f_S = game(x_i[np.newaxis])[0][dimension_select]\n",
    "            y_i = f_S - f_r\n",
    "            # get weight Ï‰_i\n",
    "            Ï‰_i = dict_Ï‰_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Î¦, x_i, y_i, Ï‰_i)\n",
    "            grad_i_accum.append(grad_i)\n",
    "            \n",
    "            if t%batch_size==0:\n",
    "                # update Î¦\n",
    "                if step_type == \"constant\":\n",
    "                    Î¦ = Î¦ - step * np.array(grad_i_accum).mean(axis=0)\n",
    "                elif step_type == \"sqrt\":\n",
    "                    Î¦ = Î¦ - (step/np.sqrt(t)) * np.array(grad_i_accum).mean(axis=0)\n",
    "                elif step_type == \"inverse\":\n",
    "                    Î¦ = Î¦ - (step/(t)) * np.array(grad_i_accum).mean(axis=0)\n",
    "\n",
    "                # projection onto convex set K\n",
    "                # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "                Î¦ = Î¦ - (Î¦.sum() - v_M) / d\n",
    "\n",
    "                # update storage of Î¦\n",
    "                Î¦_storage.append(Î¦)\n",
    "                grad_i_accum=[]\n",
    "\n",
    "        # Average all Î¦\n",
    "        Î¦ = np.mean(np.array(Î¦_storage), axis=0)  \n",
    "        \n",
    "        return Î¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[20], \n",
    "                    shapley_value=shapley_loaded1, shapley_value_key=3584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[20], \n",
    "                    shapley_value=shapley_loaded2, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test[0]['iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da03715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[5], \n",
    "                    shapley_value=shapley_loaded_test, shapley_value_key=5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2453214",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[5], \n",
    "                    shapley_value=shapley_loaded_test_permutation, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447b6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f05fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[1], \n",
    "                    shapley_value=shapley_loaded_test_permutation, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39591",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test_permutation[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3be2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "3332/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded2[0]['iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[110], \n",
    "                    shapley_value=shapley_loaded2, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f89f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb577fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78860f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd(game,\n",
    "            n_iter=5000,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ff537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0141cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3850d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73023d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=32,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=32,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=64,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72116fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=64,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2a95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439316a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=512,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e105d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990103b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35136ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8e3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df69be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "game(np.ones((1,196)))[0][8]-game(np.zeros((1,196)))[0][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0d4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02e5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13cf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd(game,\n",
    "            n_iter=200000,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a902b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6689f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e465a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output==np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69155255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d572a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbafe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efc5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda584e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e5e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "        f_x = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        import ipdb\n",
    "        ipdb.set_trace()\n",
    "        \n",
    "        v_M = f_x - f_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b0051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e1951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling=ShapleySampling(game,\n",
    "                    batch_size=32,\n",
    "                    n_samples=32*32,\n",
    "                    detect_convergence=False,\n",
    "                    thresh=0.01,\n",
    "                    antithetical=False,\n",
    "                    return_all=True,\n",
    "                    bar=True,\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d55ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818429f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc815a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e510e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad2f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72ff79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44812ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a35363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776710db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddd00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815cf31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158a08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820b53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d29d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa6fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "        \n",
    "        \n",
    "        k_record=[]\n",
    "        x_i_record=[]\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            \n",
    "            k_record.append(k)\n",
    "            x_i_record.append(x_i)\n",
    "            \n",
    "            \n",
    "        \n",
    "        x_i_record=np.array(x_i_record)\n",
    "        y_i_record=[]\n",
    "        \n",
    "        for i in tqdm(range(int(np.ceil(len(x_i_record)/128)))):\n",
    "\n",
    "            y_i = game(x_i_record[128*i:128*(i+1)].astype(int)) - null\n",
    "            y_i_record.append(y_i)\n",
    "\n",
    "        y_i_record=np.vstack(y_i_record)   \n",
    "                \n",
    "            \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            k=k_record[t-1]\n",
    "            x_i=x_i_record[t-1]\n",
    "            y_i = y_i_record[t-1]\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "#             res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "            res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "#         list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=self.p)\n",
    "        \n",
    "        \n",
    "        k_record=[]\n",
    "        x_i_record=[]\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            \n",
    "            k_record.append(k)\n",
    "            x_i_record.append(x_i)\n",
    "            \n",
    "            \n",
    "        \n",
    "        x_i_record=np.array(x_i_record)\n",
    "        y_i_record=[]\n",
    "        \n",
    "        for i in tqdm(range(int(np.ceil(len(x_i_record)/128)))):\n",
    "\n",
    "            y_i = game(x_i_record[128*i:128*(i+1)].astype(int)) - null\n",
    "            y_i_record.append(y_i)\n",
    "\n",
    "        y_i_record=np.vstack(y_i_record)   \n",
    "                \n",
    "            \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            k=k_record[t-1]\n",
    "            x_i=x_i_record[t-1]\n",
    "            y_i = y_i_record[t-1]\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "#             grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "            grad_i = self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18599a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fad0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            y_i = game(x_i.astype(bool)[np.newaxis])[0] - null\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=500000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db52ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b24747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe013aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/np.sqrt(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6adeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "            import ipdb\n",
    "            ipdb.set_trace()\n",
    "            res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.01,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef736359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=10,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8bdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82783da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ff280",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c457f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75da035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369eaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.01,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508771bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b22dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "grad_i = self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "# res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b21992",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad137386",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[50000-1]],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fcadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=5000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dad1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[10000-1]],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921511ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[5000].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42207f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output__[:500].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([sgd_shapley_output__[:i+1].mean(axis=0) for i in range(len(sgd_shapley_output__[:100]))])==\\\n",
    "np.cumsum(sgd_shapley_output__[:100], axis=0)/(np.arange(len(sgd_shapley_output__[:100]))+1).reshape(-1,1,1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284beec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1199187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:50].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:500].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d78b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:50].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91616161",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.01,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output_=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling=ShapleySampling(game,\n",
    "                    batch_size=128,\n",
    "                    n_samples=8*128,\n",
    "                    detect_convergence=False,\n",
    "                    thresh=0.01,\n",
    "                    antithetical=False,\n",
    "                    return_all=True,\n",
    "                    bar=True,\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*128*196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafadca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0]['values'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapley_sampling[\"values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26261bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': sgd_shapley_output,\n",
    "            'std': [],\n",
    "            'iters': list(range(1, len(sgd_shapley_output)+1))}}, shapley_value_key=int(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44413bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output_],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde883cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0: shapley_sampling}, shapley_value_key=int(50176))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a78949",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfab3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value=shapley_loaded, shapley_value_key=int(3332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c14d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc34a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"aaaa.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad829039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tracking_dict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a611d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1397223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3547062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fdeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63690ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97299d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0cfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*196*128=10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "128*196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"][0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b573f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(25088))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bab465",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.ceil(100 / 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd9e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0563bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cee600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "10000*0.2/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(320068))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe08406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f3c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b68d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(1536))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(5120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39906222",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec62746",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420911e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5abeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "196*17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e46ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "200116/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dce950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 31], \n",
    "                    shapley_loaded, int(200116))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 31], \n",
    "                    shapley_loaded, int(3332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1036/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5db97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_permutation_upfront_196/checkpoint-888/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 20, 30, 31])\n",
    "# epoch 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6628a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_permutation_upfront_3332/checkpoint-8732/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 20, 30, 31])\n",
    "#19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6886162",
   "metadata": {},
   "outputs": [],
   "source": [
    "32*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "148*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample_32/checkpoint-740/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c1dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34db542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1839ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925f623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af73bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e0049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4c0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f794f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfc1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6078b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f27fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b74845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93724c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][-1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e497c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf77028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfbf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939a9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3725dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(shapley_loaded[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc744c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6470500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd51d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc7264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7d883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c7799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "512*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9977d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dab037",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(shapley_values_test[\"test\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03af49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840+512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a20d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 99840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3ffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecfb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000],\n",
    "                    shapley_values[\"validation\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc574e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3714ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e26bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley_train_val.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d05692",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef656d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfede0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Initalize the explainer trainer\n",
    "########################################################\n",
    "# Load the accuracy metric from the datasets package\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "def compute_metrics(p):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    # import ipdb\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(p.predictions.shape, p.label_ids.shape)\n",
    "    # return metric.compute(\n",
    "    #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "    #     references=p.label_ids,\n",
    "    # )\n",
    "    return {}\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels,\n",
    "        \"masks\": masks,\n",
    "    }\n",
    "\n",
    "explainer_trainer = Trainer(\n",
    "    model=explainer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "    eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=explainer_image_processor,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# ipdb.set_trace()\n",
    "# print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "# print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "########################################################\n",
    "# Detecting last checkpoint\n",
    "#######################################################\n",
    "last_checkpoint = None\n",
    "if (\n",
    "    os.path.isdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif (\n",
    "        last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "    ):\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Training\n",
    "#######################################################\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    explainer_trainer.save_model()\n",
    "    explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_state()\n",
    "\n",
    "########################################################\n",
    "# Evaluation\n",
    "#######################################################\n",
    "if training_args.do_eval:\n",
    "    metrics = explainer_trainer.evaluate()\n",
    "    explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "    explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "########################################################\n",
    "# Write model card and (optionally) push to hub\n",
    "#######################################################\n",
    "kwargs = {\n",
    "    \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "    \"tasks\": \"image-classification\",\n",
    "    \"dataset\": data_args.dataset_name,\n",
    "    \"tags\": [\"image-classification\", \"vision\"],\n",
    "}\n",
    "if training_args.push_to_hub:\n",
    "    explainer_trainer.push_to_hub(**kwargs)\n",
    "else:\n",
    "    explainer_trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4f0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fa564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e459b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5eb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec93405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ede138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec9aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6306a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab5732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5627301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf8f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d8d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf9207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f239a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    # Initalize the explainer trainer\n",
    "    ########################################################\n",
    "    # Load the accuracy metric from the datasets package\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    # Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "    # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "    def compute_metrics(p):\n",
    "        \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "        # import ipdb\n",
    "\n",
    "        # ipdb.set_trace()\n",
    "        # print(p.predictions.shape, p.label_ids.shape)\n",
    "        # return metric.compute(\n",
    "        #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "        #     references=p.label_ids,\n",
    "        # )\n",
    "        return {}\n",
    "\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "        labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "        masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "        }\n",
    "\n",
    "    explainer_trainer = Trainer(\n",
    "        model=explainer,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "        eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=explainer_image_processor,\n",
    "        data_collator=collate_fn,\n",
    "    )\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "    # print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "    ########################################################\n",
    "    # Detecting last checkpoint\n",
    "    #######################################################\n",
    "    last_checkpoint = None\n",
    "    if (\n",
    "        os.path.isdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "    ):\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif (\n",
    "            last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "        ):\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    ########################################################\n",
    "    # Training\n",
    "    #######################################################\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        explainer_trainer.save_model()\n",
    "        explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_state()\n",
    "\n",
    "    ########################################################\n",
    "    # Evaluation\n",
    "    #######################################################\n",
    "    if training_args.do_eval:\n",
    "        metrics = explainer_trainer.evaluate()\n",
    "        explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "        explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    ########################################################\n",
    "    # Write model card and (optionally) push to hub\n",
    "    #######################################################\n",
    "    kwargs = {\n",
    "        \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "        \"tasks\": \"image-classification\",\n",
    "        \"dataset\": data_args.dataset_name,\n",
    "        \"tags\": [\"image-classification\", \"vision\"],\n",
    "    }\n",
    "    if training_args.push_to_hub:\n",
    "        explainer_trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        explainer_trainer.create_model_card(**kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15231b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original, labels, label2id, id2label = setup_dataset(\n",
    "    data_args=data_args, other_args=other_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data__test = load_dataset(\n",
    "        data_args.dataset_name,\n",
    "        data_args.dataset_config_name,\n",
    "        cache_dir=data_args.dataset_cache_dir,\n",
    "        task=None,\n",
    "        token=other_args.token,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "data__test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99353761",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab737a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
