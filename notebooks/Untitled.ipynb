{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/sgd_shapley.ipynb (unless otherwise specified).\n",
    "\n",
    "__all__ = ['ncr', 'SGDshapley']\n",
    "\n",
    "# Cell\n",
    "# Author: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#         Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cell\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "# Cell\n",
    "class SGDshapley():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_ω_k = dict() # weights per size k\n",
    "        dict_L_k = dict() # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            ω_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = ω_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_ω_k.update({k: ω_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "        # Probability distributions for sampling new instance\n",
    "        # Classic SGD\n",
    "        p = [ncr(d,k) for k in range(1,d)]\n",
    "        p /= np.sum(p)\n",
    "        # Importance Sampling proposal q\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.n = 2**d - 2\n",
    "        self.dict_ω_k = dict_ω_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _F_i(self, Φ, x_i, y_i, ω_i):\n",
    "        \"\"\"Function value per instance i\"\"\"\n",
    "        res = .5 * self.n * ω_i * (np.dot(x_i, Φ) - y_i)**2\n",
    "        return res\n",
    "\n",
    "    def _grad_F_i(self, Φ, x_i, y_i, ω_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        res = ω_i * x_i[:,None].dot(x_i[None,:]).dot(Φ) - ω_i * y_i * x_i\n",
    "        return res\n",
    "\n",
    "    def _Π_1(self, x, b):\n",
    "        \"\"\"Projection Π on convex set K_1\"\"\"\n",
    "        if np.abs((np.sum(x) - b)) <= 1e-6:\n",
    "            return x\n",
    "        else:\n",
    "            return x - (np.sum(x) - b)/len(x)\n",
    "\n",
    "    def _Π_2(self, x, D):\n",
    "        \"\"\"Projection Π on convex set K_2\"\"\"\n",
    "        if np.linalg.norm(x) > D:\n",
    "            return x * D / np.linalg.norm(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _Dykstra_proj(self, x, D, b, iter_proj=100, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Dykstra's algorithm to find orthogonal projection\n",
    "        onto intersection of convex sets\n",
    "        \"\"\"\n",
    "        xk = x.copy()\n",
    "        d = len(x)\n",
    "        pk, qk = np.zeros(d), np.zeros(d)\n",
    "        for k in range(iter_proj):\n",
    "            yk = self._Π_2(xk + pk, D)\n",
    "            pk = xk + pk - yk\n",
    "            if np.linalg.norm(self._Π_1(yk + qk, b) - xk, 2) <= epsilon:\n",
    "                break\n",
    "            else:\n",
    "                xk = self._Π_1(yk + qk, b)\n",
    "                qk = yk + qk - xk\n",
    "        return xk\n",
    "\n",
    "    def sgd(self, x, fc, ref, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Φ_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        d = self.d\n",
    "        \n",
    "                \n",
    "\n",
    "        # Get general information\n",
    "        feature_names = list(x.index)\n",
    "        f_x, f_r = fc(x.values), fc(ref.values)\n",
    "        v_M = f_x - f_r\n",
    "\n",
    "\n",
    "        \n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_ω_k = self.dict_ω_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Φ_0:\n",
    "            Φ = Φ_0.copy()\n",
    "        else:\n",
    "            Φ = np.zeros(d)\n",
    "        Φ_storage = np.zeros((n_iter,d))\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Φ = self._Dykstra_proj(Φ, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        Φ = Φ - (np.sum(Φ) - v_M) / d\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        \n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])\n",
    "            f_S = fc(z_S)\n",
    "            y_i = f_S - f_r\n",
    "            # get weight ω_i\n",
    "            ω_i = dict_ω_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Φ, x_i, y_i, ω_i)\n",
    "            # update Φ\n",
    "            if step_type == \"constant\":\n",
    "                Φ = Φ - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                Φ = Φ - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                Φ = Φ - (step/(t)) * grad_i\n",
    "\n",
    "            # projection onto convex set K\n",
    "            # Φ = self._Dykstra_proj(Φ, D, v_M, iter_proj, epsilon=1e-6)\n",
    "            Φ = Φ - (Φ.sum() - v_M) / d\n",
    "\n",
    "            # update storage of Φ\n",
    "            Φ_storage[t-1,:] = Φ\n",
    "\n",
    "            if callback and (t % d == 0):\n",
    "                callback(pd.Series(np.mean(Φ_storage[:t,:],axis=0), index=feature_names))\n",
    "\n",
    "        # Average all Φ\n",
    "        Φ = pd.Series(np.mean(Φ_storage,axis=0), index=feature_names)\n",
    "\n",
    "        return Φ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa57a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfd739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eac64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_players=10\n",
    "batch_size=5\n",
    "\n",
    "permutations = np.tile(np.arange(num_players), (batch_size, 1))\n",
    "arange = np.arange(batch_size)\n",
    "n = 0\n",
    "print(arange, arange.shape)\n",
    "print(permutations, permutations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin sampling.\n",
    "for it in range(5):\n",
    "    for i in range(batch_size):\n",
    "        np.random.shuffle(permutations[i])\n",
    "    S = np.zeros((batch_size, num_players), dtype=bool)\n",
    "    \n",
    "    # Sample exogenous (if applicable).\n",
    "\n",
    "    # Unroll permutations.\n",
    "    for i in range(num_players):\n",
    "        S[arange, permutations[:, i]] = 1\n",
    "        print(S)\n",
    "    break\n",
    "    print('loop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "S[arange, permutations[:, i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb53ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S[:, permutations[:, i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc55257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a69ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDshapley(d=196, C=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(np.array(list(sgd_shapley.dict_L_k.values())))), np.array(list(sgd_shapley.dict_L_k.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffb338",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.choice(list(range(1, sgd_shapley.d)), size=1000, p=sgd_shapley.q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55708b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.choice(list(range(1, sgd_shapley.d)), size=1000, p=sgd_shapley.p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2893748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989a8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c984d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7da4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37228da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e1125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import read_eval_results\n",
    "\n",
    "\n",
    "class ShapleyValues:\n",
    "    \"\"\"For storing and plotting Shapley values.\"\"\"\n",
    "\n",
    "    def __init__(self, values, std):\n",
    "        self.values = values\n",
    "        self.std = std\n",
    "\n",
    "    def plot(\n",
    "        self,\n",
    "        feature_names=None,\n",
    "        sort_features=True,\n",
    "        max_features=np.inf,\n",
    "        orientation=\"horizontal\",\n",
    "        error_bars=True,\n",
    "        color=\"C0\",\n",
    "        title=\"Feature Importance\",\n",
    "        title_size=20,\n",
    "        tick_size=16,\n",
    "        tick_rotation=None,\n",
    "        axis_label=\"\",\n",
    "        label_size=16,\n",
    "        figsize=(10, 7),\n",
    "        return_fig=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot Shapley values.\n",
    "\n",
    "        Args:\n",
    "        feature_names: list of feature names.\n",
    "        sort_features: whether to sort features by their Shapley values.\n",
    "        max_features: number of features to display.\n",
    "        orientation: horizontal (default) or vertical.\n",
    "        error_bars: whether to include standard deviation error bars.\n",
    "        color: bar chart color.\n",
    "        title: plot title.\n",
    "        title_size: font size for title.\n",
    "        tick_size: font size for feature names and numerical values.\n",
    "        tick_rotation: tick rotation for feature names (vertical plots only).\n",
    "        label_size: font size for label.\n",
    "        figsize: figure size (if fig is None).\n",
    "        return_fig: whether to return matplotlib figure object.\n",
    "        \"\"\"\n",
    "        return plotting.plot(\n",
    "            self,\n",
    "            feature_names,\n",
    "            sort_features,\n",
    "            max_features,\n",
    "            orientation,\n",
    "            error_bars,\n",
    "            color,\n",
    "            title,\n",
    "            title_size,\n",
    "            tick_size,\n",
    "            tick_rotation,\n",
    "            axis_label,\n",
    "            label_size,\n",
    "            figsize,\n",
    "            return_fig,\n",
    "        )\n",
    "\n",
    "\n",
    "def default_min_variance_samples(game):\n",
    "    \"\"\"Determine min_variance_samples.\"\"\"\n",
    "    return 5\n",
    "\n",
    "\n",
    "def default_variance_batches(num_players, batch_size):\n",
    "    \"\"\"\n",
    "    Determine variance_batches.\n",
    "\n",
    "    This value tries to ensure that enough samples are included to make A\n",
    "    approximation non-singular.\n",
    "    \"\"\"\n",
    "\n",
    "    return int(np.ceil(10 * num_players / batch_size))\n",
    "\n",
    "\n",
    "def calculate_result(A, b, total):\n",
    "    \"\"\"Calculate the regression coefficients.\"\"\"\n",
    "    num_players = A.shape[1]\n",
    "    try:\n",
    "        if len(b.shape) == 2:\n",
    "            A_inv_one = np.linalg.solve(A, np.ones((num_players, 1)))\n",
    "        else:\n",
    "            A_inv_one = np.linalg.solve(A, np.ones(num_players))\n",
    "        A_inv_vec = np.linalg.solve(A, b)\n",
    "        values = A_inv_vec - A_inv_one * (\n",
    "            np.sum(A_inv_vec, axis=0, keepdims=True) - total\n",
    "        ) / np.sum(A_inv_one)\n",
    "    except np.linalg.LinAlgError:\n",
    "        raise ValueError(\n",
    "            \"singular matrix inversion. Consider using larger \" \"variance_batches\"\n",
    "        )\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def ShapleyRegressionPrecomputed(\n",
    "    grand_value,\n",
    "    null_value,\n",
    "    model_outputs,\n",
    "    masks,\n",
    "    num_players,\n",
    "    batch_size=512,\n",
    "    detect_convergence=True,\n",
    "    thresh=0.01,\n",
    "    n_samples=None,\n",
    "    paired_sampling=True,\n",
    "    return_all=False,\n",
    "    min_variance_samples=None,\n",
    "    variance_batches=None,\n",
    "    bar=True,\n",
    "    verbose=False,\n",
    "):\n",
    "    # Verify arguments.\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    if min_variance_samples is None:\n",
    "        min_variance_samples = 5\n",
    "    else:\n",
    "        assert isinstance(min_variance_samples, int)\n",
    "        assert min_variance_samples > 1\n",
    "\n",
    "    if variance_batches is None:\n",
    "        variance_batches = default_variance_batches(num_players, batch_size)\n",
    "    else:\n",
    "        assert isinstance(variance_batches, int)\n",
    "        assert variance_batches >= 1\n",
    "\n",
    "    # Possibly force convergence detection.\n",
    "    if n_samples is None:\n",
    "        n_samples = 1e20\n",
    "        if not detect_convergence:\n",
    "            detect_convergence = True\n",
    "            if verbose:\n",
    "                print(\"Turning convergence detection on\")\n",
    "\n",
    "    if detect_convergence:\n",
    "        assert 0 < thresh < 1\n",
    "\n",
    "    # Weighting kernel (probability of each subset size).\n",
    "    weights = np.arange(1, num_players)\n",
    "    weights = 1 / (weights * (num_players - weights))\n",
    "    weights = weights / np.sum(weights)\n",
    "\n",
    "    # Calculate null and grand coalitions for constraints.\n",
    "    null = null_value\n",
    "    grand = grand_value\n",
    "\n",
    "    # Calculate difference between grand and null coalitions.\n",
    "    total = grand - null\n",
    "\n",
    "    # Set up bar.\n",
    "    n_loops = int(np.ceil(n_samples / batch_size))\n",
    "    if bar:\n",
    "        if detect_convergence:\n",
    "            bar = tqdm(total=1)\n",
    "        else:\n",
    "            bar = tqdm(total=n_loops * batch_size)\n",
    "\n",
    "    # Setup.\n",
    "    n = 0\n",
    "    b = 0\n",
    "    A = 0\n",
    "    estimate_list = []\n",
    "\n",
    "    # For variance estimation.\n",
    "    A_sample_list = []\n",
    "    b_sample_list = []\n",
    "\n",
    "    # For tracking progress.\n",
    "    var = np.nan * np.ones(num_players)\n",
    "    if return_all:\n",
    "        N_list = []\n",
    "        std_list = []\n",
    "        val_list = []\n",
    "\n",
    "    # Begin sampling.\n",
    "    for it in range(n_loops):\n",
    "        # Sample subsets.\n",
    "        # print(subsets.shape)\n",
    "        S = masks[batch_size * it : batch_size * (it + 1)]\n",
    "        game_S = model_outputs[batch_size * it : batch_size * (it + 1)]\n",
    "        #         print(\"S\", S, S.sum(axis=1))\n",
    "        #         print(\"game(s)\", game_S)\n",
    "        #         print(\"game(s)-null\", game_S-null)\n",
    "\n",
    "        A_sample = np.matmul(\n",
    "            S[:, :, np.newaxis].astype(float), S[:, np.newaxis, :].astype(float)\n",
    "        )\n",
    "\n",
    "        b_sample = (S.astype(float).T * (game_S - null)[:, np.newaxis].T).T\n",
    "\n",
    "        #         print(\"b\", b_sample)\n",
    "        #         print(\"variance_batches\", variance_batches)\n",
    "\n",
    "        # Welford's algorithm.\n",
    "        n += batch_size\n",
    "        b += np.sum(b_sample - b, axis=0) / n\n",
    "        A += np.sum(A_sample - A, axis=0) / n\n",
    "\n",
    "        # Calculate progress.\n",
    "        values = calculate_result(A, b, total)\n",
    "        A_sample_list.append(A_sample)\n",
    "        b_sample_list.append(b_sample)\n",
    "        if len(A_sample_list) == variance_batches:\n",
    "            # Aggregate samples for intermediate estimate.\n",
    "            A_sample = np.concatenate(A_sample_list, axis=0).mean(axis=0)\n",
    "            b_sample = np.concatenate(b_sample_list, axis=0).mean(axis=0)\n",
    "            A_sample_list = []\n",
    "            b_sample_list = []\n",
    "\n",
    "            # Add new estimate.\n",
    "            estimate_list.append(calculate_result(A_sample, b_sample, total))\n",
    "\n",
    "            # Estimate current var.\n",
    "            # print(len(estimate_list), min_variance_samples)\n",
    "            if len(estimate_list) >= min_variance_samples:\n",
    "                var = np.array(estimate_list).var(axis=0)\n",
    "\n",
    "        # Convergence ratio.\n",
    "        std = np.sqrt(var * variance_batches / (it + 1))\n",
    "        ratio = np.max(np.max(std, axis=0) / (values.max(axis=0) - values.min(axis=0)))\n",
    "        # print(\"std\", var)\n",
    "        # Print progress message.\n",
    "        if verbose:\n",
    "            if detect_convergence:\n",
    "                print(f\"StdDev Ratio = {ratio:.4f} (Converge at {thresh:.4f})\")\n",
    "            else:\n",
    "                print(f\"StdDev Ratio = {ratio:.4f}\")\n",
    "\n",
    "        # Check for convergence.\n",
    "        if detect_convergence:\n",
    "            if ratio < thresh:\n",
    "                if verbose:\n",
    "                    print(\"Detected convergence\")\n",
    "\n",
    "                # Skip bar ahead.\n",
    "                if bar:\n",
    "                    bar.n = bar.total\n",
    "                    bar.refresh()\n",
    "                break\n",
    "\n",
    "        # Forecast number of iterations required.\n",
    "        if detect_convergence:\n",
    "            N_est = (it + 1) * (ratio / thresh) ** 2\n",
    "            if bar and not np.isnan(N_est):\n",
    "                bar.n = np.around((it + 1) / N_est, 4)\n",
    "                bar.refresh()\n",
    "        elif bar:\n",
    "            bar.update(batch_size)\n",
    "\n",
    "        # Save intermediate quantities.\n",
    "        if return_all:\n",
    "            val_list.append(values)\n",
    "            std_list.append(std)\n",
    "            if detect_convergence:\n",
    "                N_list.append(N_est)\n",
    "\n",
    "        # print(\"size\", batch_size*it, len(masks))\n",
    "        if batch_size * (it + 1) >= len(masks):\n",
    "            break\n",
    "    # print(ratio)\n",
    "    # Return results.\n",
    "    if return_all:\n",
    "        # Dictionary for progress tracking.\n",
    "        iters = (np.arange(it + 1) + 1) * batch_size * (1)\n",
    "        tracking_dict = {\"values\": val_list, \"std\": std_list, \"iters\": iters}\n",
    "        if detect_convergence:\n",
    "            tracking_dict[\"N_est\"] = N_list\n",
    "\n",
    "        return ShapleyValues(values, std), tracking_dict, ratio\n",
    "    else:\n",
    "        return ShapleyValues(values, std), ratio\n",
    "\n",
    "\n",
    "# def read_eval_results(path):\n",
    "#     file_set = set(\n",
    "#         [\n",
    "#             p\n",
    "#             for p in glob.glob(str(Path(path) / \"*.pt\"))\n",
    "#             if p.split(\"/\")[-1] != \"shapley_output.pt\"\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     path_grand_null = str(Path(path) / \"grand_null.pt\")\n",
    "#     file_set.remove(path_grand_null)\n",
    "\n",
    "#     file_list = sorted(list(file_set), key=lambda x: x.split(\"_\")[-2])\n",
    "#     begin_idx = int(file_list[0].split(\"_\")[-2])\n",
    "#     end_idx = int(file_list[0].split(\"_\")[-1].replace(\".pt\", \"\"))\n",
    "#     step_size = end_idx - begin_idx\n",
    "\n",
    "#     idx = begin_idx\n",
    "\n",
    "#     path_eval_list = []\n",
    "#     while True:\n",
    "#         path_eval = str(Path(path) / f\"mask_eval_{idx}_{idx+step_size}.pt\")\n",
    "#         if path_eval in file_set:\n",
    "#             file_set.remove(path_eval)\n",
    "#             path_eval_list.append(path_eval)\n",
    "#         else:\n",
    "#             break\n",
    "#         idx += step_size\n",
    "\n",
    "#     assert len(file_set) == 0\n",
    "\n",
    "#     grand_null = torch.load(path_grand_null)\n",
    "#     eval_list = [torch.load(path_eval) for path_eval in path_eval_list]\n",
    "\n",
    "#     grand_logits = grand_null[\"logits\"][0]\n",
    "#     grand_masks = grand_null[\"masks\"][0]\n",
    "#     null_logits = grand_null[\"logits\"][1]\n",
    "#     nulll_masks = grand_null[\"masks\"][1]\n",
    "\n",
    "#     eval_logits = np.concatenate(\n",
    "#         [eval_value[\"logits\"] for eval_value in eval_list], axis=0\n",
    "#     )\n",
    "#     eval_masks = np.concatenate(\n",
    "#         [eval_value[\"masks\"] for eval_value in eval_list], axis=0\n",
    "#     )\n",
    "\n",
    "#     return {\n",
    "#         \"grand\": {\"logits\": grand_logits, \"masks\": grand_masks},\n",
    "#         \"null\": {\"logits\": null_logits, \"masks\": nulll_masks},\n",
    "#         \"subsets\": {\"logits\": eval_logits, \"masks\": eval_masks},\n",
    "#     }\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Parse the command line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Process some inputs.\")\n",
    "\n",
    "    # Argument for batch size without default\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\", type=int, required=True, help=\"The batch size for processing.\"\n",
    "    )\n",
    "\n",
    "    # Argument for input path without default\n",
    "    parser.add_argument(\n",
    "        \"--input_path\", type=str, required=True, help=\"Path to the input directory.\"\n",
    "    )\n",
    "\n",
    "    # Argument for normalization function\n",
    "    parser.add_argument(\n",
    "        \"--normalize_function\",\n",
    "        type=str,\n",
    "        choices=[\"softmax\"],\n",
    "        required=True,\n",
    "        help=\"The normalization function to be used. Options: softmax.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--num_players\", type=int, required=True, help=\"The number of players\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--target_subset_size\",\n",
    "        type=int,\n",
    "        required=False,\n",
    "        default=None,\n",
    "        help=\"The target subset size\",\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "--input_path logs/vitbase_imagenette_surrogate_eval_train/extract_output/train \\\n",
    "--batch_size 512 \\\n",
    "--normalize_function softmax \\\n",
    "--num_players 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17010389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the arguments\n",
    "batch_size = 512\n",
    "input_path = \"logs/vitbase_imagenette_surrogate_eval_train/extract_output/train\"\n",
    "if \"softmax\" == \"softmax\":\n",
    "    normalize_function = softmax\n",
    "else:\n",
    "    raise ValueError(\"Unsupported normalization function\")\n",
    "num_players = 196\n",
    "target_subset_size = None\n",
    "\n",
    "sample_list = glob.glob(str(Path(input_path) / \"[0-9]*\"))\n",
    "\n",
    "pbar = tqdm(sample_list)\n",
    "subsets_output_prev = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee694683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_eval_train/extract_output/train/610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a189cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_path in pbar:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c299782",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = read_eval_results(path=sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb30a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/sgd_shapley.ipynb (unless otherwise specified).\n",
    "\n",
    "__all__ = ['ncr', 'SGDshapley']\n",
    "\n",
    "# Cell\n",
    "# Author: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#         Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cell\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "# Cell\n",
    "class SGDshapley():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, num_classes, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_ω_k = dict() # weights per size k\n",
    "        dict_L_k = dict() # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            ω_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = ω_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_ω_k.update({k: ω_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "        # Probability distributions for sampling new instance\n",
    "        # Classic SGD\n",
    "        p = [ncr(d,k) for k in range(1,d)]\n",
    "        print('p', p)\n",
    "        p /= np.sum(p)\n",
    "        print(dict_L_k)\n",
    "        # Importance Sampling proposal q\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.num_classes=num_classes\n",
    "        self.d = d\n",
    "        self.n = 2**d - 2\n",
    "        self.dict_ω_k = dict_ω_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _F_i(self, Φ, x_i, y_i, ω_i):\n",
    "        \"\"\"Function value per instance i\"\"\"\n",
    "        res = .5 * self.n * ω_i * (np.dot(x_i, Φ) - y_i)**2\n",
    "        return res\n",
    "\n",
    "    def _grad_F_i(self, Φ, x_i, y_i, ω_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        res = ω_i * x_i[:,None].dot(x_i[None,:]).dot(Φ) - ω_i * y_i * x_i\n",
    "        return res\n",
    "\n",
    "    def _Π_1(self, x, b):\n",
    "        \"\"\"Projection Π on convex set K_1\"\"\"\n",
    "        if np.abs((np.sum(x) - b)) <= 1e-6:\n",
    "            return x\n",
    "        else:\n",
    "            return x - (np.sum(x) - b)/len(x)\n",
    "\n",
    "    def _Π_2(self, x, D):\n",
    "        \"\"\"Projection Π on convex set K_2\"\"\"\n",
    "        if np.linalg.norm(x) > D:\n",
    "            return x * D / np.linalg.norm(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _Dykstra_proj(self, x, D, b, iter_proj=100, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Dykstra's algorithm to find orthogonal projection\n",
    "        onto intersection of convex sets\n",
    "        \"\"\"\n",
    "        xk = x.copy()\n",
    "        d = len(x)\n",
    "        pk, qk = np.zeros(d), np.zeros(d)\n",
    "        for k in range(iter_proj):\n",
    "            yk = self._Π_2(xk + pk, D)\n",
    "            pk = xk + pk - yk\n",
    "            if np.linalg.norm(self._Π_1(yk + qk, b) - xk, 2) <= epsilon:\n",
    "                break\n",
    "            else:\n",
    "                xk = self._Π_1(yk + qk, b)\n",
    "                qk = yk + qk - xk\n",
    "        return xk\n",
    "\n",
    "    def sgd(self, x, fc, ref, \n",
    "            f_x, f_r,\n",
    "            n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Φ_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        feature_names = list(x.index)\n",
    "#         f_x, f_r = fc(x.values), fc(ref.values)\n",
    "        v_M = f_x - f_r\n",
    "\n",
    "        num_classes=self.num_classes\n",
    "        d = self.d\n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_ω_k = self.dict_ω_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Φ_0:\n",
    "            Φ = Φ_0.copy()\n",
    "        else:\n",
    "            Φ = np.zeros((d, num_classes))\n",
    "        Φ_storage = np.zeros((n_iter,d, num_classes))\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Φ = self._Dykstra_proj(Φ, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        #print(Φ.shape) # (num_features, num_classes)\n",
    "        #print(v_M)\n",
    "        Φ = Φ - (np.sum(Φ) - v_M) / d\n",
    "        #print(Φ.shape)\n",
    "        #print(Φ.sum(axis=0))\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "#         print(list_k)\n",
    "        print(q)\n",
    "        plt.hist(list_k)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])\n",
    "            f_S = fc(z_S)\n",
    "            y_i = f_S - f_r\n",
    "            # get weight ω_i\n",
    "            ω_i = dict_ω_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Φ, x_i, y_i, ω_i)\n",
    "            # update Φ\n",
    "            if step_type == \"constant\":\n",
    "                Φ = Φ - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                Φ = Φ - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                Φ = Φ - (step/(t)) * grad_i\n",
    "\n",
    "            # projection onto convex set K\n",
    "            # Φ = self._Dykstra_proj(Φ, D, v_M, iter_proj, epsilon=1e-6)\n",
    "            Φ = Φ - (Φ.sum() - v_M) / d\n",
    "\n",
    "            # update storage of Φ\n",
    "            Φ_storage[t-1,:] = Φ\n",
    "\n",
    "            if callback and (t % d == 0):\n",
    "                callback(pd.Series(np.mean(Φ_storage[:t,:],axis=0), index=feature_names))\n",
    "\n",
    "        # Average all Φ\n",
    "        Φ = pd.Series(np.mean(Φ_storage,axis=0), index=feature_names)\n",
    "\n",
    "        return Φ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDshapley(d=num_players, \n",
    "                       C=partial(normalize_function, axis=0)(eval_results[\"grand\"][\"logits\"]).max(),\n",
    "                       num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffea095",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley.sgd(x=pd.DataFrame(np.ones(100)).iloc[:,0],\n",
    "                f_x=grand_value, \n",
    "                f_r=null_value, \n",
    "                n_iter=1000,\n",
    "                fc=None, \n",
    "                ref=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e37f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daebf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da491d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_path in pbar:\n",
    "    eval_results = read_eval_results(path=sample_path)\n",
    "\n",
    "    grand_value = eval_results[\"grand\"][\"logits\"]\n",
    "    if len(grand_value.shape) == 1:\n",
    "        grand_value = partial(normalize_function, axis=0)(grand_value)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Not supported grand shape {grand_value.shape}\")\n",
    "\n",
    "    null_value = eval_results[\"null\"][\"logits\"]\n",
    "    if len(null_value.shape) == 1:\n",
    "        null_value = partial(normalize_function, axis=0)(null_value)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Not supported null shape {null_value.shape}\")\n",
    "\n",
    "    subsets_output = eval_results[\"subsets\"][\"logits\"]\n",
    "    if len(subsets_output.shape) == 2:\n",
    "        subsets_output = partial(normalize_function, axis=1)(subsets_output)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Not supported subset outputs shape {subsets_output.shape}\"\n",
    "        )\n",
    "    if subsets_output_prev is not None and len(subsets_output) != len(\n",
    "        subsets_output_prev\n",
    "    ):\n",
    "        print(\n",
    "            \"subsets_output_prev\",\n",
    "            subsets_output_prev.shape,\n",
    "            \"subsets_output\",\n",
    "            subsets_output.shape,\n",
    "            \"sample_path\",\n",
    "            sample_path,\n",
    "        )\n",
    "\n",
    "    subsets = eval_results[\"subsets\"][\"masks\"]\n",
    "\n",
    "    assert (\n",
    "        subsets_output.shape[1] == grand_value.shape[0] == null_value.shape[0]\n",
    "    ), f\"Num of classes mismatch {subsets_output.shape[1]} , {grand_value.shape[0]} , {null_value.shape[0]}\"\n",
    "    assert (\n",
    "        subsets.shape[1] == num_players\n",
    "    ), f\"Num of players mismatch {subsets.shape[1]} != {num_players}\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba009fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5373eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.ones(100)).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley.sgd(x=1,fc=None, ref=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624189a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ebf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, fc, ref, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Φ_0=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDshapley(d=num_players, \n",
    "                       C=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e453e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley.sum_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3753bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1e4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dee7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        null_value = partial(normalize_function, axis=0)(null_value)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Not supported null shape {null_value.shape}\")\n",
    "\n",
    "    subsets_output = eval_results[\"subsets\"][\"logits\"]\n",
    "    if len(subsets_output.shape) == 2:\n",
    "        subsets_output = partial(normalize_function, axis=1)(subsets_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(normalize_function, axis=0)(eval_results[\"grand\"][\"logits\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc488e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(normalize_function, axis=0)(eval_results[\"grand\"][\"logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b584c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(normalize_function, axis=1)(eval_results[\"subsets\"][\"logits\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[\"subsets\"][\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a822074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dd0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_path in pbar:\n",
    "    eval_results = read_eval_results(path=sample_path)\n",
    "\n",
    "    grand_value = eval_results[\"grand\"][\"logits\"]\n",
    "    if len(grand_value.shape) == 1:\n",
    "        grand_value = partial(normalize_function, axis=0)(grand_value)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Not supported grand shape {grand_value.shape}\")\n",
    "\n",
    "    null_value = eval_results[\"null\"][\"logits\"]\n",
    "    if len(null_value.shape) == 1:\n",
    "        null_value = partial(normalize_function, axis=0)(null_value)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Not supported null shape {null_value.shape}\")\n",
    "\n",
    "    subsets_output = eval_results[\"subsets\"][\"logits\"]\n",
    "    if len(subsets_output.shape) == 2:\n",
    "        subsets_output = partial(normalize_function, axis=1)(subsets_output)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Not supported subset outputs shape {subsets_output.shape}\"\n",
    "        )\n",
    "    if subsets_output_prev is not None and len(subsets_output) != len(\n",
    "        subsets_output_prev\n",
    "    ):\n",
    "        print(\n",
    "            \"subsets_output_prev\",\n",
    "            subsets_output_prev.shape,\n",
    "            \"subsets_output\",\n",
    "            subsets_output.shape,\n",
    "            \"sample_path\",\n",
    "            sample_path,\n",
    "        )\n",
    "\n",
    "    subsets = eval_results[\"subsets\"][\"masks\"]\n",
    "\n",
    "    assert (\n",
    "        subsets_output.shape[1] == grand_value.shape[0] == null_value.shape[0]\n",
    "    ), f\"Num of classes mismatch {subsets_output.shape[1]} , {grand_value.shape[0]} , {null_value.shape[0]}\"\n",
    "    assert (\n",
    "        subsets.shape[1] == num_players\n",
    "    ), f\"Num of players mismatch {subsets.shape[1]} != {num_players}\"\n",
    "    sdsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if target_subset_size is None:\n",
    "        _, tracking_dict, ratio = ShapleyRegressionPrecomputed(\n",
    "            grand_value=grand_value,\n",
    "            null_value=null_value,\n",
    "            model_outputs=subsets_output,\n",
    "            masks=subsets,\n",
    "            batch_size=batch_size,\n",
    "            num_players=num_players,\n",
    "            variance_batches=2,\n",
    "            min_variance_samples=2,\n",
    "            return_all=True,\n",
    "            bar=False,\n",
    "        )\n",
    "\n",
    "#         torch.save(\n",
    "#             obj=tracking_dict, f=str(Path(sample_path) / \"shapley_output.pt\")\n",
    "#         )\n",
    "    else:\n",
    "        for subset_group_idx in range(len(subsets_output) // target_subset_size):\n",
    "            _, tracking_dict, ratio = ShapleyRegressionPrecomputed(\n",
    "                grand_value=grand_value,\n",
    "                null_value=null_value,\n",
    "                model_outputs=subsets_output[\n",
    "                    target_subset_size\n",
    "                    * subset_group_idx : target_subset_size\n",
    "                    * (subset_group_idx + 1)\n",
    "                ],\n",
    "                masks=subsets[\n",
    "                    target_subset_size\n",
    "                    * subset_group_idx : target_subset_size\n",
    "                    * (subset_group_idx + 1)\n",
    "                ],\n",
    "                batch_size=batch_size,\n",
    "                num_players=num_players,\n",
    "                variance_batches=2,\n",
    "                min_variance_samples=2,\n",
    "                return_all=True,\n",
    "                bar=False,\n",
    "            )\n",
    "\n",
    "#             torch.save(\n",
    "#                 obj=tracking_dict,\n",
    "#                 f=str(\n",
    "#                     Path(sample_path)\n",
    "#                     / f\"shapley_output_{target_subset_size}_{subset_group_idx}.pt\"\n",
    "#                 ),\n",
    "#             )\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        ratio=ratio,\n",
    "        num_masks=len(subsets),\n",
    "        refresh=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
