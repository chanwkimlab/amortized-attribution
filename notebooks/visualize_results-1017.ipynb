{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv=[\"train_objexplainer.py\", \"configs/vitbase_imagenette_shapley_objexplainer_newsample_32.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9562d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import evaluate\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from arguments import DataTrainingArguments, ExplainerArguments, SurrogateArguments\n",
    "from models import (\n",
    "    ObjExplainerForImageClassification,\n",
    "    ObjExplainerForImageClassificationConfig,\n",
    "    SurrogateForImageClassificationConfig,\n",
    ")\n",
    "from utils import (\n",
    "    MaskDataset,\n",
    "    configure_dataset,\n",
    "    generate_mask,\n",
    "    get_checkpoint,\n",
    "    get_image_transform,\n",
    "    load_shapley,\n",
    "    log_dataset,\n",
    "    read_eval_results,\n",
    "    setup_dataset,\n",
    ")\n",
    "\n",
    "\"\"\" Fine-tuning a ðŸ¤— Transformers model for image classification\"\"\"\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.32.0.dev0\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/image-classification/requirements.txt\",\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OtherArguments:\n",
    "    token: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n",
    "                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    validation_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    test_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    train_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for train\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    validation_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for validation\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    test_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for test\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Parse arguments\n",
    "#######################################################\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "parser = HfArgumentParser(\n",
    "    (\n",
    "        SurrogateArguments,\n",
    "        ExplainerArguments,\n",
    "        DataTrainingArguments,\n",
    "        TrainingArguments,\n",
    "        OtherArguments,\n",
    "    )\n",
    ")\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "else:\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_args_into_dataclasses()\n",
    "\n",
    "########################################################\n",
    "# Setup logging\n",
    "#######################################################\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "if training_args.should_log:\n",
    "    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "########################################################\n",
    "# Correct cache dir if necessary\n",
    "########################################################\n",
    "if not os.path.exists(\n",
    "    os.sep.join((data_args.dataset_cache_dir).split(os.sep, 2)[:2])\n",
    "):\n",
    "    if os.path.exists(\"/data2\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/data2\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    elif os.path.exists(\"/sdata\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/sdata\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Set seed before initializing model.\n",
    "########################################################\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "########################################################\n",
    "# Initialize our dataset and prepare it for the 'image-classification' task.\n",
    "########################################################\n",
    "dataset_original, labels, label2id, id2label = setup_dataset(\n",
    "    data_args=data_args, other_args=other_args\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Initialize explainer model\n",
    "########################################################\n",
    "\n",
    "explainer_config = AutoConfig.from_pretrained(\n",
    "    explainer_args.explainer_config_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "if os.path.isfile(\n",
    "    f\"{explainer_args.explainer_model_name_or_path}/config.json\"\n",
    ") and (\n",
    "    json.loads(\n",
    "        open(f\"{explainer_args.explainer_model_name_or_path}/config.json\").read()\n",
    "    )[\"architectures\"][0]\n",
    "    == \"ObjExplainerForImageClassification\"\n",
    "):\n",
    "    explainer = ObjExplainerForImageClassification.from_pretrained(\n",
    "        explainer_args.explainer_model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "        config=explainer_config,\n",
    "        cache_dir=explainer_args.explainer_cache_dir,\n",
    "        revision=explainer_args.explainer_model_revision,\n",
    "        token=other_args.token,\n",
    "        ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "else:\n",
    "    surrogate_config = AutoConfig.from_pretrained(\n",
    "        surrogate_args.surrogate_config_name\n",
    "        or surrogate_args.surrogate_model_name_or_path,\n",
    "        num_labels=len(labels),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        finetuning_task=\"image-classification\",\n",
    "        cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        revision=surrogate_args.surrogate_model_revision,\n",
    "        token=other_args.token,\n",
    "    )\n",
    "    surrogate_for_image_classification_config = SurrogateForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer_for_image_classification_config = ObjExplainerForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_for_image_classification_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "        explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "        explainer_config=explainer_config,\n",
    "        explainer_from_tf=bool(\n",
    "            \".ckpt\" in explainer_args.explainer_model_name_or_path\n",
    "        ),\n",
    "        explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "        explainer_revision=explainer_args.explainer_model_revision,\n",
    "        explainer_token=other_args.token,\n",
    "        explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer = ObjExplainerForImageClassification(\n",
    "        config=explainer_for_image_classification_config,\n",
    "    )\n",
    "explainer_image_processor = AutoImageProcessor.from_pretrained(\n",
    "    explainer_args.explainer_image_processor_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Configure dataset (set max samples, transforms, etc.)\n",
    "########################################################\n",
    "dataset_explainer = copy.deepcopy(dataset_original)\n",
    "dataset_explainer = configure_dataset(\n",
    "    dataset=dataset_explainer,\n",
    "    image_processor=explainer_image_processor,\n",
    "    training_args=training_args,\n",
    "    data_args=data_args,\n",
    "    train_augmentation=False,\n",
    "    validation_augmentation=False,\n",
    "    test_augmentation=False,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c1271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9592e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import (\n",
    "    RegExplainerForImageClassification,\n",
    "    RegExplainerForImageClassificationConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer_for_image_classification_config = RegExplainerForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "    surrogate_config=surrogate_for_image_classification_config,\n",
    "    surrogate_from_tf=bool(\".ckpt\" in surrogate_args.surrogate_model_name_or_path),\n",
    "    surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "    surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "    surrogate_token=other_args.token,\n",
    "    surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "    explainer_config=explainer_config,\n",
    "    explainer_from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "    explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "    explainer_revision=explainer_args.explainer_model_revision,\n",
    "    explainer_token=other_args.token,\n",
    "    explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    ")\n",
    "\n",
    "regexplainer = RegExplainerForImageClassification(\n",
    "    config=regexplainer_for_image_classification_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd178b9",
   "metadata": {},
   "source": [
    "# move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a00e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf86c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcf98f",
   "metadata": {},
   "source": [
    "# visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405550b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_figure(explainer, dataset, sample_idx_list):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                explainer.eval()\n",
    "                with torch.no_grad():\n",
    "                    explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "                    explanation=explanation[\"logits\"][0]\n",
    "                #print(explanation.shape)\n",
    "                if len(explanation.shape)==2:\n",
    "                    explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "                else:\n",
    "                    explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=mpl.colormaps['Greys'](1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_figure_shapley(dataset, sample_idx_list, shapley_value, shapley_value_key):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(shapley_value[sample_idx].keys()))\n",
    "                #print(plot_type, shapley_value[sample_idx][shapley_value_key].shape)\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(shapley_value[sample_idx][\"iters\"], shapley_value[sample_idx][\"values\"])}[shapley_value_key][:,plot_type]\n",
    "                \n",
    "                #print(explanation_class.shape)\n",
    "#                 print(explanation_class.shape, plot_type)\n",
    "#                 explainer.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "#                     explanation=explanation[\"logits\"][0]\n",
    "#                 if len(explanation.shape)==2:\n",
    "#                     explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "#                 else:\n",
    "#                     explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "    return fig           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4717880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_metric_with_explainer(shapley_values, explainer, dataset, iters_ground_truth, meta_info):\n",
    "    record_dict_list=[]\n",
    "    \n",
    "    for sample_idx, tracking_dict in tqdm(shapley_values.items()):\n",
    "        data=dataset[sample_idx]\n",
    "        \n",
    "        target_class_idx=np.argmax(tracking_dict[\"values\"][0].sum(axis=0))\n",
    "        assert data[\"labels\"]==target_class_idx\n",
    "        \n",
    "        explainer.eval()\n",
    "        with torch.no_grad():\n",
    "            estimated=explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "            \n",
    "        if isinstance(tracking_dict[\"iters\"], np.ndarray):\n",
    "            tracking_dict[\"iters\"]=tracking_dict[\"iters\"].tolist()\n",
    "        \n",
    "        ground_truth=tracking_dict[\"values\"][tracking_dict[\"iters\"].index(iters_ground_truth)]\n",
    "            \n",
    "        diff=(estimated.T.cpu().detach().numpy()-ground_truth)\n",
    "        \n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record={\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "        }\n",
    "        record.update(meta_info)\n",
    "        \n",
    "        record_dict_list.append(record)\n",
    "        \n",
    "    return record_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_metric_with_value(shapley_values_ground_truth, iters_ground_truth, \n",
    "                                       shapley_values_calculated, iters_calculated, \n",
    "                                       meta_info):\n",
    "#     print(shapley_values_ground_truth.keys())\n",
    "    \n",
    "    record_dict_list=[]\n",
    "    \n",
    "    for sample_idx, tracking_dict_ground_truth in tqdm(shapley_values_ground_truth.items()):\n",
    "        target_class_idx_ground_truth=np.argmax(tracking_dict_ground_truth[\"values\"][0].sum(axis=0))\n",
    "        \n",
    "        tracking_dict_calculated=shapley_values_calculated[sample_idx]\n",
    "        target_class_idx_calculated=np.argmax(tracking_dict_calculated[\"values\"][0].sum(axis=0))         \n",
    "        \n",
    "        assert target_class_idx_ground_truth==target_class_idx_calculated\n",
    "        \n",
    "        if isinstance(tracking_dict_ground_truth[\"iters\"], np.ndarray):\n",
    "            tracking_dict_ground_truth[\"iters\"]=tracking_dict_ground_truth[\"iters\"].tolist()\n",
    "            \n",
    "        if isinstance(tracking_dict_calculated[\"iters\"], np.ndarray):\n",
    "            tracking_dict_calculated[\"iters\"]=tracking_dict_calculated[\"iters\"].tolist()            \n",
    "        \n",
    "        ground_truth=tracking_dict_ground_truth[\"values\"][tracking_dict_ground_truth[\"iters\"].index(iters_ground_truth)]\n",
    "        \n",
    "        estimated=tracking_dict_calculated[\"values\"][tracking_dict_calculated[\"iters\"].index(iters_calculated)]\n",
    "#         estimated=tracking_dict_ground_truth[\"values\"][tracking_dict_ground_truth[\"iters\"].index(iters_calculated)]\n",
    "        \n",
    "        diff=(estimated-ground_truth)\n",
    "        \n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "#         print(sample_idx, target_class_idx_ground_truth)\n",
    "        record={\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx_ground_truth].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx_ground_truth].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "        }\n",
    "        record.update(meta_info)\n",
    "        \n",
    "        record_dict_list.append(record)        \n",
    "    return record_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ground_truth_metric(shapley_values, explainer, dataset, iters_ground_truth, meta_info):\n",
    "#     record_dict_list=[]\n",
    "    \n",
    "#     for sample_idx, tracking_dict in tqdm(shapley_values.items()):\n",
    "#         data=dataset[sample_idx]\n",
    "        \n",
    "#         target_class_idx=np.argmax(tracking_dict[\"values\"][0].sum(axis=0))\n",
    "#         assert data[\"labels\"]==target_class_idx\n",
    "        \n",
    "#         explainer.eval()\n",
    "#         with torch.no_grad():\n",
    "#             estimated=explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "            \n",
    "#         if isinstance(tracking_dict[\"iters\"], np.ndarray):\n",
    "#             tracking_dict[\"iters\"]=tracking_dict[\"iters\"].tolist()\n",
    "        \n",
    "#         ground_truth=tracking_dict[\"values\"][tracking_dict[\"iters\"].index(iters_ground_truth)]\n",
    "            \n",
    "#         diff=(estimated.T.cpu().detach().numpy()-ground_truth)\n",
    "        \n",
    "#         mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "#         record={\n",
    "#             \"sample_idx\": sample_idx,\n",
    "#             \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "#             \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "#             \"mse_all\": mse_class[:].mean(),\n",
    "#         }\n",
    "#         record.update(meta_info)\n",
    "        \n",
    "#         record_dict_list.append(record)\n",
    "        \n",
    "#     return record_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60353808",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer[\"validation\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=42).permutation(list(range(9469))).tolist()[:100][::-1].index(7707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67346234",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=42).permutation(list(range(9469))).tolist()[:100][::-1].index(6051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\n",
    "    \"774\", \"8336\", \"8367\", \"7065\", \"2362\", \"3146\", \"3945\", \"3577\", \"7615\", \n",
    "    \"6553\", \"5204\", \"6673\", \"4925\", \"8285\", \"7724\", \"683\", \"6578\", \"7001\", \n",
    "    \"2183\", \"7758\", \"9234\", \"1650\", \"7593\", \"4838\", \"8294\", \"7290\", \"3995\", \n",
    "    \"6051\", \"2526\", \"3798\", \"7923\", \"483\", \"1087\", \"3019\", \"1217\", \"5014\", \n",
    "    \"1076\", \"8250\", \"5327\", \"6909\", \"908\", \"106\", \"315\", \"6177\", \"7854\", \n",
    "    \"4354\", \"6310\", \"457\", \"8606\", \"7689\", \"7707\"\n",
    "]:\n",
    "#     if i not in np.random.RandomState(seed=42).permutation(list(range(9469))).tolist():\n",
    "#         print(\"not found\", i)\n",
    "    print(np.random.RandomState(seed=42).permutation(list(range(9469))).tolist().index(int(i)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=42).permutation(list(range(9469))).tolist()[:100][::-1].index(8606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/ -trl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1749e",
   "metadata": {},
   "source": [
    "# Training target quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469310b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f702584",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd274464",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\",\n",
    "             target_subset_size=196,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97feb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\"]\\\n",
    "=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82039c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8dd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33689f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd483646",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [512, 1024, 2048, 3072]:\n",
    "    metric_list_value+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"method\":f\"KernelSHAP ({num_subsets})\",\n",
    "                                                  \"num_subsets\": num_subsets,\n",
    "                                                  \"estimation_method\": \"KernelSHAP\",\n",
    "                                                 })\n",
    "    \n",
    "    metric_list_value+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"method\":f\"KernelSHAP ({num_subsets}, antithetical)\",\n",
    "                                                  \"num_subsets\": num_subsets,\n",
    "                                                  \"estimation_method\": \"KernelSHAP\",\n",
    "                                                 })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6394620",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [196, 392, 588, 1176, 3136]:\n",
    "    metric_list_value+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"method\":f\"Permutation ({num_subsets})\",\n",
    "                                                  \"num_subsets\": num_subsets,\n",
    "                                                  \"estimation_method\": \"Permutation\",                                                  \n",
    "                                                 })\n",
    "    metric_list_value+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"method\":f\"Permutation ({num_subsets}, antithetical)\",\n",
    "                                                  \"num_subsets\": num_subsets,\n",
    "                                                  \"estimation_method\": \"Permutation\",                                                  \n",
    "                                                 })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b367ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    shapley_loaded_dict_temp={}\n",
    "    for sample_idx, tracking_dict in shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation_newsample_196/extract_output/train\"].items():\n",
    "        shapley_loaded_dict_temp[sample_idx]=tracking_dict[i]\n",
    "\n",
    "    metric_list_value+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict_temp,\n",
    "                                       iters_calculated=196,\n",
    "                                       meta_info={\"method\":f\"Permutation (196, newsample, {i+1})\",\n",
    "                                                  \"num_subsets\": 196,\n",
    "                                                  \"estimation_method\": \"Permutation\",                                                  \n",
    "                                                 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_shapley??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d62ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shapley(path, target_subset_size=None):\n",
    "    file_list = glob.glob(str(Path(path) / \"[0-9]*\"))\n",
    "    output_dict = {}\n",
    "    if target_subset_size is None:\n",
    "        for file in tqdm(file_list):\n",
    "            loaded = torch.load(Path(file) / \"shapley_output.pt\")\n",
    "\n",
    "            output_dict[int(file.split(\"/\")[-1])] = loaded\n",
    "    else:\n",
    "        for file in tqdm(file_list):\n",
    "            subset_file_list = glob.glob(\n",
    "                str(Path(file) / f\"shapley_output_{target_subset_size}_*.pt\")\n",
    "            )\n",
    "            loaded_list = []\n",
    "            for subset_file in sorted(\n",
    "                subset_file_list,\n",
    "                key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]),\n",
    "            ):\n",
    "                loaded = torch.load(subset_file)\n",
    "                loaded_list.append(loaded)\n",
    "            output_dict[int(file.split(\"/\")[-1])] = loaded_list\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4748183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "/homes/gws/chanwkim/vit-shapley/results/3_explanation_generate/ImageNette/vit_base_patch16_224_kernelshap_test.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_shapley_eval_train_antithetical/extract_output/train/*/shapley_output.pt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9531ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,10))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "\n",
    "def get_reg_type(x):\n",
    "    if \"KernelSHAP\" in x:\n",
    "        return \"KernelSHAP\"\n",
    "    elif \"Permutation\" in x:\n",
    "        return \"Permutation\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "    \n",
    "\n",
    "metric_df=pd.DataFrame(metric_list_value)\n",
    "# metric_df[\"method\"]=metric_df[\"method\"].str.pad(40, side=\"right\", fillchar='-')\n",
    "\n",
    "# metric_df[\"explainer\"]=metric_df[\"explainer\"].str.replace(\n",
    "#     \"Reg-AO (upfront, regression, 512, antithetical)\",\n",
    "#     \"Reg-AO (upfront, regression, antithetical, 512)\")\\\n",
    "#     .str.replace(\n",
    "#     \"Obj-AO (newsample, 32, antithetical)\",\n",
    "#     \"Obj-AO (newsample, antithetical, 32)\",)\n",
    "\n",
    "# print(metric_df[\"explainer\"].value_counts())\n",
    "\n",
    "\n",
    "# metric_df[\"AO type\"]=metric_df[\"explainer\"].map(lambda x: x.split('(')[0].strip())\n",
    "# metric_df[\"num_subsets\"]=metric_df[\"explainer\"].map(lambda x: int(x.split(',')[-1][:-1].strip()))\n",
    "# metric_df[\"reg type\"]=metric_df[\"explainer\"].map(get_reg_type)\n",
    "\n",
    "# metric_df=metric_df.sort_values([\"AO type\", \"reg type\", \"num_subsets\"], ascending=True)\n",
    "# metric_df=metric_df[metric_df[\"explainer\"].str.contains(\"Obj-AO\")]\n",
    "\n",
    "sns.barplot(\n",
    "    y=\"method\",\n",
    "    x=\"mse_target\",\n",
    "#     hue=\"method\",\n",
    "#     style=\"AO type\",\n",
    "#     style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "    palette=\"tab10\",\n",
    "    linewidth=3,\n",
    "    data=metric_df,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Method\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"MSE\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))    \n",
    "# axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "# axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "# axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', rotation=-90, labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "\n",
    "# yax = axd[plot_key].get_yaxis()\n",
    "# # find the maximum width of the label on the major ticks\n",
    "# pad = max(T.label1.get_window_extent().width for T in yax.majorTicks)\n",
    "# yax.set_tick_params(pad=pad)\n",
    "\n",
    "# axd[plot_key].axis[\"left\"].major_ticklabels.set_ha(\"left\")\n",
    "\n",
    "# for label in axd[plot_key].get_yticklabels():\n",
    "#     label.set_horizontalalignment('right')\n",
    "#     import matplotlib.transforms as mtrans\n",
    "#     # Shifting the label by -15 points on the x-axis\n",
    "#     trans = mtrans.Affine2D().translate(-100, 0)\n",
    "#     t = axd[plot_key].transData + trans\n",
    "#     label.set_transform(t)    \n",
    "\n",
    "\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "# axd[plot_key].set_xlim(0, 40)\n",
    "# axd[plot_key].set_ylim(0, 0.030)\n",
    "\n",
    "leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba773b65",
   "metadata": {},
   "source": [
    "# Training curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d82f49c",
   "metadata": {},
   "source": [
    "### Obj-AO (newsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_objexplainer_newsample_32/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:100]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    explainer.load_state_dict(state_dict)\n",
    "    \n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=explainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Obj-AO (newsample, 32)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_objexplainer_antithetical_newsample_32/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[20:20+20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    explainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=explainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Obj-AO (newsample, antithetical, 32)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb6f81",
   "metadata": {},
   "source": [
    "### Reg-AO (upfront, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94138e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_upfront_512/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, regression, 512)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_upfront_1024/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, regression, 1024)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30466e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_upfront_2048/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, regression, 2048)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_upfront_3072/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, regression, 3072)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_antithetical_upfront_512/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "metric_list_=[]\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list_+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, regression, antithetical, 512)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7d557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c79a809",
   "metadata": {},
   "source": [
    "### Reg-AO (upfront, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_196/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999936,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, permutation, 196)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f17068",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_392/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999936,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, permutation, 392)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_588/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999936,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, permutation, 588)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_1176/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999936,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, permutation, 1176)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9cd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_3136/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999936,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (upfront, permutation, 3136)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25291441",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list=([metric for metric in metric_list if metric[\"explainer\"]!='Reg-AO (upfront, regression, 512, antithetical)'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33229546",
   "metadata": {},
   "source": [
    "### Reg-AO (newsample, permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_regexplainer_permutation_newsample_196/checkpoint-*\"), key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:20]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "                            explainer=regexplainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=999424,\n",
    "                            meta_info={\"explainer\": \"Reg-AO (newsample, permutation, 196)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9963b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(metric_list, \"logs/experiment_results/metric_list.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773c1a0",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4035e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "\n",
    "def get_reg_type(x):\n",
    "    if \"regression\" in x:\n",
    "        return \"regression\"\n",
    "    elif \"permutation\" in x:\n",
    "        return \"permutation\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "    \n",
    "\n",
    "metric_df=pd.DataFrame(metric_list+metric_list_)\n",
    "metric_df[\"explainer\"]=metric_df[\"explainer\"].str.replace(\n",
    "    \"Reg-AO (upfront, regression, 512, antithetical)\",\n",
    "    \"Reg-AO (upfront, regression, antithetical, 512)\")\\\n",
    "    .str.replace(\n",
    "    \"Obj-AO (newsample, 32, antithetical)\",\n",
    "    \"Obj-AO (newsample, antithetical, 32)\",)\n",
    "\n",
    "print(metric_df[\"explainer\"].value_counts())\n",
    "\n",
    "\n",
    "metric_df[\"AO type\"]=metric_df[\"explainer\"].map(lambda x: x.split('(')[0].strip())\n",
    "metric_df[\"num_subsets\"]=metric_df[\"explainer\"].map(lambda x: int(x.split(',')[-1][:-1].strip()))\n",
    "metric_df[\"reg type\"]=metric_df[\"explainer\"].map(get_reg_type)\n",
    "\n",
    "metric_df=metric_df.sort_values([\"AO type\", \"reg type\", \"num_subsets\"], ascending=True)\n",
    "# metric_df=metric_df[metric_df[\"explainer\"].str.contains(\"Obj-AO\")]\n",
    "metric_df=metric_df[metric_df[\"explainer\"].str.contains(\"permutation\")]\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"epoch\",\n",
    "    y=\"mse_target\",\n",
    "    hue=\"explainer\",\n",
    "    style=\"AO type\",\n",
    "    style_order=[\"Reg-AO\", \"Obj-AO\"],\n",
    "    palette=\"tab10\",\n",
    "    linewidth=3,\n",
    "    data=metric_df,\n",
    "    ax=axd[plot_key]\n",
    ")\n",
    "\n",
    "\n",
    "axd[plot_key].set_ylabel(\"MSE\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Epoch\", fontsize=20)\n",
    "\n",
    "          \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))    \n",
    "# axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))  \n",
    "axd[plot_key].set_xlim(0, 40)\n",
    "axd[plot_key].set_ylim(0, 0.030)\n",
    "\n",
    "leg=axd[plot_key].legend(loc='best', bbox_to_anchor=(0.0, -1.2, 0.5, 1))\n",
    "\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9d4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b747c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a9f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b1b31c",
   "metadata": {},
   "source": [
    "# Error from prediction vs Error from targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\" not in shapley_loaded_dict.keys():\n",
    "    shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"]=\\\n",
    "    load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\" not in shapley_loaded_dict.keys():\n",
    "    shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"]=\\\n",
    "    load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\" not in shapley_loaded_dict.keys():\n",
    "    shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\"]=\\\n",
    "    load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"logs/vitbase_imagenette_surrogate_shapley_eval_test_permutation/extract_output/test\" not in shapley_loaded_dict.keys():\n",
    "    shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_permutation/extract_output/test\"]=\\\n",
    "    load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test_permutation/extract_output/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4341d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8f80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"logs/vitbase_imagenette_surrogate_shapley_eval_test_permutation/extract_output/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767ba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af762099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "'logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bb6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict={\n",
    "    \"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\": load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"),\n",
    "    \"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\": load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\")\n",
    "    \"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\": load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\")\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122923e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"]=load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab8759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_explainer=[]\n",
    "metric_list_target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets, checkpoint_path in {\n",
    "    512: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_512/checkpoint-888\",\n",
    "    1024: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_1024/checkpoint-1036\",\n",
    "    1536: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_1536/checkpoint-1480\",\n",
    "    2048: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_2048/checkpoint-1480\",\n",
    "    3072: \"logs/vitbase_imagenette_shapley_regexplainer_upfront_3072/checkpoint-1924\",\n",
    "}.items():\n",
    "    \n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "\n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "    num_epoch=int(trainer_state[\"epoch\"])\n",
    "\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list_explainer+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                                        explainer=regexplainer,\n",
    "                                                        dataset=dataset_explainer[\"train\"],\n",
    "                                                        iters_ground_truth=999424,\n",
    "                                                        meta_info={\"explainer\": f\"Reg-AO (upfront, regression, {num_subsets}) (epoch={num_epoch})\",\n",
    "                                                                   \"num_subsets\": num_subsets,\n",
    "                                                                   \"repeat\": \"upfront\",\n",
    "                                                                   \"estimation_method\": \"KernelSHAP\",\n",
    "                                                                   \"split\": \"train\",\n",
    "                                                                  })\n",
    "\n",
    "    metric_list_target+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                                    iters_ground_truth=999424,\n",
    "                                                    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"], \n",
    "                                                    iters_calculated=num_subsets, \n",
    "                                                    meta_info={\"explainer\": f\"Reg-AO (upfront, regression, {num_subsets}) (epoch={num_epoch})\",\n",
    "                                                               \"num_subsets\": num_subsets,\n",
    "                                                               \"estimation_method\": \"KernelSHAP\",\n",
    "                                                                \"split\": \"train\",\n",
    "                                                               }\n",
    "    )    \n",
    "    \n",
    "#     metric_list_explainer+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                                         explainer=regexplainer,\n",
    "#                                                         dataset=dataset_explainer[\"test\"],\n",
    "#                                                         iters_ground_truth=999424,\n",
    "#                                                         meta_info={\"explainer\": f\"Reg-AO (upfront, regression, {num_subsets}) (epoch={num_epoch})\",\n",
    "#                                                                    \"num_subsets\": num_subsets,\n",
    "#                                                                    \"repeat\": \"upfront\",\n",
    "#                                                                    \"estimation_method\": \"KernelSHAP\",\n",
    "#                                                                    \"split\": \"test\",\n",
    "#                                                                   })\n",
    "\n",
    "#     metric_list_target+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                                     iters_ground_truth=999424,\n",
    "#                                                     shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\"], \n",
    "#                                                     iters_calculated=num_subsets, \n",
    "#                                                     meta_info={\"explainer\": f\"Reg-AO (upfront, regression, {num_subsets}) (epoch={num_epoch})\",\n",
    "#                                                                \"num_subsets\": num_subsets,\n",
    "#                                                                \"estimation_method\": \"KernelSHAP\",\n",
    "#                                                                 \"split\": \"test\",\n",
    "#                                                                }\n",
    "#     )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebccf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets, checkpoint_path in {\n",
    "    196: \"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_196/checkpoint-1036\",\n",
    "    392: \"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_392/checkpoint-1332\",\n",
    "    588: \"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_588/checkpoint-1332\",\n",
    "    1176: \"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_1176/checkpoint-1480\",\n",
    "    3136: \"logs/vitbase_imagenette_shapley_regexplainer_permutation_upfront_3136/checkpoint-2812\"\n",
    "}.items():\n",
    "    \n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "\n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "    num_epoch=int(trainer_state[\"epoch\"])\n",
    "\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    metric_list_explainer+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                                        explainer=regexplainer,\n",
    "                                                        dataset=dataset_explainer[\"train\"],\n",
    "                                                        iters_ground_truth=999424,\n",
    "                                                        meta_info={\"explainer\": f\"Reg-AO (upfront, permutation, {num_subsets}) (epoch={num_epoch})\",\n",
    "                                                                   \"num_subsets\": num_subsets,\n",
    "                                                                   \"repeat\": \"upfront\",\n",
    "                                                                   \"estimation_method\": \"Permutation\",\n",
    "                                                                   \"split\": \"train\",\n",
    "                                                                   \"target\": False,\n",
    "                                                                  })\n",
    "\n",
    "    metric_list_target+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                                    iters_ground_truth=999424,\n",
    "                                                    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_permutation/extract_output/train\"], \n",
    "                                                    iters_calculated=num_subsets, \n",
    "                                                    meta_info={\"explainer\": f\"Reg-AO (upfront, permutation, {num_subsets}) (epoch={num_epoch})\",\n",
    "                                                               \"num_subsets\": num_subsets,\n",
    "                                                               \"estimation_method\": \"Permutation\",\n",
    "                                                                \"split\": \"train\",\n",
    "                                                               \"target\": True,\n",
    "                                                               }\n",
    "    )        \n",
    "    \n",
    "    \n",
    "#     metric_list_explainer+=get_ground_truth_metric_with_explainer(shapley_values=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                                         explainer=regexplainer,\n",
    "#                                                         dataset=dataset_explainer[\"test\"],\n",
    "#                                                         iters_ground_truth=999424,\n",
    "#                                                         meta_info={\"explainer\": f\"Reg-AO (upfront, permutation, {num_subsets}) (epoch={num_epoch})\",\n",
    "#                                                                    \"num_subsets\": num_subsets,\n",
    "#                                                                    \"repeat\": \"upfront\",\n",
    "#                                                                    \"estimation_method\": \"Permutation\",\n",
    "#                                                                    \"split\": \"test\",\n",
    "#                                                                    \"target\": False,\n",
    "#                                                                   })\n",
    "\n",
    "#     metric_list_target+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_regression_antithetical/extract_output/test\"], \n",
    "#                                                     iters_ground_truth=999424,\n",
    "#                                                     shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test_permutation/extract_output/test\"], \n",
    "#                                                     iters_calculated=num_subsets, \n",
    "#                                                     meta_info={\"explainer\": f\"Reg-AO (upfront, permutation, {num_subsets}) (epoch={num_epoch})\",\n",
    "#                                                                \"num_subsets\": num_subsets,\n",
    "#                                                                \"estimation_method\": \"Permutation\",\n",
    "#                                                                 \"split\": \"test\",\n",
    "#                                                                \"target\": True,\n",
    "#                                                                }\n",
    "#     )             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbc93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list_value_variable=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_subsets in [\n",
    "    1000,\n",
    "    2000,\n",
    "    3000,\n",
    "    4000,\n",
    "    5000,\n",
    "    6000,\n",
    "    7000,\n",
    "    8000,\n",
    "    9000,\n",
    "    10000,\n",
    "    20000,\n",
    "    30000,\n",
    "    40000,\n",
    "    50000,\n",
    "    60000,\n",
    "    70000,\n",
    "    80000,\n",
    "    90000,\n",
    "    100000,\n",
    "    200000,\n",
    "    300000,\n",
    "    400000,\n",
    "    500000,\n",
    "    600000,\n",
    "    700000,\n",
    "    700000,\n",
    "    800000,\n",
    "    900000,    \n",
    "                   ]:\n",
    "    \n",
    "    num_subsets=(int(num_subsets//512)+1)*512\n",
    "    \n",
    "    metric_list_value_variable+=get_ground_truth_metric_with_value(shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"], \n",
    "                                       iters_ground_truth=999424, \n",
    "                                       shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression_antithetical/extract_output/train\"],\n",
    "                                       iters_calculated=num_subsets,\n",
    "                                       meta_info={\"method\":f\"KernelSHAP ({num_subsets})\",\n",
    "                                                  \"num_subsets\": num_subsets,\n",
    "                                                  \"estimation_method\": \"KernelSHAP\",\n",
    "                                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd0d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046311a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dbc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a40cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_plot=metric_df.groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"permutation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f097067",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_plot.sort_values(\"num_subsets\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 196)\"].loc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 392)\"].loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a277be",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 588)\"].loc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 588)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533fe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0b1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 1176)\"].loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_.groupby(['explainer', 'epoch']).mean().loc[\"Reg-AO (upfront, permutation, 3332)\"].loc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522758b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_=pd.DataFrame(metric_list+metric_list_)\n",
    "metric_df_[\"explainer\"]=metric_df_[\"explainer\"].str.replace(\n",
    "    \"Reg-AO (upfront, regression, 512, antithetical)\",\n",
    "    \"Reg-AO (upfront, regression, antithetical, 512)\")\\\n",
    "    .str.replace(\n",
    "    \"Obj-AO (newsample, 32, antithetical)\",\n",
    "    \"Obj-AO (newsample, antithetical, 32)\",)\n",
    "\n",
    "print(metric_df_[\"explainer\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_explainer_df=pd.DataFrame(metric_list_explainer)\n",
    "\n",
    "metric_target_df=pd.DataFrame(metric_list_target)\n",
    "\n",
    "metric_df=metric_explainer_df.merge(right=metric_target_df, \n",
    "                          left_on=[\"explainer\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          right_on=[\"explainer\", \"sample_idx\", \"num_subsets\", \"split\"],\n",
    "                          suffixes=('_explainer', '_target')\n",
    "                         )\n",
    "metric_df[metric_df[\"split\"]==\"train\"].groupby(\"explainer\")[['sample_idx',  \"num_subsets\", \n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96885ac",
   "metadata": {},
   "source": [
    "# train permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_value_variable).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df254b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric_list_value_variable).groupby([\"estimation_method\",\"num_subsets\"])\\\n",
    "[['mse_target', 'mse_nontarget', 'mse_all']].mean().loc[\"KernelSHAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_plot[\"mse_target_explainer\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "metric_df_plot=metric_df[metric_df[\"split\"]==\"train\"].groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"permutation\")]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_all_explainer\", \n",
    "    y=\"mse_all_target\", \n",
    "    hue=\"num_subsets\",\n",
    "    data=metric_df_plot,\n",
    "    s=200,\n",
    "    palette=\"Set2\",\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "count=0\n",
    "for idx, row in pd.DataFrame(metric_list_value_variable).groupby([\"estimation_method\",\"num_subsets\"])\\\n",
    "[['mse_target', 'mse_nontarget', 'mse_all']].mean().loc[\"KernelSHAP\"].iterrows():\n",
    "    print(metric_df_plot[\"mse_all_explainer\"].min(), row[\"mse_all\"])\n",
    "    if row[\"mse_all\"]>metric_df_plot[\"mse_all_explainer\"].min() and row[\"mse_all\"]<metric_df_plot[\"mse_all_explainer\"].max():\n",
    "#     if True:\n",
    "        axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "                             x=row[\"mse_all\"], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "                             label=f'KernelSHAP {idx}'\n",
    "                            )\n",
    "        count+=1\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "axd[plot_key].set_xscale(\"log\")\n",
    "axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"right\", fontsize=15)\n",
    "\n",
    "axd[plot_key].set_xlim(left=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efb000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf60679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_plot=metric_df[metric_df[\"split\"]==\"train\"].groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"regression\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d369ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc38d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "metric_df_plot=metric_df[metric_df[\"split\"]==\"train\"].groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"regression\")]\n",
    "# sds\n",
    "\n",
    "count=0\n",
    "for idx, row in pd.DataFrame(metric_list_value_variable).groupby([\"estimation_method\",\"num_subsets\"])\\\n",
    "[['mse_target', 'mse_nontarget', 'mse_all']].mean().loc[\"KernelSHAP\"].iterrows():\n",
    "    print(metric_df_plot[\"mse_all_explainer\"].min(), row[\"mse_all\"])\n",
    "    if row[\"mse_all\"]>metric_df_plot[\"mse_all_explainer\"].min() and row[\"mse_all\"]<metric_df_plot[\"mse_all_explainer\"].max():\n",
    "#     if True:\n",
    "        axd[plot_key].vlines(ymin=0, ymax=1, \n",
    "                             x=row[\"mse_all\"], linewidth=2, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][count],\n",
    "                             label=f'KernelSHAP {idx}'\n",
    "                            )\n",
    "        count+=1\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_all_explainer\", \n",
    "    y=\"mse_all_target\", \n",
    "    hue=\"num_subsets\",\n",
    "    data=metric_df_plot,\n",
    "    s=200,\n",
    "    palette=\"Set2\",\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "axd[plot_key].set_xscale(\"log\")\n",
    "axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"right\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7dcdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5bc27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "metric_df_plot=metric_df[metric_df[\"split\"]==\"test\"].groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"permutation\")]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_target_explainer\", \n",
    "    y=\"mse_target_target\", \n",
    "    hue=\"num_subsets\",\n",
    "    data=metric_df_plot,\n",
    "    s=200,\n",
    "    palette=\"Set2\",\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "axd[plot_key].set_xscale(\"log\")\n",
    "axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"right\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcfbfb",
   "metadata": {},
   "source": [
    "# train regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e15fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ba33c51",
   "metadata": {},
   "source": [
    "# test regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "metric_df_plot=metric_df[metric_df[\"split\"]==\"test\"].groupby(\"explainer\")[['sample_idx',\"num_subsets\",\n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index()\n",
    "metric_df_plot[\"num_subsets\"]=metric_df_plot[\"num_subsets\"].astype(int)\n",
    "metric_df_plot=metric_df_plot[metric_df_plot[\"explainer\"].str.contains(\"regression\")]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_target_explainer\", \n",
    "    y=\"mse_target_target\", \n",
    "    hue=\"num_subsets\",\n",
    "    data=metric_df_plot,\n",
    "    s=200,\n",
    "    palette=\"Set2\",\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "axd[plot_key].set_xscale(\"log\")\n",
    "axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"right\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0823ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7caca72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3db49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be061549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda08cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf24ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5674b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcf556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39398c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e39af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35511e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea9111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f542d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534cf090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05482c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f126a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc3374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40df624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ff59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e972da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean()[[\"mse_target_explainer\",\n",
    "                                      \"mse_target_calculated\",\n",
    "                                      \"mse_nontarget_explainer\",\n",
    "                                      \"mse_nontarget_calculated\"\n",
    "                                     \n",
    "                                     ]]\\\n",
    ".loc[sorted(metric_df[\"explainer\"].unique(), key=lambda x: int(x.split(',')[-1].strip().replace(')','')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_target_explainer\", \n",
    "    y=\"mse_target_target\", \n",
    "    hue=\"explainer\",\n",
    "    hue_order=sorted(metric_df[\"explainer\"][metric_df[\"explainer\"].str.contains(\"regression\")].unique(), key=lambda x: int(x.split(',')[-1].strip().replace(')',''))),\n",
    "    data=metric_df[metric_df[\"explainer\"].str.contains(\"regression\")].groupby(\"explainer\")\n",
    "    [['sample_idx',  \n",
    "        'mse_target_explainer', 'mse_nontarget_explainer', 'mse_all_explainer',  \n",
    "       'mse_target_target', 'mse_nontarget_target', 'mse_all_target']].mean().reset_index(),\n",
    "    palette=sns.color_palette(\"rocket\", 3),\n",
    "    s=200,\n",
    "\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,3,100), np.linspace(0,3,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "# axd[plot_key].set_xscale(\"log\")\n",
    "# axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"best\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f65e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "axd={\"main\":ax}\n",
    "\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"mse_target_explainer\", \n",
    "    y=\"mse_target_calculated\", \n",
    "    hue=\"explainer\",\n",
    "    hue_order=sorted(metric_df[\"explainer\"][metric_df[\"explainer\"].str.contains(\"permutation\")].unique(), key=lambda x: int(x.split(',')[-1].strip().replace(')',''))),\n",
    "    data=metric_df[metric_df[\"explainer\"].str.contains(\"permutation\")].groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().reset_index(),\n",
    "    palette=sns.color_palette(\"rocket\", 4),\n",
    "    s=200,\n",
    "    ax=axd[plot_key],\n",
    ")\n",
    "\n",
    "# axd[plot_key].set_xlim(0,3)\n",
    "# axd[plot_key].set_ylim(0,3)\n",
    "\n",
    "axd[plot_key].plot(np.linspace(0,10,100), np.linspace(0,10,100))\n",
    "\n",
    "axd[plot_key].set_ylabel(\"Error from target\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"Error from prediction\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.01))\n",
    "# axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.005))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "# axd[plot_key].xaxis.set_major_locator(MultipleLocator(10))\n",
    "# axd[plot_key].xaxis.set_minor_locator(MultipleLocator(5))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False) \n",
    "\n",
    "axd[plot_key].set_xscale(\"log\")\n",
    "axd[plot_key].set_yscale(\"log\")\n",
    "\n",
    "axd[plot_key].legend(loc=\"best\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea811d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b73689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e801a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6386e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc5cf197",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d56c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dfe32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30eaff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b1e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa178a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1309639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852dc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"mse_target_explainer\", \n",
    "                y=\"mse_target_calculated\", \n",
    "                hue=\"explainer\",\n",
    "                data=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c71a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbc37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be141659",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468517ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.groupby(\"explainer\")[['sample_idx', 'mse_target_explainer', 'mse_nontarget_explainer',\n",
    "       'mse_all_explainer',  'epoch', \n",
    "       'mse_target_calculated', 'mse_nontarget_calculated',\n",
    "       'mse_all_calculated']].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be48817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c45d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.fillna(\"None\").groupby([\"explainer\", \"sample_idx\"]).apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd3435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58efd0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbd701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3c285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_calculated=512*3, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"], \n",
    "    iters_calculated=512*1, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839429f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b8409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c5c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_calculated=512*2, \n",
    "    meta_info={}\n",
    ")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "199680/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428dee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fef3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ground_truth_metric_with_value(\n",
    "    shapley_values_ground_truth=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"], \n",
    "    iters_ground_truth=199680,\n",
    "    shapley_values_calculated=shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"], \n",
    "    iters_calculated=512, \n",
    "    meta_info={}\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e75ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]=\\\n",
    "load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8600c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b15c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][9213][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0736b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train_regression/extract_output/train\"][9213][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eeca45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70db19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_train/extract_output/train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_dict[\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246047f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8b928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list+=get_ground_truth_metric(shapley_values=shapley_loaded_test, \n",
    "                        explainer=regexplainer,\n",
    "                        dataset=dataset_explainer[\"test\"],\n",
    "                        iters_ground_truth=200192,\n",
    "                        meta_info={\"explainer\": \"Reg-AO (upfront, 512)\",\n",
    "                                   \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a1447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d9986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de98d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80301eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cf63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f793130",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_list=sorted(glob.glob(\"logs/vitbase_imagenette_shapley_objexplainer_newsample_32/\"), key=lambda x: int(x.split('-')[-1]))\n",
    "for checkpoint_path in tqdm(checkpoint_path_list[:100]):\n",
    "    state_dict = torch.load(checkpoint_path+\"/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    \n",
    "    with open(checkpoint_path+\"/trainer_state.json\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    explainer.load_state_dict(state_dict)\n",
    "    metric_list+=get_ground_truth_metric(shapley_values=shapley_loaded_test, \n",
    "                            explainer=explainer,\n",
    "                            dataset=dataset_explainer[\"test\"],\n",
    "                            iters_ground_truth=200192,\n",
    "                            meta_info={\"explainer\": \"Obj-AO (newsample, 32)\",\n",
    "                                       \"epoch\":int(trainer_state[\"epoch\"])\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda32760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe486877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5384a3ae",
   "metadata": {},
   "source": [
    "# per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_ground_truth=99840\n",
    "\n",
    "record_dict_list=[]\n",
    "\n",
    "for sample_idx, num_eval_shapley_values in enumerate(shapley_values_dict[\"test\"]):\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"per-sample\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list=[]\n",
    "\n",
    "for sample_idx, num_eval_shapley_values in enumerate(shapley_loaded_test[\"test\"]):\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"per-sample\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1d9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_estimated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd84ee",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4babde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',                       \n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset[\"test_explainer\"], \n",
    "                sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "    fig.suptitle(f\"Reg-AO {num_eval}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae9a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b04791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(shapley_values_dict[\"test\"], dataset[\"test_explainer\"])):\n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        regexplainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=regexplainer(pixel_values=data[\"pixel_values\"].unsqueeze(0), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"regression_AO\",            \n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_obj in sorted(glob.glob(\"logs/vitbase_imagenette_explainer_objective/checkpoint-*\"), key=lambda x: int(x.split('-')[-1])):\n",
    "    num_eval=int(model_path_obj.split('-')[-1])/148*32\n",
    "    if int(int(model_path_obj.split('-')[-1])/148)%10!=1:\n",
    "        continue\n",
    "    state_dict = torch.load(f\"{model_path_obj}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    explainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_model_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(tqdm.tqdm(shapley_values_dict[\"test\"]), dataset[\"test_explainer\"])):        \n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        explainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.cpu().detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"objective_AO\",            \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2c7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(int(model_path_obj.split('-')[-1])/148)%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461153fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "444/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91304c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090995a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fac37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da40cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5134987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16300924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df,\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15561acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a497ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb68920",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.01)\n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "500/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a5318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d446c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce44723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a5f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426e85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf5a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76564e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76abcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d86bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febe09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9111265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fd24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d72efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c03e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609424dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb71e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb571e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2455520",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression_0/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_out=explainer.forward(pixel_values=dataset[\"validation_explainer\"][0]['pixel_values'].unsqueeze(0),\n",
    "                               return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09996826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75733ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.to(device)\n",
    "explainer.surrogate_null=explainer.surrogate_null.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd568cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409324e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51752451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.max_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76788cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6879770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7701de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec174b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a8c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030835e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_train=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_train/extract_output/train/\")\n",
    "shapley_loaded_train_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_train_validation_permutation/extract_output/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_validation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation/extract_output/validation/\")\n",
    "shapley_loaded_validation_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation_permutation/extract_output/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7252da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test/extract_output/test/\")\n",
    "shapley_loaded_test_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test_permutation=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_validation/extract_output/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded2[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapley_loaded1), len(shapley_loaded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd334290",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/vitbase_imagenette_surrogate_eval_train_permutation/extract_output/train/3 -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c738cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f924f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_shapley??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef410cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"values\"][-1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d869aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "explainer.surrogate.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def ShapleySampling(game,\n",
    "                    batch_size=512,\n",
    "                    detect_convergence=True,\n",
    "                    thresh=0.01,\n",
    "                    n_samples=None,\n",
    "                    antithetical=False,\n",
    "                    return_all=False,\n",
    "                    bar=True,\n",
    "                    verbose=False):\n",
    "    # Verify arguments.\n",
    "    stochastic = False\n",
    "#     if isinstance(game, CooperativeGame):\n",
    "#         stochastic = False\n",
    "#     elif isinstance(game, StochasticCooperativeGame):\n",
    "#         stochastic = True\n",
    "#     else:\n",
    "#         raise ValueError('game must be CooperativeGame or '\n",
    "#                          'StochasticCooperativeGame')\n",
    "\n",
    "    # Possibly force convergence detection.\n",
    "    if n_samples is None:\n",
    "        n_samples = 1e20\n",
    "        if not detect_convergence:\n",
    "            detect_convergence = True\n",
    "            if verbose:\n",
    "                print('Turning convergence detection on')\n",
    "\n",
    "    if detect_convergence:\n",
    "        assert 0 < thresh < 1\n",
    "\n",
    "    # Calculate null coalition value.\n",
    "    if stochastic:\n",
    "        null = game.null(batch_size=batch_size)\n",
    "    else:\n",
    "        null = game.null()\n",
    "\n",
    "    # Set up bar.\n",
    "    n_loops = int(np.ceil(n_samples / batch_size))\n",
    "    if bar:\n",
    "        if detect_convergence:\n",
    "            bar = tqdm(total=1)\n",
    "        else:\n",
    "            bar = tqdm(total=n_loops * batch_size)\n",
    "\n",
    "    # Setup.\n",
    "    num_players = game.players\n",
    "    if isinstance(null, np.ndarray):\n",
    "        values = np.zeros((num_players, len(null)))\n",
    "        sum_squares = np.zeros((num_players, len(null)))\n",
    "        deltas = np.zeros((batch_size, num_players, len(null)))\n",
    "    else:\n",
    "        values = np.zeros((num_players))\n",
    "        sum_squares = np.zeros((num_players))\n",
    "        deltas = np.zeros((batch_size, num_players))\n",
    "    permutations = np.tile(np.arange(game.players), (batch_size, 1))\n",
    "    arange = np.arange(batch_size)\n",
    "    n = 0\n",
    "\n",
    "    # For tracking progress.\n",
    "    if return_all:\n",
    "        N_list = []\n",
    "        std_list = []\n",
    "        val_list = []\n",
    "\n",
    "    # Begin sampling.\n",
    "    for it in range(n_loops):\n",
    "        for i in range(batch_size):\n",
    "            if antithetical and i % 2 == 1:\n",
    "                permutations[i] = permutations[i - 1][::-1]\n",
    "            else:\n",
    "                np.random.shuffle(permutations[i])\n",
    "        S = np.zeros((batch_size, game.players), dtype=int)\n",
    "\n",
    "        # Sample exogenous (if applicable).\n",
    "        if stochastic:\n",
    "            U = game.sample(batch_size)\n",
    "\n",
    "        # Unroll permutations.\n",
    "        prev_value = null\n",
    "        for i in tqdm(range(num_players)):\n",
    "            S[arange, permutations[:, i]] = 1\n",
    "            if stochastic:\n",
    "                next_value = game(S, U)\n",
    "            else:\n",
    "                next_value = game(S)\n",
    "            deltas[arange, permutations[:, i]] = next_value - prev_value\n",
    "            prev_value = next_value\n",
    "\n",
    "        # Welford's algorithm.\n",
    "        n += batch_size\n",
    "        diff = deltas - values\n",
    "        values += np.sum(diff, axis=0) / n\n",
    "        diff2 = deltas - values\n",
    "        sum_squares += np.sum(diff * diff2, axis=0)\n",
    "\n",
    "        # Calculate progress.\n",
    "        var = sum_squares / (n ** 2)\n",
    "        std = np.sqrt(var)\n",
    "        ratio = np.max(\n",
    "            np.max(std, axis=0) / (values.max(axis=0) - values.min(axis=0)))\n",
    "\n",
    "        # Print progress message.\n",
    "        if verbose:\n",
    "            if detect_convergence:\n",
    "                print(f'StdDev Ratio = {ratio:.4f} (Converge at {thresh:.4f})')\n",
    "            else:\n",
    "                print(f'StdDev Ratio = {ratio:.4f}')\n",
    "\n",
    "        # Check for convergence.\n",
    "        if detect_convergence:\n",
    "            if ratio < thresh:\n",
    "                if verbose:\n",
    "                    print('Detected convergence')\n",
    "\n",
    "                # Skip bar ahead.\n",
    "                if bar:\n",
    "                    bar.n = bar.total\n",
    "                    bar.refresh()\n",
    "                break\n",
    "\n",
    "        # Forecast number of iterations required.\n",
    "        if detect_convergence:\n",
    "            N_est = (it + 1) * (ratio / thresh) ** 2\n",
    "            if bar and not np.isnan(N_est):\n",
    "                bar.n = np.around((it + 1) / N_est, 4)\n",
    "                bar.refresh()\n",
    "        elif bar:\n",
    "            bar.update(batch_size)\n",
    "\n",
    "        # Save intermediate quantities.\n",
    "        if return_all:\n",
    "            val_list.append(np.copy(values))\n",
    "            std_list.append(np.copy(std))\n",
    "            if detect_convergence:\n",
    "                N_list.append(N_est)\n",
    "\n",
    "    # Return results.\n",
    "    if return_all:\n",
    "        # Dictionary for progress tracking.\n",
    "        iters = (np.arange(it + 1) + 1) * batch_size * num_players\n",
    "        tracking_dict = {\n",
    "            'values': val_list,\n",
    "            'std': std_list,\n",
    "            'iters': iters}\n",
    "        if detect_convergence:\n",
    "            tracking_dict['N_est'] = N_list\n",
    "\n",
    "        return tracking_dict\n",
    "    else:\n",
    "        return (values, std)\n",
    "    \n",
    "class CooperativeGame:\n",
    "    '''Base class for cooperative games.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''Evaluate cooperative game.'''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def grand(self):\n",
    "        '''Get grand coalition value.'''\n",
    "        return self.__call__(np.ones((1, self.players), dtype=int))[0]\n",
    "\n",
    "    def null(self):\n",
    "        '''Get null coalition value.'''\n",
    "        return self.__call__(np.zeros((1, self.players), dtype=int))[0]\n",
    "\n",
    "\n",
    "class PredictionGame(CooperativeGame):\n",
    "    '''\n",
    "    Cooperative game for an individual example's prediction.\n",
    "\n",
    "    Args:\n",
    "      extension: model extension (see removal.py).\n",
    "      sample: numpy array representing a single model input.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, surrogate, sample):\n",
    "        # Add batch dimension to sample.\n",
    "\n",
    "        self.surrogate = surrogate\n",
    "        self.sample = sample\n",
    "\n",
    "        # Store feature groups.\n",
    "\n",
    "        self.players = 196\n",
    "        self.groups_matrix = None\n",
    "\n",
    "        # Caching.\n",
    "        self.sample_repeat = sample\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''\n",
    "        Evaluate cooperative game.\n",
    "\n",
    "        Args:\n",
    "          S: array of player coalitions with size (batch, players).\n",
    "        '''\n",
    "        # Try to use caching for repeated data.\n",
    "        input_data = self.sample_repeat\n",
    "\n",
    "        # Evaluate.\n",
    "        with torch.no_grad():\n",
    "            output=self.surrogate(input_data[\"pixel_values\"].unsqueeze(0).to(device), \n",
    "                                  torch.Tensor(S).unsqueeze(0).to(device), return_loss=False)\n",
    "            logits=output.logits\n",
    "            return softmax(logits[0].detach().cpu().numpy(), axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "# shapley_sampling=ShapleySampling(game,\n",
    "#                     batch_size=128,\n",
    "#                     detect_convergence=True,\n",
    "#                     thresh=0.01,\n",
    "#                     antithetical=False,\n",
    "#                     return_all=True,\n",
    "#                     bar=True,\n",
    "#                     verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "\n",
    "            # Compute y_i\n",
    "            y_i = game(x_i.astype(bool)[np.newaxis])[0] - null\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        phi = np.mean(phi_iterates, axis=0)\n",
    "\n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class SGDshapley():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_Ï‰_k = OrderedDict() # weights per size k\n",
    "        dict_L_k = OrderedDict() # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            Ï‰_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = Ï‰_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_Ï‰_k.update({k: Ï‰_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "        # Probability distributions for sampling new instance\n",
    "        # Classic SGD\n",
    "        p = [ncr(d,k) for k in range(1,d)]\n",
    "        p /= np.sum(p)\n",
    "        # Importance Sampling proposal q\n",
    "#         print(dict_L_k.keys(), dict_L_k.values())\n",
    "#         sdsd\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.n = 2**d - 2\n",
    "        self.dict_Ï‰_k = dict_Ï‰_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _F_i(self, Î¦, x_i, y_i, Ï‰_i):\n",
    "        \"\"\"Function value per instance i\"\"\"\n",
    "        res = .5 * self.n * Ï‰_i * (np.dot(x_i, Î¦) - y_i)**2\n",
    "        return res\n",
    "\n",
    "    def _grad_F_i(self, Î¦, x_i, y_i, Ï‰_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        res = Ï‰_i * x_i[:,None].dot(x_i[None,:]).dot(Î¦) - Ï‰_i * y_i * x_i\n",
    "        return res\n",
    "\n",
    "    def _Î _1(self, x, b):\n",
    "        \"\"\"Projection Î  on convex set K_1\"\"\"\n",
    "        if np.abs((np.sum(x) - b)) <= 1e-6:\n",
    "            return x\n",
    "        else:\n",
    "            return x - (np.sum(x) - b)/len(x)\n",
    "\n",
    "    def _Î _2(self, x, D):\n",
    "        \"\"\"Projection Î  on convex set K_2\"\"\"\n",
    "        if np.linalg.norm(x) > D:\n",
    "            return x * D / np.linalg.norm(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _Dykstra_proj(self, x, D, b, iter_proj=100, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Dykstra's algorithm to find orthogonal projection\n",
    "        onto intersection of convex sets\n",
    "        \"\"\"\n",
    "        xk = x.copy()\n",
    "        d = len(x)\n",
    "        pk, qk = np.zeros(d), np.zeros(d)\n",
    "        for k in range(iter_proj):\n",
    "            yk = self._Î _2(xk + pk, D)\n",
    "            pk = xk + pk - yk\n",
    "            if np.linalg.norm(self._Î _1(yk + qk, b) - xk, 2) <= epsilon:\n",
    "                break\n",
    "            else:\n",
    "                xk = self._Î _1(yk + qk, b)\n",
    "                qk = yk + qk - xk\n",
    "        return xk\n",
    "\n",
    "    def sgd(self, game, dimension_select, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Î¦_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        \n",
    "        f_x = game(np.ones((1, self.d), dtype=int))[0][dimension_select]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=int))[0][dimension_select]\n",
    "\n",
    "        \n",
    "        v_M = f_x - f_r\n",
    "\n",
    "        d = self.d\n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_Ï‰_k = self.dict_Ï‰_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Î¦_0:\n",
    "            Î¦ = Î¦_0.copy()\n",
    "        else:\n",
    "            Î¦ = np.zeros(d)\n",
    "        Î¦_storage = np.zeros((n_iter,d))\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        Î¦ = Î¦ - (np.sum(Î¦) - v_M) / d\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            #z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])            \n",
    "            f_S = game(x_i[np.newaxis])[0][dimension_select]\n",
    "            y_i = f_S - f_r\n",
    "            # get weight Ï‰_i\n",
    "            Ï‰_i = dict_Ï‰_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Î¦, x_i, y_i, Ï‰_i)\n",
    "            # update Î¦\n",
    "            if step_type == \"constant\":\n",
    "                Î¦ = Î¦ - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                Î¦ = Î¦ - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                Î¦ = Î¦ - (step/(t)) * grad_i\n",
    "\n",
    "            # projection onto convex set K\n",
    "            # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "            Î¦ = Î¦ - (Î¦.sum() - v_M) / d\n",
    "\n",
    "            # update storage of Î¦\n",
    "            Î¦_storage[t-1,:] = Î¦\n",
    "\n",
    "\n",
    "        # Average all Î¦\n",
    "        Î¦ = np.mean(Î¦_storage,axis=0)\n",
    "\n",
    "        return Î¦\n",
    "    \n",
    "    def sgd_minibatch(self, game, batch_size, dimension_select, n_iter=100, step=.1, step_type=\"sqrt\",\n",
    "            callback=None, Î¦_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        The game is defined for an element x, a reference r and function fc\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        \n",
    "        f_x = game(np.ones((1, self.d), dtype=int))[0][dimension_select]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=int))[0][dimension_select]\n",
    "\n",
    "        \n",
    "        v_M = f_x - f_r\n",
    "\n",
    "        d = self.d\n",
    "        n = 2**d - 2\n",
    "        p = self.p\n",
    "        dict_Ï‰_k = self.dict_Ï‰_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # Store Shapley Values in a pandas Series\n",
    "        if Î¦_0:\n",
    "            Î¦ = Î¦_0.copy()\n",
    "        else:\n",
    "            Î¦ = np.zeros(d)\n",
    "        Î¦_storage = []\n",
    "\n",
    "        # projection onto convex set K by using a simple algorithm\n",
    "        # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "        Î¦ = Î¦ - (np.sum(Î¦) - v_M) / d\n",
    "\n",
    "        # Sample in advance coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        grad_i_accum=[]\n",
    "        \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            # Compute y_i\n",
    "            #z_S = np.array([x.values[j] if x_i[j] == 1 else ref.values[j] for j in range(d)])            \n",
    "            f_S = game(x_i[np.newaxis])[0][dimension_select]\n",
    "            y_i = f_S - f_r\n",
    "            # get weight Ï‰_i\n",
    "            Ï‰_i = dict_Ï‰_k[k]\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(Î¦, x_i, y_i, Ï‰_i)\n",
    "            grad_i_accum.append(grad_i)\n",
    "            \n",
    "            if t%batch_size==0:\n",
    "                # update Î¦\n",
    "                if step_type == \"constant\":\n",
    "                    Î¦ = Î¦ - step * np.array(grad_i_accum).mean(axis=0)\n",
    "                elif step_type == \"sqrt\":\n",
    "                    Î¦ = Î¦ - (step/np.sqrt(t)) * np.array(grad_i_accum).mean(axis=0)\n",
    "                elif step_type == \"inverse\":\n",
    "                    Î¦ = Î¦ - (step/(t)) * np.array(grad_i_accum).mean(axis=0)\n",
    "\n",
    "                # projection onto convex set K\n",
    "                # Î¦ = self._Dykstra_proj(Î¦, D, v_M, iter_proj, epsilon=1e-6)\n",
    "                Î¦ = Î¦ - (Î¦.sum() - v_M) / d\n",
    "\n",
    "                # update storage of Î¦\n",
    "                Î¦_storage.append(Î¦)\n",
    "                grad_i_accum=[]\n",
    "\n",
    "        # Average all Î¦\n",
    "        Î¦ = np.mean(np.array(Î¦_storage), axis=0)  \n",
    "        \n",
    "        return Î¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[20], \n",
    "                    shapley_value=shapley_loaded1, shapley_value_key=3584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[20], \n",
    "                    shapley_value=shapley_loaded2, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test[0]['iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da03715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[5], \n",
    "                    shapley_value=shapley_loaded_test, shapley_value_key=5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2453214",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[5], \n",
    "                    shapley_value=shapley_loaded_test_permutation, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447b6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f05fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[1], \n",
    "                    shapley_value=shapley_loaded_test_permutation, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39591",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test_permutation[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3be2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "3332/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded2[0]['iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"validation\"], sample_idx_list=[110], \n",
    "                    shapley_value=shapley_loaded2, shapley_value_key=3332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f89f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb577fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78860f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd(game,\n",
    "            n_iter=5000,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ff537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0141cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3850d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73023d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=32,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=32,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=64,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72116fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=64,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2a95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439316a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd_minibatch(game,\n",
    "            n_iter=5000,\n",
    "            batch_size=512,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e105d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990103b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35136ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8e3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df69be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "game(np.ones((1,196)))[0][8]-game(np.zeros((1,196)))[0][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0d4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02e5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13cf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old=SGDshapley(d=196, C=1)\n",
    "\n",
    "sgd_shapley_old_output=sgd_shapley_old.sgd(game,\n",
    "            n_iter=200000,\n",
    "            dimension_select=8,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a902b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6689f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e465a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output==np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69155255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_old_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d572a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbafe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [np.tile(sgd_shapley_old_output.reshape(-1,1), (1,10))],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efc5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda584e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e5e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "        f_x = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        f_r = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        import ipdb\n",
    "        ipdb.set_trace()\n",
    "        \n",
    "        v_M = f_x - f_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b0051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e1951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling=ShapleySampling(game,\n",
    "                    batch_size=32,\n",
    "                    n_samples=32*32,\n",
    "                    detect_convergence=False,\n",
    "                    thresh=0.01,\n",
    "                    antithetical=False,\n",
    "                    return_all=True,\n",
    "                    bar=True,\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d55ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818429f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc815a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e510e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad2f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72ff79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44812ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a35363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776710db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddd00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815cf31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158a08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820b53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d29d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa6fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "        \n",
    "        \n",
    "        k_record=[]\n",
    "        x_i_record=[]\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            \n",
    "            k_record.append(k)\n",
    "            x_i_record.append(x_i)\n",
    "            \n",
    "            \n",
    "        \n",
    "        x_i_record=np.array(x_i_record)\n",
    "        y_i_record=[]\n",
    "        \n",
    "        for i in tqdm(range(int(np.ceil(len(x_i_record)/128)))):\n",
    "\n",
    "            y_i = game(x_i_record[128*i:128*(i+1)].astype(int)) - null\n",
    "            y_i_record.append(y_i)\n",
    "\n",
    "        y_i_record=np.vstack(y_i_record)   \n",
    "                \n",
    "            \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            k=k_record[t-1]\n",
    "            x_i=x_i_record[t-1]\n",
    "            y_i = y_i_record[t-1]\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "#             res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "            res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "#         list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=self.p)\n",
    "        \n",
    "        \n",
    "        k_record=[]\n",
    "        x_i_record=[]\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "            \n",
    "            k_record.append(k)\n",
    "            x_i_record.append(x_i)\n",
    "            \n",
    "            \n",
    "        \n",
    "        x_i_record=np.array(x_i_record)\n",
    "        y_i_record=[]\n",
    "        \n",
    "        for i in tqdm(range(int(np.ceil(len(x_i_record)/128)))):\n",
    "\n",
    "            y_i = game(x_i_record[128*i:128*(i+1)].astype(int)) - null\n",
    "            y_i_record.append(y_i)\n",
    "\n",
    "        y_i_record=np.vstack(y_i_record)   \n",
    "                \n",
    "            \n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            k=k_record[t-1]\n",
    "            x_i=x_i_record[t-1]\n",
    "            y_i = y_i_record[t-1]\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "#             grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "            grad_i = self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18599a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fad0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited by: Ian Covert and Chanwoo Kim\n",
    "\n",
    "# Original authors: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#                   Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "class SGDShapleyNew():\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, C):\n",
    "        \"\"\"\n",
    "        Calculate internal values for later purposes\n",
    "        Those elements depend only on the number of features d\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : integer\n",
    "            Dimension of the problem. The number of features\n",
    "        C : float\n",
    "            Constant bounding |y|\n",
    "        \"\"\"\n",
    "\n",
    "        # Store in a dictionary for each size k of coalitions\n",
    "        dict_w_k = dict()  # weights per size k\n",
    "        dict_L_k = dict()  # L-smooth constant per size k\n",
    "        D = C * np.sqrt(d)\n",
    "        for k in range(1, d):\n",
    "            w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "            L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "            dict_w_k.update({k: w_k})\n",
    "            dict_L_k.update({k: L_k})\n",
    "\n",
    "        # Summation of all L per coalition (closed formula)\n",
    "        sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "        # Probability distributions for sampling new instance\n",
    "\n",
    "        # 1. Classic SGD (not used)\n",
    "        p = [ncr(d, k) for k in range(1, d)]\n",
    "        p /= np.sum(p)\n",
    "\n",
    "        # 2. Importance Sampling proposal q (used)\n",
    "        q = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "        q /= np.sum(q)\n",
    "\n",
    "        # Save internal attributes\n",
    "        self.d = d\n",
    "        self.dict_w_k = dict_w_k\n",
    "        self.dict_L_k = dict_L_k\n",
    "        self.sum_L = sum_L\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def _grad_F_i(self, phi, x_i, y_i, w_i):\n",
    "        \"\"\"Gradient vector per instance i\"\"\"\n",
    "        if isinstance(y_i, np.ndarray):\n",
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)\n",
    "        return res\n",
    "\n",
    "    def sgd(self,\n",
    "            game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False):\n",
    "        \"\"\"\n",
    "        Stochastic gradient descent algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        # Get general information\n",
    "        grand = game(np.ones((1, self.d), dtype=bool))[0]\n",
    "        null = game(np.zeros((1, self.d), dtype=bool))[0]\n",
    "        if isinstance(grand, np.ndarray):\n",
    "            out_dim = len(grand)\n",
    "        else:\n",
    "            out_dim = None\n",
    "        total = grand - null\n",
    "        # print(grand)\n",
    "        # print(null)\n",
    "        # print(total)\n",
    "        # print(out_dim)\n",
    "\n",
    "        d = self.d\n",
    "        dict_w_k = self.dict_w_k\n",
    "        q = self.q\n",
    "        dict_L_k = self.dict_L_k\n",
    "        sum_L = self.sum_L\n",
    "\n",
    "        # initialize Shapley value estimates\n",
    "        if phi_0:\n",
    "            phi = phi_0.copy()\n",
    "        else:\n",
    "            if out_dim is None:\n",
    "                phi = np.zeros(d)\n",
    "            else:\n",
    "                phi = np.zeros((d, out_dim))\n",
    "\n",
    "        # projection step\n",
    "        phi = phi - (np.sum(phi, axis=0) - total) / d\n",
    "\n",
    "        # store for iterate averaging\n",
    "        if out_dim is None:\n",
    "            phi_iterates = np.zeros((n_iter, d))\n",
    "        else:\n",
    "            phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "        # sample coalition sizes\n",
    "        list_k = np.random.choice(list(range(1, d)), size=n_iter, p=q)\n",
    "\n",
    "        for t in tqdm(range(1, n_iter+1)):\n",
    "            # build subset indicator x_i\n",
    "            k = list_k[t-1]\n",
    "            indexes = np.random.permutation(d)[:k]\n",
    "            x_i = np.zeros(d)\n",
    "            x_i[indexes] = 1\n",
    "\n",
    "            # Compute y_i\n",
    "#             print(x_i.astype(bool).shape)\n",
    "            y_i = game(x_i.astype(bool)[np.newaxis])[0] - null\n",
    "            #print(game(x_i.astype(bool)[np.newaxis])[0], y_i)\n",
    "\n",
    "            # get weight w_i for importance sampling\n",
    "            w_i = dict_w_k[k]\n",
    "\n",
    "            # calculate gradient\n",
    "            p_i = dict_L_k[k] / sum_L\n",
    "            grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "            # update phi\n",
    "            if step_type == \"constant\":\n",
    "                phi = phi - step * grad_i\n",
    "            elif step_type == \"sqrt\":\n",
    "                phi = phi - (step/np.sqrt(t)) * grad_i\n",
    "            elif step_type == \"inverse\":\n",
    "                phi = phi - (step/(t)) * grad_i\n",
    "\n",
    "            # projection step\n",
    "            phi = phi - (phi.sum(axis=0) - total) / d\n",
    "\n",
    "            # update iterate history\n",
    "            phi_iterates[t-1] = phi\n",
    "\n",
    "        # Average iterates\n",
    "        return np.cumsum(phi_iterates, axis=0)/(np.arange(len(phi_iterates))+1).reshape(-1,1,1)\n",
    "#         return phi_iterates\n",
    "        #phi = np.mean(phi_iterates, axis=0)\n",
    "        \n",
    "        return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=500000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db52ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b24747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe013aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/np.sqrt(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6adeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # print('y is an array')\n",
    "            res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "            import ipdb\n",
    "            ipdb.set_trace()\n",
    "            res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "        else:\n",
    "            # print('y is a scalar')\n",
    "            res = w_i * x_i * (x_i.dot(phi) - y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.01,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef736359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=10,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8bdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82783da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ff280",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c457f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75da035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369eaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.01,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508771bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b22dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# grad_i = 1/(p_i) * self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "grad_i = self._grad_F_i(phi, x_i, y_i, w_i)\n",
    "\n",
    "# res = w_i * x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]\n",
    "res = x_i[:, np.newaxis] * (x_i.dot(phi) - y_i)[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b21992",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [50,500,5000,50000]:\n",
    "    fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                        shapley_value={0:{\n",
    "                'values': [sgd_shapley_output[subset-1]],\n",
    "                'std': [],\n",
    "                'iters': [0]}}, shapley_value_key=int(0))\n",
    "    fig.suptitle(str(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad137386",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[50000-1]],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fcadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=5000,\n",
    "            step=0.1,\n",
    "            step_type=\"sqrt\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dad1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[10000-1]],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921511ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output[5000].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42207f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output__[:500].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([sgd_shapley_output__[:i+1].mean(axis=0) for i in range(len(sgd_shapley_output__[:100]))])==\\\n",
    "np.cumsum(sgd_shapley_output__[:100], axis=0)/(np.arange(len(sgd_shapley_output__[:100]))+1).reshape(-1,1,1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284beec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1199187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:50].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:500].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d78b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output__[:50].mean(axis=0)],\n",
    "            'std': [],\n",
    "            'iters': [0]}}, shapley_value_key=int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=100,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "game=PredictionGame(surrogate=explainer.surrogate,\n",
    "                    sample=dataset_explainer[\"test\"][0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91616161",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=50000,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.01,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley=SGDShapleyNew(d=196, C=1)\n",
    "\n",
    "sgd_shapley_output_=sgd_shapley.sgd(game,\n",
    "            n_iter=200000,\n",
    "            step=0.1,\n",
    "            step_type=\"inverse\",\n",
    "            phi_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling=ShapleySampling(game,\n",
    "                    batch_size=128,\n",
    "                    n_samples=8*128,\n",
    "                    detect_convergence=False,\n",
    "                    thresh=0.01,\n",
    "                    antithetical=False,\n",
    "                    return_all=True,\n",
    "                    bar=True,\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*128*196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafadca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0]['values'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapley_sampling[\"values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_shapley_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26261bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': sgd_shapley_output,\n",
    "            'std': [],\n",
    "            'iters': list(range(1, len(sgd_shapley_output)+1))}}, shapley_value_key=int(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44413bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output_],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde883cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value={0: shapley_sampling}, shapley_value_key=int(50176))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a78949",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfab3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"test\"], sample_idx_list=[0], \n",
    "                    shapley_value=shapley_loaded, shapley_value_key=int(3332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c14d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:{\n",
    "            'values': [sgd_shapley_output],\n",
    "            'std': [],\n",
    "            'iters': [50000]}}, shapley_value_key=int(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc34a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"aaaa.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad829039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tracking_dict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a611d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1397223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3547062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fdeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63690ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97299d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0cfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*196*128=10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "128*196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"][0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b573f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(25088))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], sample_idx_list=[0, 1, 2, 3, 4], \n",
    "                    shapley_value={0:shapley_sampling}, shapley_value_key=int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bab465",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.ceil(100 / 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd9e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0563bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_sampling[\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cee600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "10000*0.2/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(320068))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe08406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"train\"], [0, 1, 2, 3, 4], \n",
    "                    shapley_loaded, int(32144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f3c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b68d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(1536))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(5120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39906222",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test_permutation/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec62746",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420911e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5abeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "196*17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e46ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "200116/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dce950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 31], \n",
    "                    shapley_loaded, int(200116))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 31], \n",
    "                    shapley_loaded, int(3332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1036/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5db97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_permutation_upfront_196/checkpoint-888/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 20, 30, 31])\n",
    "# epoch 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6628a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_permutation_upfront_3332/checkpoint-8732/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 20, 30, 31])\n",
    "#19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6886162",
   "metadata": {},
   "outputs": [],
   "source": [
    "32*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "148*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample_32/checkpoint-740/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c1dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34db542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1839ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925f623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af73bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e0049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4c0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f794f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfc1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6078b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f27fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b74845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93724c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][-1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e497c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf77028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfbf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939a9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3725dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(shapley_loaded[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc744c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6470500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd51d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc7264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7d883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c7799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "512*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9977d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dab037",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(shapley_values_test[\"test\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03af49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840+512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a20d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 99840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3ffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecfb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000],\n",
    "                    shapley_values[\"validation\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc574e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3714ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e26bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley_train_val.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d05692",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef656d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfede0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Initalize the explainer trainer\n",
    "########################################################\n",
    "# Load the accuracy metric from the datasets package\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "def compute_metrics(p):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    # import ipdb\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(p.predictions.shape, p.label_ids.shape)\n",
    "    # return metric.compute(\n",
    "    #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "    #     references=p.label_ids,\n",
    "    # )\n",
    "    return {}\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels,\n",
    "        \"masks\": masks,\n",
    "    }\n",
    "\n",
    "explainer_trainer = Trainer(\n",
    "    model=explainer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "    eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=explainer_image_processor,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# ipdb.set_trace()\n",
    "# print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "# print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "########################################################\n",
    "# Detecting last checkpoint\n",
    "#######################################################\n",
    "last_checkpoint = None\n",
    "if (\n",
    "    os.path.isdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif (\n",
    "        last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "    ):\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Training\n",
    "#######################################################\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    explainer_trainer.save_model()\n",
    "    explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_state()\n",
    "\n",
    "########################################################\n",
    "# Evaluation\n",
    "#######################################################\n",
    "if training_args.do_eval:\n",
    "    metrics = explainer_trainer.evaluate()\n",
    "    explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "    explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "########################################################\n",
    "# Write model card and (optionally) push to hub\n",
    "#######################################################\n",
    "kwargs = {\n",
    "    \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "    \"tasks\": \"image-classification\",\n",
    "    \"dataset\": data_args.dataset_name,\n",
    "    \"tags\": [\"image-classification\", \"vision\"],\n",
    "}\n",
    "if training_args.push_to_hub:\n",
    "    explainer_trainer.push_to_hub(**kwargs)\n",
    "else:\n",
    "    explainer_trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4f0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fa564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e459b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5eb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec93405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ede138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec9aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6306a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab5732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5627301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf8f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d8d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf9207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f239a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    # Initalize the explainer trainer\n",
    "    ########################################################\n",
    "    # Load the accuracy metric from the datasets package\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    # Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "    # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "    def compute_metrics(p):\n",
    "        \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "        # import ipdb\n",
    "\n",
    "        # ipdb.set_trace()\n",
    "        # print(p.predictions.shape, p.label_ids.shape)\n",
    "        # return metric.compute(\n",
    "        #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "        #     references=p.label_ids,\n",
    "        # )\n",
    "        return {}\n",
    "\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "        labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "        masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "        }\n",
    "\n",
    "    explainer_trainer = Trainer(\n",
    "        model=explainer,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "        eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=explainer_image_processor,\n",
    "        data_collator=collate_fn,\n",
    "    )\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "    # print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "    ########################################################\n",
    "    # Detecting last checkpoint\n",
    "    #######################################################\n",
    "    last_checkpoint = None\n",
    "    if (\n",
    "        os.path.isdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "    ):\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif (\n",
    "            last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "        ):\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    ########################################################\n",
    "    # Training\n",
    "    #######################################################\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        explainer_trainer.save_model()\n",
    "        explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_state()\n",
    "\n",
    "    ########################################################\n",
    "    # Evaluation\n",
    "    #######################################################\n",
    "    if training_args.do_eval:\n",
    "        metrics = explainer_trainer.evaluate()\n",
    "        explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "        explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    ########################################################\n",
    "    # Write model card and (optionally) push to hub\n",
    "    #######################################################\n",
    "    kwargs = {\n",
    "        \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "        \"tasks\": \"image-classification\",\n",
    "        \"dataset\": data_args.dataset_name,\n",
    "        \"tags\": [\"image-classification\", \"vision\"],\n",
    "    }\n",
    "    if training_args.push_to_hub:\n",
    "        explainer_trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        explainer_trainer.create_model_card(**kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15231b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99353761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
