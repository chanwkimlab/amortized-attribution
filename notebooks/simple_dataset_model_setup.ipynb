{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0b0f7b",
   "metadata": {},
   "source": [
    "# Set up dataset and model\n",
    "\n",
    "Please run all the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv=[\"train_objexplainer.py\", \"configs/vitbase_imagenette_shapley_objexplainer_newsample_32.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import evaluate\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from arguments import DataTrainingArguments, ExplainerArguments, SurrogateArguments\n",
    "from models import (\n",
    "    ObjExplainerForImageClassification,\n",
    "    ObjExplainerForImageClassificationConfig,\n",
    "    SurrogateForImageClassificationConfig,\n",
    ")\n",
    "from utils import (\n",
    "    MaskDataset,\n",
    "    configure_dataset,\n",
    "    generate_mask,\n",
    "    get_checkpoint,\n",
    "    get_image_transform,\n",
    "    load_shapley,\n",
    "    log_dataset,\n",
    "    read_eval_results,\n",
    "    setup_dataset,\n",
    ")\n",
    "\n",
    "\"\"\" Fine-tuning a ðŸ¤— Transformers model for image classification\"\"\"\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.32.0.dev0\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/image-classification/requirements.txt\",\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OtherArguments:\n",
    "    token: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n",
    "                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    validation_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    test_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    train_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for train\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    validation_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for validation\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    test_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for test\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Parse arguments\n",
    "#######################################################\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "parser = HfArgumentParser(\n",
    "    (\n",
    "        SurrogateArguments,\n",
    "        ExplainerArguments,\n",
    "        DataTrainingArguments,\n",
    "        TrainingArguments,\n",
    "        OtherArguments,\n",
    "    )\n",
    ")\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "else:\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_args_into_dataclasses()\n",
    "\n",
    "########################################################\n",
    "# Setup logging\n",
    "#######################################################\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "if training_args.should_log:\n",
    "    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "########################################################\n",
    "# Correct cache dir if necessary\n",
    "########################################################\n",
    "if not os.path.exists(\n",
    "    os.sep.join((data_args.dataset_cache_dir).split(os.sep, 2)[:2])\n",
    "):\n",
    "    if os.path.exists(\"/data2\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/data2\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    elif os.path.exists(\"/sdata\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/sdata\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Set seed before initializing model.\n",
    "########################################################\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "########################################################\n",
    "# Initialize our dataset and prepare it for the 'image-classification' task.\n",
    "########################################################\n",
    "dataset_original, labels, label2id, id2label = setup_dataset(\n",
    "    data_args=data_args, other_args=other_args\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Initialize explainer model\n",
    "########################################################\n",
    "\n",
    "explainer_config = AutoConfig.from_pretrained(\n",
    "    explainer_args.explainer_config_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "if os.path.isfile(\n",
    "    f\"{explainer_args.explainer_model_name_or_path}/config.json\"\n",
    ") and (\n",
    "    json.loads(\n",
    "        open(f\"{explainer_args.explainer_model_name_or_path}/config.json\").read()\n",
    "    )[\"architectures\"][0]\n",
    "    == \"ObjExplainerForImageClassification\"\n",
    "):\n",
    "    explainer = ObjExplainerForImageClassification.from_pretrained(\n",
    "        explainer_args.explainer_model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "        config=explainer_config,\n",
    "        cache_dir=explainer_args.explainer_cache_dir,\n",
    "        revision=explainer_args.explainer_model_revision,\n",
    "        token=other_args.token,\n",
    "        ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "else:\n",
    "    surrogate_config = AutoConfig.from_pretrained(\n",
    "        surrogate_args.surrogate_config_name\n",
    "        or surrogate_args.surrogate_model_name_or_path,\n",
    "        num_labels=len(labels),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        finetuning_task=\"image-classification\",\n",
    "        cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        revision=surrogate_args.surrogate_model_revision,\n",
    "        token=other_args.token,\n",
    "    )\n",
    "    surrogate_for_image_classification_config = SurrogateForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer_for_image_classification_config = ObjExplainerForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_for_image_classification_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "        explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "        explainer_config=explainer_config,\n",
    "        explainer_from_tf=bool(\n",
    "            \".ckpt\" in explainer_args.explainer_model_name_or_path\n",
    "        ),\n",
    "        explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "        explainer_revision=explainer_args.explainer_model_revision,\n",
    "        explainer_token=other_args.token,\n",
    "        explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer = ObjExplainerForImageClassification(\n",
    "        config=explainer_for_image_classification_config,\n",
    "    )\n",
    "explainer_image_processor = AutoImageProcessor.from_pretrained(\n",
    "    explainer_args.explainer_image_processor_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Configure dataset (set max samples, transforms, etc.)\n",
    "########################################################\n",
    "dataset_explainer = copy.deepcopy(dataset_original)\n",
    "dataset_explainer = configure_dataset(\n",
    "    dataset=dataset_explainer,\n",
    "    image_processor=explainer_image_processor,\n",
    "    training_args=training_args,\n",
    "    data_args=data_args,\n",
    "    train_augmentation=False,\n",
    "    validation_augmentation=False,\n",
    "    test_augmentation=False,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "model=explainer.surrogate\n",
    "model.to(device)\n",
    "\n",
    "dataset=dataset_explainer[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7ca9a",
   "metadata": {},
   "source": [
    "# label info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b121b",
   "metadata": {},
   "source": [
    "# Model inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28547b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfddc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefee089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae291d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aadc2a",
   "metadata": {},
   "source": [
    "pixel_values: (batch_size, channel, height, weight)\n",
    "\n",
    "masks: (batch_size, num_mask_samples, num_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86a0fb",
   "metadata": {},
   "source": [
    "## get grand value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output=model(pixel_values=sample[\"pixel_values\"].unsqueeze(0).to(device), \n",
    "          masks=torch.ones((1,1,196), device=device),\n",
    "          return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41deb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.logits)\n",
    "print(output.logits.softmax(dim=-1)[0, 0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e713d8",
   "metadata": {},
   "source": [
    "## get grand and null simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe06791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output=model(pixel_values=sample[\"pixel_values\"].unsqueeze(0).to(device),\n",
    "          masks=torch.concat([torch.ones((1,1,196), device=device), torch.zeros((1,1,196), device=device)], axis=1),\n",
    "          return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bba982",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.logits[0].cpu().numpy())\n",
    "print(output.logits[0].softmax(-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f51ef2",
   "metadata": {},
   "source": [
    "# Example `Game` class for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77acd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperativeGame:\n",
    "    '''Base class for cooperative games.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''Evaluate cooperative game.'''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def grand(self):\n",
    "        '''Get grand coalition value.'''\n",
    "        return self.__call__(np.ones((1, self.players), dtype=int))[0]\n",
    "\n",
    "    def null(self):\n",
    "        '''Get null coalition value.'''\n",
    "        return self.__call__(np.zeros((1, self.players), dtype=int))[0]\n",
    "\n",
    "\n",
    "class PredictionGame(CooperativeGame):\n",
    "    '''\n",
    "    Cooperative game for an individual example's prediction.\n",
    "\n",
    "    Args:\n",
    "      extension: model extension (see removal.py).\n",
    "      sample: numpy array representing a single model input.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, surrogate, sample):\n",
    "        # Store sample.\n",
    "        self.surrogate = surrogate\n",
    "        self.sample = sample\n",
    "        self.players = 196\n",
    "\n",
    "    def __call__(self, S):\n",
    "        '''\n",
    "        Evaluate cooperative game.\n",
    "\n",
    "        Args:\n",
    "          S: array of player coalitions with size (batch, players).\n",
    "        '''\n",
    "        # Evaluate.\n",
    "        with torch.no_grad():\n",
    "            output = self.surrogate(\n",
    "                self.sample[\"pixel_values\"].unsqueeze(0).to(device), \n",
    "                torch.Tensor(S).unsqueeze(0).to(device),\n",
    "                return_loss=False)\n",
    "            return output.logits[0].softmax(dim=-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3572cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = PredictionGame(\n",
    "    surrogate=explainer.surrogate,\n",
    "    sample=dataset_explainer[\"test\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game.grand().shape)\n",
    "print(game.null().shape)\n",
    "print(game(np.random.choice([0,1], size=(4,196), replace=True)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e77c38",
   "metadata": {},
   "source": [
    "# SGD Shapley implementation\n",
    "\n",
    "Todo list:\n",
    "- (Done) Implementing minibatches\n",
    "- (Done) Make importance sampling optional\n",
    "- (Done) Make paired sampling optional\n",
    "- (Done) Change to function rather than class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ncr(n, r):\n",
    "    \"\"\"\n",
    "    Combinatorial computation: number of subsets of size r among n elements\n",
    "    Efficient algorithm\n",
    "    \"\"\"\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "def projection_step(phi, total):\n",
    "    return phi - (np.sum(phi, axis=0) - total) / len(phi)\n",
    "\n",
    "\n",
    "def SGDShapley(game,\n",
    "               n_iter=100,\n",
    "               mbsize=32,\n",
    "               step=0.001,\n",
    "               step_type=\"constant\",\n",
    "               sampling=\"importance\",\n",
    "               averaging=\"uniform\",\n",
    "               C=1,\n",
    "               phi_0=False):\n",
    "    \"\"\"\n",
    "    Estimate the Shapley values using projected stochastic gradient descent.\n",
    "    \"\"\"\n",
    "    # Get general information\n",
    "    assert sampling in (\"default\", \"paired\", \"importance\")\n",
    "    assert step_type in (\"constant\", \"sqrt\", \"inverse\")\n",
    "    assert averaging in (\"none\", \"uniform\", \"tail\")\n",
    "    d = game.players\n",
    "\n",
    "    # Setup for importance sampling\n",
    "    dict_w_k = dict()  # weights per size k\n",
    "    dict_L_k = dict()  # L-smooth constant per size k\n",
    "    D = C * np.sqrt(d)\n",
    "    for k in range(1, d):\n",
    "        w_k = (d - 1) / (ncr(d, k) * k * (d - k))\n",
    "        L_k = w_k * np.sqrt(k) * (np.sqrt(k) * D + C)\n",
    "        dict_w_k.update({k: w_k})\n",
    "        dict_L_k.update({k: L_k})\n",
    "\n",
    "    # Summation of all L per coalition (closed formula)\n",
    "    sum_L = np.sum([(d-1)/(np.sqrt(k)*(d-k)) * (np.sqrt(k)*D + C) for k in range(1, d)])\n",
    "\n",
    "    # Subset distributions\n",
    "\n",
    "    # 1. Importance sampling\n",
    "    p = [ncr(d, k) for k in range(1, d)]\n",
    "    p /= np.sum(p)\n",
    "    p_importance = np.array(list(dict_L_k.values())) * np.array(p)\n",
    "    p_importance /= np.sum(p_importance)\n",
    "\n",
    "    # 2. Default distribution or paired sampling\n",
    "    p_default = 1 / (np.arange(1, d) * (d - np.arange(1, d)))\n",
    "    p_default /= p_default.sum()\n",
    "\n",
    "    # Get null/grand and output dimension\n",
    "    grand = game(np.ones((1, d), dtype=bool))[0]\n",
    "    null = game(np.zeros((1, d), dtype=bool))[0]\n",
    "    assert isinstance(grand, np.ndarray)\n",
    "    out_dim = len(grand)\n",
    "    total = grand - null\n",
    "\n",
    "    # Initialize Shapley value estimates\n",
    "    if phi_0:\n",
    "        phi = phi_0.copy()\n",
    "    else:\n",
    "        phi = np.zeros((d, out_dim))\n",
    "\n",
    "    # Projection step\n",
    "    phi = projection_step(phi, total)\n",
    "\n",
    "    # Store for iterate averaging\n",
    "    if out_dim is None:\n",
    "        phi_iterates = np.zeros((n_iter, d))\n",
    "    else:\n",
    "        phi_iterates = np.zeros((n_iter, d, out_dim))\n",
    "\n",
    "    for t in tqdm(range(n_iter)):\n",
    "        # Sample subset cardinality\n",
    "        if sampling == \"importance\":\n",
    "            k_list = np.random.choice(list(range(1, d)), size=mbsize, p=p_importance)\n",
    "        else:\n",
    "            k_list = np.random.choice(list(range(1, d)), size=mbsize, p=p_default)\n",
    "\n",
    "        # Apply permutations\n",
    "        indices = [np.random.permutation(d)[:k] for k in k_list]\n",
    "        x = np.zeros((mbsize, d))\n",
    "        for i in range(mbsize):\n",
    "            if (i % 2 == 1) and (sampling == \"paired\"):\n",
    "                x[i] = 1 - x[i - 1]\n",
    "            else:\n",
    "                x[i, indices[i]] = 1\n",
    "\n",
    "        # Compute y\n",
    "        y = game(x.astype(bool)) - null\n",
    "\n",
    "        # Calculate gradient\n",
    "        residual = (x.dot(phi) - y)\n",
    "        grad = x[:, :, None] * residual[:, None, :]\n",
    "        if sampling == \"importance\":\n",
    "            # Get weights w, p for importance sampling\n",
    "            w = np.array([dict_w_k[k] for k in x.sum(axis=1)])\n",
    "            p = np.array([dict_L_k[k] / sum_L for k in x.sum(axis=1)])\n",
    "\n",
    "            # Apply importance sampling weights\n",
    "            grad *= np.expand_dims(w / p, (1, 2))\n",
    "\n",
    "        # Average gradient\n",
    "        grad = np.mean(grad, axis=0)\n",
    "\n",
    "        # Update phi\n",
    "        if step_type == \"constant\":\n",
    "            phi = phi - step * grad\n",
    "        elif step_type == \"sqrt\":\n",
    "            phi = phi - (step / np.sqrt(t + 1)) * grad\n",
    "        elif step_type == \"inverse\":\n",
    "            phi = phi - (step / (t + 1)) * grad\n",
    "\n",
    "        # Projection step\n",
    "        phi = projection_step(phi, total)\n",
    "\n",
    "        # Update iterate history\n",
    "        phi_iterates[t] = phi\n",
    "\n",
    "    # Calculate iterate averages\n",
    "    if averaging == \"none\":\n",
    "        return phi_iterates\n",
    "    elif averaging == \"uniform\":\n",
    "        averaged = np.cumsum(phi_iterates, axis=0) / np.expand_dims(np.arange(n_iter) + 1, (1, 2))\n",
    "        return averaged\n",
    "    elif averaging == \"tail\":\n",
    "        t = np.expand_dims(np.arange(len(phi_iterates)) + 1, (1, 2))\n",
    "        averaged = np.cumsum(2 * phi_iterates * t, axis=0) / (t * (t + 1))\n",
    "        return averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1edc3",
   "metadata": {},
   "source": [
    "# SGD Shapley ground truth tests\n",
    "\n",
    "@chanwoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_shapley\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded_test = load_shapley(\"logs/vitbase_imagenette_surrogate_shapley_eval_test/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 10\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    # Run SGD estimator\n",
    "    phi = SGDShapley(\n",
    "        game,\n",
    "        mbsize=2,\n",
    "        n_iter=5000,\n",
    "        step=0.0005,\n",
    "        sampling=\"paired\",\n",
    "        step_type=\"constant\",\n",
    "        averaging=\"uniform\",\n",
    "    )\n",
    "\n",
    "    # Store values\n",
    "    sgd_results[i] = {\n",
    "        \"estimates\": phi,\n",
    "        \"label\": sample[\"labels\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual curves\n",
    "dist_list = []\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Get target-class estimates\n",
    "    label = sgd_results[i][\"label\"]\n",
    "    estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "    # Get target-class ground truth\n",
    "    ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "    \n",
    "    # Plot distance\n",
    "    dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "    dist_list.append(dist)\n",
    "    plt.plot(np.arange(len(dist)), dist, color=\"C0\")\n",
    "    \n",
    "plt.title(\"SGD Shapley Convergence\")\n",
    "plt.xlabel(\"# Steps\")\n",
    "plt.ylabel(\"L2 Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged curve\n",
    "plt.figure()\n",
    "mean_dist = np.array(dist_list).mean(axis=0)\n",
    "plt.plot(np.arange(len(mean_dist)), mean_dist)\n",
    "plt.title(\"SGD Shapley Convergence\")\n",
    "plt.xlabel(\"# Steps\")\n",
    "plt.ylabel(\"L2 Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0649a0e",
   "metadata": {},
   "source": [
    "# Parameter tuning\n",
    "\n",
    "- Inverse step schedule leads to very slow progress, constant often works better\n",
    "- Step size = 0.001 worked best for one sample, but leads to divergence for others\n",
    "- Tail averaging works better when objective improves monotonically, uniform is better in noisy cases\n",
    "- Default subset distribution seems to work better than importance sampling. Setting mbsize = 2 with paired sampling works even better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d82d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\", \"inverse\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=1,\n",
    "            n_iter=10000,\n",
    "            step=0.001,\n",
    "            sampling=\"importance\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\", \"inverse\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=1,\n",
    "            n_iter=10000,\n",
    "            step=0.0003,\n",
    "            sampling=\"importance\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96828843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\", \"inverse\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=1,\n",
    "            n_iter=10000,\n",
    "            step=0.0003,\n",
    "            sampling=\"default\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=1,\n",
    "            n_iter=10000,\n",
    "            step=0.0001,\n",
    "            sampling=\"default\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb70bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=1,\n",
    "            n_iter=10000,\n",
    "            step=0.001,\n",
    "            sampling=\"default\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60058795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\", \"sqrt\"):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.0003,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\",):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.0002,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19610fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\",):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.0005,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97978043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\",):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.0007,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139214b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\",):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.001,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 1\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    for step_type in (\"constant\",):\n",
    "        # Run SGD estimator\n",
    "        phi = SGDShapley(\n",
    "            game,\n",
    "            mbsize=2,\n",
    "            n_iter=5000,\n",
    "            step=0.0015,\n",
    "            sampling=\"paired\",\n",
    "            step_type=step_type,\n",
    "            averaging=\"none\",\n",
    "        )\n",
    "\n",
    "        # Store values\n",
    "        sgd_results[i] = {\n",
    "            \"estimates\": phi,\n",
    "            \"label\": sample[\"labels\"]\n",
    "        }\n",
    "\n",
    "        ### Plot results ###\n",
    "\n",
    "        # Get target-class estimates\n",
    "        label = sgd_results[i][\"label\"]\n",
    "        estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "        # Get target-class ground truth\n",
    "        ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        # No averaging\n",
    "        dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "        # Uniform averaging\n",
    "        averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "        # Tail averaging\n",
    "        t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "        averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "        dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "        plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "        plt.title(f'SGD Shapley Convergence (index={i} step_type={step_type})')\n",
    "        plt.ylabel('L2 Distance to Ground Truth')\n",
    "        plt.xlabel('# Steps')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_examples = 10\n",
    "sgd_results = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Set up game\n",
    "    sample = dataset_explainer[\"test\"][i]\n",
    "    game = PredictionGame(\n",
    "        surrogate=explainer.surrogate,\n",
    "        sample=sample\n",
    "    )\n",
    "\n",
    "    # Run SGD estimator\n",
    "    phi = SGDShapley(\n",
    "        game,\n",
    "        mbsize=2,\n",
    "        n_iter=5000,\n",
    "        step=0.001,\n",
    "        sampling=\"paired\",\n",
    "        step_type=\"constant\",\n",
    "        averaging=\"none\",\n",
    "    )\n",
    "\n",
    "    # Store values\n",
    "    sgd_results[i] = {\n",
    "        \"estimates\": phi,\n",
    "        \"label\": sample[\"labels\"]\n",
    "    }\n",
    "\n",
    "    ### Plot results ###\n",
    "\n",
    "    # Get target-class estimates\n",
    "    label = sgd_results[i][\"label\"]\n",
    "    estimates = sgd_results[i][\"estimates\"][:, :, label]\n",
    "\n",
    "    # Get target-class ground truth\n",
    "    ground_truth = shapley_loaded_test[i][\"values\"][-1][:, label]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # No averaging\n",
    "    dist = np.sqrt(np.sum((estimates - ground_truth) ** 2, axis=1))\n",
    "    plt.plot(1 + np.arange(len(dist)), dist, label=\"No Averaging\")\n",
    "\n",
    "    # Uniform averaging\n",
    "    averaged = np.cumsum(estimates, axis=0) / np.expand_dims(1 + np.arange(len(estimates)), 1)\n",
    "    dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "    plt.plot(1 + np.arange(len(dist)), dist, label=\"Uniform Average\")\n",
    "\n",
    "    # Tail averaging\n",
    "    t = np.expand_dims(np.arange(len(estimates)) + 1, 1)\n",
    "    averaged = np.cumsum(2 * estimates * t, axis=0) / (t * (t + 1))\n",
    "    dist = np.sqrt(np.sum((averaged - ground_truth) ** 2, axis=1))\n",
    "    plt.plot(1 + np.arange(len(dist)), dist, label=\"Tail Average\")\n",
    "\n",
    "    plt.title(f'SGD Shapley Convergence (index={i})')\n",
    "    plt.ylabel('L2 Distance to Ground Truth')\n",
    "    plt.xlabel('# Steps')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual sanity checks\n",
    "for i in range(n_examples):\n",
    "    fig, axarr = plt.subplots(1, 2)\n",
    "    \n",
    "    axarr[0].imshow(dataset_explainer[\"test\"][i][\"image\"])\n",
    "    axarr[0].set_xticks([])\n",
    "    axarr[0].set_yticks([])\n",
    "    \n",
    "    estimates = sgd_results[i][\"estimates\"][-1, :, sgd_results[i][\"label\"]]\n",
    "    max_abs = np.absolute(estimates).max()\n",
    "    axarr[1].imshow(estimates.reshape(14, 14), vmin=-max_abs, vmax=max_abs, cmap=\"seismic\")\n",
    "    axarr[1].set_xticks([])\n",
    "    axarr[1].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
