{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv=[\"train_objexplainer.py\", \"configs/vitbase_imagenette_objexplainer_newsample_32.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import evaluate\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from arguments import DataTrainingArguments, ExplainerArguments, SurrogateArguments\n",
    "from models import (\n",
    "    ObjExplainerForImageClassification,\n",
    "    ObjExplainerForImageClassificationConfig,\n",
    "    SurrogateForImageClassificationConfig,\n",
    ")\n",
    "from utils import (\n",
    "    MaskDataset,\n",
    "    configure_dataset,\n",
    "    generate_mask,\n",
    "    get_checkpoint,\n",
    "    get_image_transform,\n",
    "    load_shapley,\n",
    "    log_dataset,\n",
    "    read_eval_results,\n",
    "    setup_dataset,\n",
    ")\n",
    "\n",
    "\"\"\" Fine-tuning a ðŸ¤— Transformers model for image classification\"\"\"\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.32.0.dev0\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/image-classification/requirements.txt\",\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OtherArguments:\n",
    "    token: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n",
    "                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    validation_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    test_subsets_cache_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to load the downloaded dataset.\",\n",
    "        },\n",
    "    )\n",
    "    train_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for train\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    validation_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for validation\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    test_mask_mode: str = field(\n",
    "        default=\"incremental,1\",\n",
    "        metadata={\n",
    "            \"help\": \"mask mode for test\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Parse arguments\n",
    "#######################################################\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "parser = HfArgumentParser(\n",
    "    (\n",
    "        SurrogateArguments,\n",
    "        ExplainerArguments,\n",
    "        DataTrainingArguments,\n",
    "        TrainingArguments,\n",
    "        OtherArguments,\n",
    "    )\n",
    ")\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "else:\n",
    "    (\n",
    "        surrogate_args,\n",
    "        explainer_args,\n",
    "        data_args,\n",
    "        training_args,\n",
    "        other_args,\n",
    "    ) = parser.parse_args_into_dataclasses()\n",
    "\n",
    "########################################################\n",
    "# Setup logging\n",
    "#######################################################\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "if training_args.should_log:\n",
    "    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "########################################################\n",
    "# Correct cache dir if necessary\n",
    "########################################################\n",
    "if not os.path.exists(\n",
    "    os.sep.join((data_args.dataset_cache_dir).split(os.sep, 2)[:2])\n",
    "):\n",
    "    if os.path.exists(\"/data2\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/data2\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    elif os.path.exists(\"/sdata\"):\n",
    "        data_args.dataset_cache_dir = os.sep.join(\n",
    "            [\"/sdata\"] + (data_args.dataset_cache_dir).split(os.sep, 2)[2:]\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found, using {data_args.dataset_cache_dir}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"dataset_cache_dir {data_args.dataset_cache_dir} not found\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Set seed before initializing model.\n",
    "########################################################\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "########################################################\n",
    "# Initialize our dataset and prepare it for the 'image-classification' task.\n",
    "########################################################\n",
    "dataset_original, labels, label2id, id2label = setup_dataset(\n",
    "    data_args=data_args, other_args=other_args\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Initialize explainer model\n",
    "########################################################\n",
    "\n",
    "explainer_config = AutoConfig.from_pretrained(\n",
    "    explainer_args.explainer_config_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "if os.path.isfile(\n",
    "    f\"{explainer_args.explainer_model_name_or_path}/config.json\"\n",
    ") and (\n",
    "    json.loads(\n",
    "        open(f\"{explainer_args.explainer_model_name_or_path}/config.json\").read()\n",
    "    )[\"architectures\"][0]\n",
    "    == \"ObjExplainerForImageClassification\"\n",
    "):\n",
    "    explainer = ObjExplainerForImageClassification.from_pretrained(\n",
    "        explainer_args.explainer_model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "        config=explainer_config,\n",
    "        cache_dir=explainer_args.explainer_cache_dir,\n",
    "        revision=explainer_args.explainer_model_revision,\n",
    "        token=other_args.token,\n",
    "        ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "else:\n",
    "    surrogate_config = AutoConfig.from_pretrained(\n",
    "        surrogate_args.surrogate_config_name\n",
    "        or surrogate_args.surrogate_model_name_or_path,\n",
    "        num_labels=len(labels),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        finetuning_task=\"image-classification\",\n",
    "        cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        revision=surrogate_args.surrogate_model_revision,\n",
    "        token=other_args.token,\n",
    "    )\n",
    "    surrogate_for_image_classification_config = SurrogateForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer_for_image_classification_config = ObjExplainerForImageClassificationConfig(\n",
    "        surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "        surrogate_config=surrogate_for_image_classification_config,\n",
    "        surrogate_from_tf=bool(\n",
    "            \".ckpt\" in surrogate_args.surrogate_model_name_or_path\n",
    "        ),\n",
    "        surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "        surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "        surrogate_token=other_args.token,\n",
    "        surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "        explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "        explainer_config=explainer_config,\n",
    "        explainer_from_tf=bool(\n",
    "            \".ckpt\" in explainer_args.explainer_model_name_or_path\n",
    "        ),\n",
    "        explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "        explainer_revision=explainer_args.explainer_model_revision,\n",
    "        explainer_token=other_args.token,\n",
    "        explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    explainer = ObjExplainerForImageClassification(\n",
    "        config=explainer_for_image_classification_config,\n",
    "    )\n",
    "explainer_image_processor = AutoImageProcessor.from_pretrained(\n",
    "    explainer_args.explainer_image_processor_name\n",
    "    or explainer_args.explainer_model_name_or_path,\n",
    "    cache_dir=explainer_args.explainer_cache_dir,\n",
    "    revision=explainer_args.explainer_model_revision,\n",
    "    token=other_args.token,\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Configure dataset (set max samples, transforms, etc.)\n",
    "########################################################\n",
    "dataset_explainer = copy.deepcopy(dataset_original)\n",
    "dataset_explainer = configure_dataset(\n",
    "    dataset=dataset_explainer,\n",
    "    image_processor=explainer_image_processor,\n",
    "    training_args=training_args,\n",
    "    data_args=data_args,\n",
    "    train_augmentation=False,\n",
    "    validation_augmentation=False,\n",
    "    test_augmentation=False,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820654d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9592e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import (\n",
    "    RegExplainerForImageClassification,\n",
    "    RegExplainerForImageClassificationConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer_for_image_classification_config = RegExplainerForImageClassificationConfig(\n",
    "    surrogate_pretrained_model_name_or_path=surrogate_args.surrogate_model_name_or_path,\n",
    "    surrogate_config=surrogate_for_image_classification_config,\n",
    "    surrogate_from_tf=bool(\".ckpt\" in surrogate_args.surrogate_model_name_or_path),\n",
    "    surrogate_cache_dir=surrogate_args.surrogate_cache_dir,\n",
    "    surrogate_revision=surrogate_args.surrogate_model_revision,\n",
    "    surrogate_token=other_args.token,\n",
    "    surrogate_ignore_mismatched_sizes=surrogate_args.surrogate_ignore_mismatched_sizes,\n",
    "    explainer_pretrained_model_name_or_path=explainer_args.explainer_model_name_or_path,\n",
    "    explainer_config=explainer_config,\n",
    "    explainer_from_tf=bool(\".ckpt\" in explainer_args.explainer_model_name_or_path),\n",
    "    explainer_cache_dir=explainer_args.explainer_cache_dir,\n",
    "    explainer_revision=explainer_args.explainer_model_revision,\n",
    "    explainer_token=other_args.token,\n",
    "    explainer_ignore_mismatched_sizes=explainer_args.explainer_ignore_mismatched_sizes,\n",
    ")\n",
    "\n",
    "regexplainer = RegExplainerForImageClassification(\n",
    "    config=regexplainer_for_image_classification_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0a28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174db1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b16c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3db1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexplainer(pixel_values=data[\"pixel_values\"].unsqueeze(0), return_loss=False)[\"logits\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82608186",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset[\"test_explainer\"]:\n",
    "    regexplainer.eval()\n",
    "    with torch.no_grad():\n",
    "        regexplainer(pixel_values=data[\"pixel_values\"].unsqueeze(0), return_loss=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b814ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_dict=torch.load(\"logs/vitbase_imagenette_surrogate_eval/shapley.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapley_values_dict[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_ground_truth=99840\n",
    "\n",
    "mse_dict={\n",
    "    \"target\": {},\n",
    "    \"non_target\": {},\n",
    "    \"all\": {}\n",
    "}\n",
    "\n",
    "for num_eval_shapley_values in shapley_values_dict[\"test\"]:\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[99840].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[99840])\n",
    "        mse_class=(diff*diff).mean(axis=0)\n",
    "        \n",
    "        mse_dict[\"target\"].setdefault(num_eval, []).append(mse_class[np.arange(len(mse_class))==target_class_idx].mean())\n",
    "        mse_dict[\"non_target\"].setdefault(num_eval, []).append(mse_class[np.arange(len(mse_class))!=target_class_idx].mean())\n",
    "        mse_dict[\"all\"].setdefault(num_eval, []).append(mse_class[:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384a3ae",
   "metadata": {},
   "source": [
    "# per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_ground_truth=99840\n",
    "\n",
    "record_dict_list=[]\n",
    "\n",
    "for sample_idx, num_eval_shapley_values in enumerate(shapley_values_dict[\"test\"]):\n",
    "    target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "    for num_eval, shapley_values in num_eval_shapley_values.items():\n",
    "        diff=(shapley_values-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)\n",
    "        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"per-sample\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_estimated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd84ee",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4babde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',                       \n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "    fig=plot_figure(explainer=regexplainer, \n",
    "                dataset=dataset[\"test_explainer\"], \n",
    "                sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "    fig.suptitle(f\"Reg-AO {num_eval}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae9a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b04791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_reg in ['logs/vitbase_imagenette_explainer_regression_0',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1024',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_512',\n",
    "                       'logs/vitbase_imagenette_explainer_regression_1536']:\n",
    "    num_eval=int(model_path_reg.split('_')[-1])+512\n",
    "    state_dict = torch.load(f\"{model_path_reg}/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    regexplainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(shapley_values_dict[\"test\"], dataset[\"test_explainer\"])):\n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        regexplainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=regexplainer(pixel_values=data[\"pixel_values\"].unsqueeze(0), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"regression_AO\",            \n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for model_path_obj in sorted(glob.glob(\"logs/vitbase_imagenette_explainer_objective/checkpoint-*\"), key=lambda x: int(x.split('-')[-1])):\n",
    "    num_eval=int(model_path_obj.split('-')[-1])/148*32\n",
    "    if int(int(model_path_obj.split('-')[-1])/148)%10!=1:\n",
    "        continue\n",
    "    state_dict = torch.load(f\"{model_path_obj}/pytorch_model.bin\", map_location=\"cpu\")\n",
    "    explainer.load_state_dict(state_dict)\n",
    "#     fig=plot_figure(explainer=regexplainer, \n",
    "#                 dataset=dataset[\"test_explainer\"], \n",
    "#                 sample_idx_list=[0,  10, 20, 30, 40, 50, 60, 70])\n",
    "#     fig.suptitle(f\"Reg-AO {num_model_eval}\")    \n",
    "    for sample_idx, (num_eval_shapley_values, data) in enumerate(zip(tqdm.tqdm(shapley_values_dict[\"test\"]), dataset[\"test_explainer\"])):        \n",
    "        target_class_idx=np.argmax(num_eval_shapley_values[num_eval_ground_truth].sum(axis=0))\n",
    "        explainer.eval()\n",
    "        with torch.no_grad():\n",
    "            shapley_estimated=explainer(pixel_values=data[\"pixel_values\"].unsqueeze(0).to(explainer.device), return_loss=False)[\"logits\"][0]\n",
    "        diff=(shapley_estimated.T.cpu().detach().numpy()-num_eval_shapley_values[num_eval_ground_truth])\n",
    "        mse_class=(diff*diff).sum(axis=0)        \n",
    "        record_dict_list.append({\n",
    "            \"sample_idx\": sample_idx,\n",
    "            \"mse_target\": mse_class[np.arange(len(mse_class))==target_class_idx].mean(),\n",
    "            \"mse_nontarget\": mse_class[np.arange(len(mse_class))!=target_class_idx].mean(),\n",
    "            \"mse_all\": mse_class[:].mean(),\n",
    "            \"num_eval\":num_eval,\n",
    "            \"method\": \"objective_AO\",            \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2c7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(int(model_path_obj.split('-')[-1])/148)%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461153fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "444/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91304c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090995a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fac37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da40cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5134987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from cycler import cycler\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "font_manager.findfont(\"Arial\") # Test with \"Special Elite\" too\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.1))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16300924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df,\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15561acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a497ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(50000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(10000))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)    \n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_target\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.01))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.1)\n",
    "\n",
    "axd[plot_key].set_title(\"Target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb68920",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict_list_df=pd.DataFrame(record_dict_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "axd={\"main\": ax}\n",
    "plot_key=\"main\"\n",
    "\n",
    "sns.lineplot(x=\"num_eval\",\n",
    "             y=\"mse_nontarget\",\n",
    "             data=record_dict_list_df[record_dict_list_df[\"num_eval\"]>0],\n",
    "             hue=\"method\",\n",
    "            ax=ax)\n",
    "\n",
    "axd[plot_key].set_ylabel(\"L2 distance\", fontsize=20)\n",
    "axd[plot_key].set_xlabel(\"# model evaluations\", fontsize=20)\n",
    "\n",
    "\n",
    "axd[plot_key].yaxis.set_major_locator(MultipleLocator(0.005))\n",
    "axd[plot_key].yaxis.set_minor_locator(MultipleLocator(0.001))            \n",
    "axd[plot_key].yaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].yaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].xaxis.set_major_locator(MultipleLocator(1000))\n",
    "axd[plot_key].xaxis.set_minor_locator(MultipleLocator(500))            \n",
    "axd[plot_key].xaxis.grid(True, which='major', linewidth=2, alpha=0.6)\n",
    "axd[plot_key].xaxis.grid(True, which='minor', linewidth=1, alpha=0.1)\n",
    "\n",
    "axd[plot_key].tick_params(axis='x', which='major', labelsize=20)\n",
    "axd[plot_key].tick_params(axis='y', which='major', labelsize=20)   \n",
    "\n",
    "axd[plot_key].spines['right'].set_visible(False)\n",
    "axd[plot_key].spines['top'].set_visible(False)                   \n",
    "\n",
    "axd[plot_key].set_xlim(0,3500)\n",
    "axd[plot_key].set_ylim(0, 0.01)\n",
    "\n",
    "axd[plot_key].set_title(\"Non-target\", fontsize=20)\n",
    "\n",
    "# axd[plot_key].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "500/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a5318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d446c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce44723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a5f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426e85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf5a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76564e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76abcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d86bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febe09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9111265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fd24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d72efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c03e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609424dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb71e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb571e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2455520",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression_0/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_explainer_regression/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_out=explainer.forward(pixel_values=dataset[\"validation_explainer\"][0]['pixel_values'].unsqueeze(0),\n",
    "                               return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09996826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75733ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.to(device)\n",
    "explainer.surrogate_null=explainer.surrogate_null.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd568cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409324e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51752451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.max_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_figure(explainer, dataset, sample_idx_list):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                explainer.eval()\n",
    "                with torch.no_grad():\n",
    "                    explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "                    explanation=explanation[\"logits\"][0]\n",
    "                #print(explanation.shape)\n",
    "                if len(explanation.shape)==2:\n",
    "                    explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "                else:\n",
    "                    explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=mpl.colormaps['Greys'](1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{explainer.explainer.config.surrogate_config['id2label'][str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_figure_shapley(dataset, sample_idx_list, shapley_value, shapley_value_key):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=np.unique([dataset[sample_idx][\"labels\"] for sample_idx in sample_idx_list])\n",
    "    label_choice={idx:label for idx, label in enumerate(label_choice)}\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+list(class_list.values()))+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+list(class_list.values())), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(list(class_list.keys())))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "    print(\"class_list\", class_list)\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dataset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"pixel_values\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        \n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+list(class_list.values())):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(label)]}\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                #print(max(shapley_value[sample_idx].keys()))\n",
    "                #print(plot_type, shapley_value[sample_idx][shapley_value_key].shape)\n",
    "                explanation_class={n_samples:values for n_samples, values in zip(shapley_loaded[sample_idx][\"iters\"], shapley_loaded[sample_idx][\"values\"])}[shapley_value_key][:,plot_type]\n",
    "                \n",
    "                #print(explanation_class.shape)\n",
    "#                 print(explanation_class.shape, plot_type)\n",
    "#                 explainer.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     explanation=explainer(image.unsqueeze(0).to(explainer.device), return_loss=False)\n",
    "#                     explanation=explanation[\"logits\"][0]\n",
    "#                 if len(explanation.shape)==2:\n",
    "#                     explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "#                 else:\n",
    "#                     explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "                axd[plot_key].set_title(f\"{id2label[str(plot_type)]}\")\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded=load_shapley(\"logs/vitbase_imagenette_surrogate_eval_test/extract_output/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b68d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(1536))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(5120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_loaded, int(100352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(dataset_explainer[\"test\"], [0,  10, 30, 40], \n",
    "                    shapley_loaded, int(200192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1036/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5db97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_upfront_2048/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6628a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_regexplainer_upfront_2048/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "regexplainer.load_state_dict(state_dict)\n",
    "plot_figure(regexplainer, dataset_explainer[\"test\"],  [0,  10, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6886162",
   "metadata": {},
   "outputs": [],
   "source": [
    "32*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "148*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample_32/checkpoint-740/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c1dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34db542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1839ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_newsample/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-14800/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"logs/vitbase_imagenette_objexplainer_upfront_3200/checkpoint-1480/pytorch_model.bin\", map_location=\"cpu\")\n",
    "explainer.load_state_dict(state_dict)\n",
    "plot_figure(explainer, dataset_explainer[\"test\"], [0,  10, 20, 30, 40, 50, 60, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925f623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af73bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e0049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_explainer[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4c0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f794f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfc1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6078b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f27fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b74845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93724c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[1][\"values\"][-1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e497c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf77028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfbf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939a9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3725dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(shapley_loaded[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc744c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_loaded[0][\"iters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6470500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd51d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc7264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7d883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c7799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "512*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 5120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9977d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dab037",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(shapley_values_test[\"test\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03af49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "99840+512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a20d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 99840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"test_explainer\"], [0,  10, 20, 30, 40, 50, 60, 70], \n",
    "                    shapley_values_test[\"test\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3ffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecfb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_shapley(explainer, dataset[\"validation_explainer\"], [0,  250, 500,1000],\n",
    "                    shapley_values[\"validation\"], 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test_explainer\"], [0,  10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc574e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3714ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e26bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(explainer, dataset[\"test\"], [0,  250, 500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley_train_val.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d05692",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test = torch.load(\n",
    "    \"logs/vitbase_imagenette_surrogate_eval/shapley.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef656d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfede0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Initalize the explainer trainer\n",
    "########################################################\n",
    "# Load the accuracy metric from the datasets package\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "def compute_metrics(p):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    # import ipdb\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(p.predictions.shape, p.label_ids.shape)\n",
    "    # return metric.compute(\n",
    "    #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "    #     references=p.label_ids,\n",
    "    # )\n",
    "    return {}\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels,\n",
    "        \"masks\": masks,\n",
    "    }\n",
    "\n",
    "explainer_trainer = Trainer(\n",
    "    model=explainer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "    eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=explainer_image_processor,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# ipdb.set_trace()\n",
    "# print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "# print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "########################################################\n",
    "# Detecting last checkpoint\n",
    "#######################################################\n",
    "last_checkpoint = None\n",
    "if (\n",
    "    os.path.isdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif (\n",
    "        last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "    ):\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n",
    "\n",
    "########################################################\n",
    "# Training\n",
    "#######################################################\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    explainer_trainer.save_model()\n",
    "    explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "    explainer_trainer.save_state()\n",
    "\n",
    "########################################################\n",
    "# Evaluation\n",
    "#######################################################\n",
    "if training_args.do_eval:\n",
    "    metrics = explainer_trainer.evaluate()\n",
    "    explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "    explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "########################################################\n",
    "# Write model card and (optionally) push to hub\n",
    "#######################################################\n",
    "kwargs = {\n",
    "    \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "    \"tasks\": \"image-classification\",\n",
    "    \"dataset\": data_args.dataset_name,\n",
    "    \"tags\": [\"image-classification\", \"vision\"],\n",
    "}\n",
    "if training_args.push_to_hub:\n",
    "    explainer_trainer.push_to_hub(**kwargs)\n",
    "else:\n",
    "    explainer_trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4f0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fa564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e459b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5eb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec93405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ede138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec9aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6306a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab5732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5627301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf8f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d8d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf9207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f239a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    # Initalize the explainer trainer\n",
    "    ########################################################\n",
    "    # Load the accuracy metric from the datasets package\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    # Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "    # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "    def compute_metrics(p):\n",
    "        \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "        # import ipdb\n",
    "\n",
    "        # ipdb.set_trace()\n",
    "        # print(p.predictions.shape, p.label_ids.shape)\n",
    "        # return metric.compute(\n",
    "        #     predictions=np.argmax(p.predictions[:, 0, :], axis=1),\n",
    "        #     references=p.label_ids,\n",
    "        # )\n",
    "        return {}\n",
    "\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "        labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "        masks = torch.tensor(np.array([example[\"masks\"] for example in examples]))\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "        }\n",
    "\n",
    "    explainer_trainer = Trainer(\n",
    "        model=explainer,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train_explainer\"] if training_args.do_train else None,\n",
    "        eval_dataset=dataset[\"validation_explainer\"] if training_args.do_eval else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=explainer_image_processor,\n",
    "        data_collator=collate_fn,\n",
    "    )\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "    # print(\"explainer_trainer.label_names\", explainer_trainer.label_names)\n",
    "    # print(explainer_trainer.evaluate(dataset[\"validation_explainer\"]))\n",
    "\n",
    "    ########################################################\n",
    "    # Detecting last checkpoint\n",
    "    #######################################################\n",
    "    last_checkpoint = None\n",
    "    if (\n",
    "        os.path.isdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "    ):\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif (\n",
    "            last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
    "        ):\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    ########################################################\n",
    "    # Training\n",
    "    #######################################################\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = explainer_trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        explainer_trainer.save_model()\n",
    "        explainer_trainer.log_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_metrics(\"train\", train_result.metrics)\n",
    "        explainer_trainer.save_state()\n",
    "\n",
    "    ########################################################\n",
    "    # Evaluation\n",
    "    #######################################################\n",
    "    if training_args.do_eval:\n",
    "        metrics = explainer_trainer.evaluate()\n",
    "        explainer_trainer.log_metrics(\"eval\", metrics)\n",
    "        explainer_trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    ########################################################\n",
    "    # Write model card and (optionally) push to hub\n",
    "    #######################################################\n",
    "    kwargs = {\n",
    "        \"finetuned_from\": explainer_args.explainer_model_name_or_path,\n",
    "        \"tasks\": \"image-classification\",\n",
    "        \"dataset\": data_args.dataset_name,\n",
    "        \"tags\": [\"image-classification\", \"vision\"],\n",
    "    }\n",
    "    if training_args.push_to_hub:\n",
    "        explainer_trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        explainer_trainer.create_model_card(**kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15231b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99353761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
